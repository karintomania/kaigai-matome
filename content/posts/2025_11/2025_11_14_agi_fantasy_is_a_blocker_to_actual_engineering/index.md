+++
date = '2025-11-14T00:00:00'
months = '2025/11'
draft = false
title = 'AGI幻想はエンジニアリングの足かせ！本物のAIは遠い？'
tags = ["AGI", "AI開発", "ハードウェア", "LLM", "脳科学"]
featureimage = 'thumbnails/purple5.jpg'
+++

> AGI幻想はエンジニアリングの足かせ！本物のAIは遠い？

引用元：[https://news.ycombinator.com/item?id=45926469](https://news.ycombinator.com/item?id=45926469)




{{<matomeQuote body="AGIは結局ハードウェアの問題だと思うよ。LLMのニューロンは単純な機能だけど、人間の脳のニューロンは数千の入出力を処理するほど複雑で、さらに電力効率も段違いだ。脳には何百億ものニューロンがあって、アーキテクチャも超並列で複雑なフィードバックネットワークがある。現在の製造技術では人間の脳レベルのニューロンを作るのは無理だね。だからGPUやTPUでAGIをシミュレートするのは厳しくて、新しいハードウェアのパラダイムが必要だと思うよ。" userName="IgorPartola" createdAt="2025/11/14 14:25:21" color="#785bff">}}




{{<matomeQuote body="AGIを人間の脳の機能と定義するなら、ニューロンレベルのシミュレーターを作るか、機能レベルで設計するかの二つのアプローチがあるね。現状、脳の仕組みが十分に分かってないから、機能レベルで進めるしかないんだ。脳の電力効率と比べて、今のデータセンターの消費電力はすごいけど、まずは動くAGIを作ってから最適化すればいいんじゃないかな。MOE LLMの例を考えると、データセンターでは全ての専門家が常に動いてるから、カスタムハードウェアが電力効率で劇的に有利になるかは分からないかもね。" userName="HarHarVeryFunny" createdAt="2025/11/14 15:56:33" color="#45d325">}}




{{<matomeQuote body="意識の「ハード問題」は、純粋なエンジニアリング問題である「イージー問題」よりもずっと解くのが難しいと思うよ。人間はずっと脳がなぜ考えるのかを考えてきたけど、今のところ全くわかってない。これがAGI実現の大きな壁だよね。" userName="HDThoreaun" createdAt="2025/11/14 17:34:14" color="#785bff">}}




{{<matomeQuote body="ミツバチは、自律的に歩いたり飛んだりして環境を調べ、資源を集め、巣を作り、他のミツバチと連携するドローンみたいなものだよね。僕たちはそれに似たAIすら作れてないんだから、今のロボットが荒れた道を倒れずに歩くのがまだすごいレベルだ。ミツバチ一匹分の計算能力が足りないわけじゃないと思うな。" userName="nitwit005" createdAt="2025/11/15 00:24:14" color="#45d325">}}




{{<matomeQuote body="『脳がなぜ考えるのか全く分かってない』って言うけど、僕はそうは思わないな。僕らの新皮質は、過去の経験から未来を予測する予測マシンだってのが広く受け入れられてるよ。予測できる能力は、捕食者や獲物の行動を事前に予測したり、自分の行動の結果を予測したりするのに、生存上で計り知れないメリットがあるから進化したんだ。考えることって、多段階の予測にすぎないんだよ。意識だって自己観察能力みたいなもので、意識のないAGIができても誰が気にする？" userName="HarHarVeryFunny" createdAt="2025/11/14 19:37:36" color="#38d3d3">}}




{{<matomeQuote body="一方で、人間のハードウェアの複雑さの多くは、生存のためにランダムに進化したもので、高度な知的ゲームをするだけならそこまで多くのニューロンはいらないかもしれないよ。進化は僕らよりずっと低いスケールで動いてて、少ないエネルギーで成果を出してるんだからね。僕らの進歩も、作るものが小さくなるにつれて加速してきたし、これって偶然じゃないと思うな。" userName="rekrsiv" createdAt="2025/11/14 15:44:33" color="#45d325">}}




{{<matomeQuote body="意識がなぜ作られたかじゃなくて、脳のシステムが『なぜ』意識につながるのか、その根本的な理由を理解する必要があるんだよ。メカニズムだけを理解しても、脳のより正確な表現を目指すことしか自信を持ってできない。意識のないAGIっていうのは想像できるけど、僕は信じがたいな。" userName="HDThoreaun" createdAt="2025/11/14 23:32:24" color="#ff33a1">}}




{{<matomeQuote body="確かに、純粋な計算能力だけが足りないわけじゃないっていう点には同意するよ。でも、シンプルな昆虫の脳ですら完全にシミュレートできるほどの計算能力が今あるかって言われたら、それも同意できないな。" userName="nawgz" createdAt="2025/11/15 03:50:52" color="">}}




{{<matomeQuote body="AGIは、アーキテクチャの問題でもあると思う。LLMは単純にAGIにはなれないよ。" userName="zgk7iqea" createdAt="2025/11/14 15:59:13" color="">}}




{{<matomeQuote body="意識って自己観察能力で、予測入力に役立つんだ。賢い動物はみんな意識があるし、脳みたいなAIを作れば意識を持つって言うと思うよ。LLMは単純すぎて意識はないだろうね。意識を支える神経結合は自己予測の進化で発達したのかもしれないけど、十分な認知・感覚アーキテクチャがあれば「おまけ」で付いてくるもんじゃないかな。" userName="HarHarVeryFunny" createdAt="2025/11/15 00:06:17" color="#ff5733">}}




{{<matomeQuote body="進化は40億年のリードがあったから勝ってきたけど、たった200年で技術は巨大な計算機から、人間の会話を模倣するAIになったよ。まだ人間の脳には及ばないけど、新しいハードウェアアプローチが必要だね。脳が進化にかかった時間に比べたら、あっという間に人間レベルに到達しそうだ。" userName="wat10000" createdAt="2025/11/14 16:22:06" color="#ff5c5c">}}




{{<matomeQuote body="＞ 意識は自己観察能力ってあるけど、僕が知る限り、意識は自己言及システムとは違うもの、特に意識の「ハードプロブレム」に関わる話だよ。<br>「哲学的なゾンビ」（https://en.wikipedia.org/wiki/Philosophical_zombie）って思考実験は有名で、君が言うような構造的特徴は全部あるけど、「どんな感じか」っていう意識体験がないものを想像してるんだ。" userName="pavas" createdAt="2025/11/15 10:05:23" color="#ff5c5c">}}




{{<matomeQuote body="なんでダメなの？<br>多くの人がそう言うけど、LLMが最後まで行けないっていう根本的な限界を指摘した人は誰もいないよ。もしLLMに限界があるなら、まだ見つかってないだけだね。" userName="ACCount37" createdAt="2025/11/14 16:28:59" color="">}}




{{<matomeQuote body="なんか話がすれ違ってる気がするな。僕が世界中の全プロセッサを合わせてもミツバチの脳一つをシミュレートできないってのはおかしいと思う。もしミツバチの脳の仕組みをモデル化する知識がないって意味なら、それは同意するけど。<br>それにしても、NetflixのBlack Mirrorとか見てると、あの小さなデバイスどうやって動かしてるんだ？どんなバッテリー技術なんだ？ってSFなのに考えちゃうんだよね。" userName="mcny" createdAt="2025/11/15 06:15:24" color="">}}




{{<matomeQuote body="「哲学的なゾンビ」は不可能で非論理的な概念で、意識に必要な構造があれば必然的に意識を持つ、って考えられるよ。<br>意識の構造的基盤を考えると、「ブラインドサイト」って現象は面白い。視覚自体は失ってないのに、視覚的な意識が失われるんだ！<br>自分の思考や感覚入力にアクセスできれば、「どんな感じか」を報告できるはず。彼らが視覚や聴覚のクオリアを報告するなら、それこそ「どんな感じか」ってことじゃない？" userName="HarHarVeryFunny" createdAt="2025/11/15 14:42:30" color="#38d3d3">}}




{{<matomeQuote body="人間の脳なんて必要ないよ。人間脳は成長に時間がかかり、訓練も長くて、いつも気が散ってるんだから。<br>僕らの論理ベースのプロセスは、どんどん小さく、低電力になっていくだろうね。いずれ進化と同じ構成要素で、より賢い方法で問題を解決できるようになるさ。LLMはその中のごく一部を担うだけになるだろう。" userName="rekrsiv" createdAt="2025/11/14 16:49:24" color="#ff33a1">}}




{{<matomeQuote body="＞ 世界中の全プロセッサを合わせてもミツバチの脳一つをシミュレートできないってのはおかしい。<br>ミツバチは100mgで、その5%が脳だと5mg。炭素5mgは2.5×10^20原子だよ。一番大きなスーパーコンピュータでもトランジスタは2-5×10^14個。世界中のコンピュータを合わせてもミツバチの脳の原子1個につき1トランジスタも無理だし、1原子のシミュレーションには何桁も多くのトランジスタが必要だろうね。今の計算レベルでは簡単な昆虫の脳すらリアルタイムでシミュレートできないと思う。世界中の計算資源を使っても、ミツバチの1秒の思考を1時間で計算できるかどうか。それに、原子を完全にシミュレートする方法なんて全くわかってないからね。" userName="nawgz" createdAt="2025/11/15 20:11:22" color="#ff33a1">}}




{{<matomeQuote body="＞ ミツバチの脳の原子数計算<br>この問題の合理的な特徴付けはもう終わったね。誰も生物の脳や神経系を原子レベルでシミュレートしたいわけじゃないよ。<br>どんな細胞の原子も、神経細胞を含めて、ほとんどが複雑だけど一般的な生存システムを動かしてるだけ。神経学的行動を具体的にサポートするごく一部の原子は、個々の原子レベルではなく、それより何桁も高いスケールで意味のある貢献をしてるんだ。" userName="Nevermark" createdAt="2025/11/15 22:36:40" color="#ff5c5c">}}




{{<matomeQuote body="＞ 「哲学的なゾンビ」は不可能で非論理的。構造があれば意識を持つ。<br>そうだね、まさにそこがポイントなんだ。誰かがp-ゾンビなのか、意識的な現象体験を持つ存在なのか、判断する方法がないんだよ。十分な構造があれば意識があるって意見や信念を持つのは全く合理的だけど、それはテスト不可能で反証できないから科学的立場じゃないってことを理解しないとね。だから「意識のハードプロブレム」って呼ばれてるんだ。心理的快適さから選ぶ根拠のない信念だね。<br>「マッピングとテリトリー」の関係について君は洗練された区別をしてるね。他人が経験してないことを「どんな感じか」ってどう報告できるのかって核心を突いてるよ。トーマス・ネーゲルの「コウモリであるとはどのようなことか？」っていう論文が有名だから、もし興味があれば読んでみて。<br>「ブラインドサイト」については詳しくないんだけど、視覚意識の喪失と、意識領域間の情報伝達の喪失、または意識経験に関する記憶の喪失をどう区別するんだろう？" userName="pavas" createdAt="2025/11/15 18:52:04" color="#ff5733">}}




{{<matomeQuote body="蜂の脳をシミュレートするのに、原子数より圧倒的に少ないトランジスタでどうやって十分って言えるんだ？トランジスタ一つじゃ何もできないって。原子を軽視するのは違うだろ。" userName="nawgz" createdAt="2025/11/16 16:48:18" color="">}}




{{<matomeQuote body="意識があるかどうかって、どうやってわかるんだ？「意識的な経験」の定義が曖昧すぎないか？ただ本人に聞けばいいんじゃない？意識の「ハードプロブレム」とか言われてるけど、脳がクオリアや主観的経験を生み出す理由なんて、そもそも問題じゃないと思うんだよね。色の知覚だって、連想で説明できるじゃん。" userName="HarHarVeryFunny" createdAt="2025/11/15 22:03:30" color="">}}




{{<matomeQuote body="LLMの限界は色々見つかってるよ。スケーリング法則だと性能向上は頭打ちだし、OOD問題も未解決。LLMはドメインシフトとか新しい組み合わせに弱いんだ。COTの忠実性研究では、LLMの推論が実際の内部計算と違って、自己知識がないことも示されてる。AGIは無理とまでは言わないけど、今のLLMをただスケールアップしてもAGIには届かないんじゃないかな。" userName="lossolo" createdAt="2025/11/14 17:45:33" color="#ff33a1">}}




{{<matomeQuote body="「LLMニューロンは単一入出力、脳は数千」って言ってるけど、それは単なるスケーリングの問題だよ。数千の単一I/O関数で数千の入出力を持つ関数を再現できるからね。それに、LLMは人間より断然速くエッセイ書けるし、並列処理もできるから、エネルギー効率の比較は単純じゃないって。" userName="naasking" createdAt="2025/11/14 15:39:59" color="#ff5c5c">}}




{{<matomeQuote body="赤いものを見たとき、連想とか思考が始まる前に、その赤さ自体に何か感覚的なものってある？俺は思考を止めてただ見ると、言葉にできないけど、そこにある「質」みたいなものを感じるんだ。でもこれって人によって違うのかな？視覚イメージがない人とかもいるし、現象的な経験って意外と個人差が大きいのかもしれないね。" userName="pavas" createdAt="2025/11/16 00:27:40" color="">}}




{{<matomeQuote body="トランジスタはニューロンより単純だけど、めちゃくちゃ速いから、単位時間で見たら圧倒的に多くの処理ができるんだよ。蜂の脳のニューロン動作とCPUのトランジスタ動作を比較すると、CPUの方が桁違いにパワフルってわかる。蜂の脳のモデリングは、ニューロンの組織構造が問題なんだ。原子は計算と関係ないから、蜂の脳を原子レベルでモデル化する必要はないって。" userName="Nevermark" createdAt="2025/11/17 04:38:12" color="#ff5733">}}




{{<matomeQuote body="ハードウェアの話だけど、人間の脳のデータ処理量は今のエクサスケールコンピュータより桁違いに多いよ。手だけで4万以上の受容器、眼には数百万の細胞があるんだ。個々のニューロンやシナプスも並列処理能力と状態情報を持ってる。AIコミュニティの傲慢さには笑っちゃうね。AGIには、今のハードウェアじゃなくて、もっと大規模なハードウェアの進歩が何段階も必要だって！" userName="daveguy" createdAt="2025/11/14 16:31:14" color="#ff5c5c">}}




{{<matomeQuote body="LLMがCOTの忠実性とかで失敗するのは、人間と同じ失敗の仕方をしてるんだよね。これはLLMがAGI capableな弱いサインだと思う。人間と同じ失敗をするってことは、LLMが人間と同じようなやり方で考えてる可能性を示唆してるじゃん。人間の心は汎用知能をサポートする唯一のアーキテクチャだしね。それにAnthropicの論文だと、LLMには内省能力も少しはあるらしいよ。訓練すればもっと良くなるって！" userName="ACCount37" createdAt="2025/11/15 09:43:41" color="#ff33a1">}}




{{<matomeQuote body="ダイヤルアップモデムしか知らない人に、4k HDR動画ストリーミングがあるって説明するのを想像してみてよ。" userName="anal_reactor" createdAt="2025/11/14 15:17:53" color="">}}




{{<matomeQuote body="おいおい、リアルタイムで昆虫の脳より4*10^14倍も計算能力があるとか、いい加減にしろよ。この人は、何兆もの原子の複雑さを軽視する前に、合理的な特徴付けが失われたって言ってた人だろ。お前のうぬぼれが想像できてマジむかつくわ。" userName="nawgz" createdAt="2025/11/17 19:03:20" color="">}}




{{<matomeQuote body="半導体業界の生能力はすごいぞ。3nmの100mm^2ダイには1～10兆個の機能がある。規模的にはそんなに遠くないんじゃないかな。どう配置するかが難しいんだよな。EDA [0]の問題は”苦い教訓”には当てはまらない。GPU/TPU/CPUよりもこの問題をうまく解決できる特定の物質配置は確実にあるはずだよ。<br>[0] https://en.wikipedia.org/wiki/Electronic_design_automation" userName="bob1029" createdAt="2025/11/14 16:58:31" color="#ff33a1">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="テクノロジストとして効果的、効率的、無害に問題を解決したいって？俺もだよ。でも、それって現実的じゃないかもって心配してる。昨日Raspberry CM 4でBluetooth/BLEを動かそうとして、GPTとClaudeに10分デュエルしたらrfkillを学べたんだ。Linux歴20年なのに知らなかった。Stack Overflowも昔みたいじゃないし、どこを見ればいいかわからない。技術が複雑になりすぎて、LLMとAGI幻想に頼るしかないって感じだよ。" userName="travisgriggs" createdAt="2025/11/14 15:40:30" color="#ff5733">}}




{{<matomeQuote body="短期的にはgenAIなしで複雑な技術世界を乗り切るのは無理だろうね。でも中長期的には、genAIなしでは成り立たない世界が生き残るとは思えない。いつか車は普通の人が理解して直せるくらいシンプルになるべきだ。専門知識に頼りすぎ、専門家ですらgenAIなしではやっていけない社会は、あまりに脆すぎて長くは続かないと思うよ。" userName="wilkommen" createdAt="2025/11/14 15:51:50" color="#ff5733">}}




{{<matomeQuote body="概ね同意だけど、複雑な気持ちだよ。AIが”悟りを開いた達人エンジニア”になって、超人的なレベルで物事を簡素化できる可能性もあるよね。例えばWebプラットフォームは巨大すぎて、V8を長く担当してた俺でも全体は理解できない。AIがコードを深く理解して、ゼロから俺たちが本当に望む、理解できるものを作り直せる日が来るかもしれないな。" userName="titzer" createdAt="2025/11/14 21:14:46" color="#ff33a1">}}




{{<matomeQuote body="＞俺たちのシステムはショックに耐えられない<br>最近その不穏な予兆を見たよね。使わないものは衰えるっていうのは自然の法則だ。システムをあまりに安定させて予測可能にすると、安定性がない状況で効果的に機能する能力も失われちゃうんだ。" userName="andai" createdAt="2025/11/15 04:33:30" color="#785bff">}}




{{<matomeQuote body="俺もその脆弱性の議論には同意するよ。でも、もしショックが来たら、車なんて作ってるどころじゃないと思うね。簡単に手に入る鉱石はとっくに掘り尽くされて酸化しちゃってるってことを考えると特にね。" userName="jgilias" createdAt="2025/11/14 17:21:47" color="">}}




{{<matomeQuote body="ディストリビューションにはマニュアルがあるよ、最近はユーザーが管理するWikiの形だけどね。俺もDebianユーザーだけど、Linuxで問題にぶつかったらArchWikiをまず見るよ。<br>https://wiki.archlinux.org/title/Bluetooth も https://wiki.debian.org/BluetoothUser もrfkillについて書いてあって、トラブルシューティング方法も載ってる。" userName="saint_yossarian" createdAt="2025/11/14 17:37:45" color="#785bff">}}




{{<matomeQuote body="＞技術が複雑になりすぎて、LLMとAGI幻想に頼るしかない<br>これは短期的に俺たちが心配すべき真のAIリスクだと思う。情報技術は既に物事をめちゃくちゃ複雑にした。AIはさらに理解不能にするだろうね。うちの大企業でも、誰も片付けたくない複雑なツールや技術的負債が山ほどある。AIを使って適切なツールを見つけ、コマンドを実行する試みがいくつかあるんだ。10年か20年後には人間は実際に何が起こってるかを理解しようとしない、脳が弱まり、論理は途方もなく複雑になるなんてありえない話じゃないよ。" userName="asdfman123" createdAt="2025/11/14 17:46:20" color="#ff5733">}}




{{<matomeQuote body="AIに技術的負債を片付けさせるなんて試み、誰かしたことある？" userName="jimbokun" createdAt="2025/11/14 17:53:11" color="">}}




{{<matomeQuote body="長期的な投資って、結果がすぐ出ないからマネジメントは評価してくれないんだよね。新しい機能を作って数字を伸ばすやつが出世するってさ。現場はもうやってるんだけど、会社からのインセンティブがなくて困るよ。" userName="asdfman123" createdAt="2025/11/14 17:55:38" color="#45d325">}}




{{<matomeQuote body="だからソフトウェア開発するなら、エンジニア出身のマネージャーがいる組織で働くのがマジで重要だよ。彼らならちゃんと設計されたシステムの価値を理解してくれるもん。そうじゃないと評価されなくてモチベーション保てないよな。" userName="jimbokun" createdAt="2025/11/14 20:39:06" color="#45d325">}}




{{<matomeQuote body="それって、小さい会社の場合だよね。無駄な投資をする余裕がないからさ。Big Techなら、あらゆる「くだらないこと」にもお金を使える余裕があるってことだろ。" userName="asdfman123" createdAt="2025/11/14 21:26:36" color="">}}




{{<matomeQuote body="そうそう、よくわかるわ。”信じられるROI”ばっかり重視されるから、新しいことやるのが本当に難しいんだよね。" userName="iamflimflam1" createdAt="2025/11/14 19:12:54" color="">}}




{{<matomeQuote body="LLMがGoogleやStack Overflowの代わりになるってのは、マジで当然だと思うね。ソースが確認できて、ハルシネーションを見抜くスキルがあれば全然OK。人間が作った情報でも同じように取捨選択してるわけだし。ただ、まだ人間を完全に置き換えるのは無理だよ。" userName="jimbokun" createdAt="2025/11/14 17:52:13" color="#ff5c5c">}}




{{<matomeQuote body="うん、LLMを使ってみると、自分が作ってるソフトウェアや使ってるシステムの複雑さについて考え直すきっかけになるよ。LLMは複雑性のテストになるし、高速なイテレーションで既存より良いソリューションが見つかる可能性もあるんだ。" userName="FattiMei" createdAt="2025/11/14 16:56:12" color="#38d3d3">}}




{{<matomeQuote body="今日のLLMは幻想なんかじゃない、ちゃんと機能する具体的なものだよね。開発者が夢見てるってだけで、俺らがその成果を享受できないわけじゃないし！とはいえ、AIトレーニングに使われたエネルギーの多くは、使い物にならないカスになってる気はするけどな。" userName="gwbas1c" createdAt="2025/11/14 19:37:20" color="#ff5c5c">}}




{{<matomeQuote body="検索がAIより劣ってる唯一の理由は、品質がどんどん悪くなってる（enshitification）からだよ。オープンウェブが廃れてしまえば、このLLMたちも同じ道をたどるだろうなと俺は思ってるよ。" userName="jayd16" createdAt="2025/11/15 00:09:49" color="">}}




{{<matomeQuote body="LLMって「semantic search」はめちゃくちゃ得意だよね。従来の検索エンジンが苦手としてた領域だから、そこは大きな強みだよ。" userName="undeveloper" createdAt="2025/11/15 00:37:26" color="#ff5c5c">}}




{{<matomeQuote body="誰も検索エンジンが”伝統的”じゃなきゃダメなんて言ってないだろ。でも、実際の検索結果とマッチさせるために、ハルシネーション起こすようなUXを通して情報をフィルターする必要もないんだよ。" userName="jayd16" createdAt="2025/11/16 21:16:35" color="">}}




{{<matomeQuote body="LLMは根本的な行き止まりだって、業界の大物たちは前から言ってるよ。新しい道を探す会社を立ち上げた人も多い。でも、株とか評判が絡んでたら、その幻想を壊したくはないだろ？だから、今があるのさ。" userName="Etheryte" createdAt="2025/11/14 14:13:18" color="#38d3d3">}}




{{<matomeQuote body="「危ない技術だから誰にも教えてない」って話だけどさ。AIって名前が付けられて以来、自分のアイデアこそがAIを成功させると信じる賢い人は山ほどいたんだよ。ELIZAとかSHRDLUとかAutomated Mathematicianとか、小規模だと凄いけど、実用的な規模じゃ使えないアイデアばかりだったろ？だから、お前がちゃんとアイデアを形にしてないなら、俺は信用しないね。" userName="chriswarbo" createdAt="2025/11/14 15:16:16" color="#ff5c5c">}}




{{<matomeQuote body="おいおい、皮肉って分かる？お前は具体的に何一つ言えないアイデアに、なんでそんなに固執してるんだ？自分の考えが間違ってる可能性すら認めないとか、正直、妄想としか思えないよ。もっと自分を疑った方がいい。アイデアが正しすぎて世界を燃やすのを恐れてるなら、セラピストに相談しろ。これは個人攻撃じゃないし、お前のアイデアを否定するつもりもない。だって何もアイデア出してないだろ？自分がどれだけ賢いか愚痴ってるだけで、周りから反感買ってんぞ。そんな態度じゃ何も進まないし、お前のエゴしか見えない。もっと自分を見つめ直して、信頼できる人に話してみな。" userName="titzer" createdAt="2025/11/15 18:40:20" color="#38d3d3">}}




{{<matomeQuote body="お前が低評価されてるのは、人が恥ずかしいと感じるような自信満々な態度だからだよ。MLやってる奴なら、「これぞAIの大発見になる新アイデアだ！」なんて話を何百回も聞いてきたんだ。なんで本当のブレイクスルーがそんなに少ないか、考えたことないの？" userName="ACCount37" createdAt="2025/11/14 16:35:08" color="#ff5733">}}




{{<matomeQuote body="じゃあ、俺の前の仕事の話を聞けよ。俺は機械の実験のために雇われたんだが、連中は無駄な実験ばっかりしてた。俺は数分で、最大効率を出す解決策をノートに書き出したよ。でも、それじゃ俺の仕事なくなるだろ？だから教えなかった。どうせ誰も俺の声なんて聞かないしね。数ヶ月後、大学のPhDチームが同じアイデアの原型を見つけやがった。その時になって「あ、俺もう解いてるんで」って上司に言ったら、コード書いたら爆速になったよ。褒められたけど、結局、学位持ちの男が言ったから聞いただけ。どうせ聞かない奴らに、俺が先にアイデア出すメリットなんてないだろ？だから今、お前らが俺をイカれてるって言っても構わないよ。正直、俺にはお前らに答えを教える義理はないんだからな。勝手に頑張れよ。" userName="fallingfrog" createdAt="2025/11/16 03:41:44" color="#45d325">}}




{{<matomeQuote body="多くのアイデアは全くスケールしないんだよね。もし2.5億規模で粘り強く+5%の効果を出せるなら、そりゃ本物だ。でもほとんどの新しいMLアイデアは、そこまで到達できないのが現実だよ。" userName="ACCount37" createdAt="2025/11/14 16:33:07" color="#ff5c5c">}}




{{<matomeQuote body="「数ヶ月前に答えを教えたとしても、真面目に受け止められたとしてもボーナスは出なかっただろう」って？アイデアを自分の中にしまっておいたから、評価されなかったんだよ。被害者意識は自分で作り出したもので、ずっと頭の中にあっただけだ。皮肉なことに、君こそ同僚に対して受動的攻撃的で偏見を示してるじゃないか。" userName="thunky" createdAt="2025/11/16 19:16:40" color="">}}




{{<matomeQuote body="LLMの進歩を見て「これは蜃気楼だ」ってどうして思えるんだ？" userName="jamesoofou" createdAt="2025/11/14 22:40:46" color="">}}




{{<matomeQuote body="「AGI」の定義が何であれ、それにとっては行き止まりかもしれないけど、多くの分野でめちゃくちゃ役立つし、経済的には「行き止まり」じゃないよ。" userName="wild_egg" createdAt="2025/11/14 15:29:10" color="#ff5c5c">}}




{{<matomeQuote body="自分の発見がすぐに他の誰かに見つけられるって確信してるなら、ここで共有して、君が欲しいみたいに評価を得ればいいじゃん？そうでなきゃ、そもそも何でそんな話を持ち出すの？" userName="thunky" createdAt="2025/11/15 02:20:02" color="">}}




{{<matomeQuote body="100万回中999999回は君が正しいだろうね。でも、俺は何も言うべきじゃなかったな。" userName="fallingfrog" createdAt="2025/11/14 20:23:05" color="">}}




{{<matomeQuote body="あんたのクソみたいなアイデア、ちょっとでもスケールさせてみたことあるの？" userName="ACCount37" createdAt="2025/11/15 08:46:35" color="">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="多くの業界の大物が、LLMが根本的な行き止まりだって主張してるけど、それならその限界に関する論文があるはずだよね？ポインタはどこ？「LLMの単一フォワードパスのTC0回路複雑性」ってのはちょっと違うし。現代のLLMはCoTを使ってるし、ゲーデルの不完全性定理を持ち出すと話が大きくなりすぎちゃうよ（脳がハイパー計算できるかなんて分からないし、おそらくできないだろうからね）。" userName="red75prime" createdAt="2025/11/14 15:32:28" color="#785bff">}}




{{<matomeQuote body="いくつか名前を挙げてみてよ？だって、YeCunの離脱が、LLMの軌道から大きく外れて目立った最初の著名人だと思うけど。" userName="rsbrown" createdAt="2025/11/15 22:33:35" color="">}}




{{<matomeQuote body="概念の深さがすごく深いから、始めたばかりだとその言葉がどれだけ明白か理解するのに時間がかかるだろうね。2010年代初めからこの分野を嗅ぎ回ってる人たちにとっては、LLMなんてとっくに捨てて、もっと深い代替研究に移ってるのが当たり前なんだ。僕ら残りの人たちは、まだ空から落ちてくるコカ・コーラの瓶を拾って、それを崇拝する場所を作ってるようなもんさ。" userName="NamlchakKhandro" createdAt="2025/11/14 22:55:44" color="">}}




{{<matomeQuote body="「給料がかかってる奴に何かを理解させるのは難しい」とか「仕事で納得しちゃいけない奴と議論するな」って言葉、まさにこれだね。" userName="hoherd" createdAt="2025/11/14 15:31:11" color="">}}




{{<matomeQuote body="人類を滅ぼす終末兵器を少しでも早く登場させるリスクを冒す理由はないし、それにどうせ聞かないでしょ。私が何か言ったのは、口の軽いバカだからで、理性的な根拠のない感情的なカタルシスのためだったんだ。" userName="fallingfrog" createdAt="2025/11/16 04:27:40" color="">}}




{{<matomeQuote body="「根本的な行き止まり」ってのは言い過ぎに感じるね。たとえLLM自体がAGI構築に十分じゃなくても、「AGI」システムの重要な一部になりえるのは明らかじゃない？" userName="jimbokun" createdAt="2025/11/14 17:55:45" color="">}}




{{<matomeQuote body="俺は蒸気機関と飛行機の話に似てると思ってるよ。蒸気機関は飛行機には向かなかったけど、その開発経験は内燃機関に応用されたでしょ。LLMとAGIもそんな感じなんじゃないかな。" userName="tim333" createdAt="2025/11/14 18:30:41" color="#ff33a1">}}




{{<matomeQuote body="3年サイクルの技術に40年もの投資が必要ってのはちょっとね。" userName="bigbuppo" createdAt="2025/11/14 16:39:07" color="">}}




{{<matomeQuote body="結論には賛成だね。例えば、Whisperのおかげで動画のCC作成が劇的に楽になったよ。以前は数時間かかってたのに、今じゃ数分でWhisperに通して、ちょっと修正するだけで終わるんだ。AIには大きな成功例があるけど、それが解決されるとバブルは弾けない。<br>MacWhisperみたいな優れたUIが出たから、Whisperがもっと使いやすくなったんだよね。" userName="geerlingguy" createdAt="2025/11/14 14:18:45" color="#38d3d3">}}




{{<matomeQuote body="著者だよ。ディープラーニングやTransformerに価値がないなんて言うのは非現実的だよね。昨日、Cory Doctorowが、プロボノ弁護士たちがLLMを使って書類を分析し、無実の人を助けてるって話してたよ。これも大きな成果だね。過剰なスケールアップなしでも、基盤技術でできる良いエンジニアリングってたくさんあるんだ。" userName="tomwphillips" createdAt="2025/11/14 16:26:11" color="#ff5c5c">}}




{{<matomeQuote body="Whisperだけじゃなく、コンピュータービジョンの分野もあまり流行ってないよね。たぶん、そこで生まれたものすごいソリューションが、一般の人にはあまり馴染みがないからじゃないかな。例えば、大規模な産業製造やロボティクスとかね。" userName="sota_pop" createdAt="2025/11/14 14:39:33" color="">}}




{{<matomeQuote body="LLMの誇大広告が、現実世界やロボット知能におけるすごくリアルで影響力のある進歩を隠してると思うんだ。論文書き機もすごいけど、どんなロボットアームでも器用に制御できて、すぐに使える機械は世界を変える可能性を秘めてるよね。人間が明示的にコード化した指示なしで物を動かしたり操作したりできたら、本当に世界が大きく変わるよ。" userName="dghlsakjg" createdAt="2025/11/14 16:15:44" color="#785bff">}}




{{<matomeQuote body="それはね、産業製造やロボティクスがコストを下げて、みんなの生活をもっと手頃にするのに失敗してるからだよ。それがこれらの技術が提供する唯一の価値なんだから、コストが下がらないなら、これらの技術からは何の価値も生まれてないってことになっちゃうね。" userName="jimbokun" createdAt="2025/11/14 17:58:14" color="">}}




{{<matomeQuote body="この前Parakeetに切り替えたんだけど、Whisperより良くて速いんだよ。10年前のThinkPadのCPUでも動くんだ。ClaudeにPythonのバインディングを作ってもらって、自分の音声入力アプリに追加したんだよね。まさに未来に生きてるって感じ！" userName="andai" createdAt="2025/11/15 04:36:42" color="#38d3d3">}}




{{<matomeQuote body="AIの多くの成功は、Whisperみたいにローカルで無料で使えるものになると思うんだ。もうちょっと精度が上がったり速くなったりしたらいいけど、最終的には95%完成した無料のソフトウェアとしてずっと使えるようになるんじゃないかな。5～10年後には、みんな10万コアと1TBのRAMを積んだノートPCを持って、まるでStar Trekみたいに話しかけるLLMを使うようになるって予想してるよ。" userName="colechristensen" createdAt="2025/11/14 16:09:56" color="">}}




{{<matomeQuote body="AI懐疑派へのアドバイスだけど、データセンターの’水の消費量’議論は避けた方がいいよ。文脈なしの“年間数百万リットル”は怖く聞こえるけど、農地やゴルフ場と比べたら小さいから、信頼性を損なうと思う。エネルギー消費量とかCO2排出量はいいんだけどね。AGIの議論は大きな邪魔だね。追記：農業用水との比較は良くなかったかも。データセンターは飲料水を使うことが多いから。でも、文脈なしで“大量のガロン”って数字を出すのは良くないってのは変わらないかな。" userName="simonw" createdAt="2025/11/14 14:21:42" color="#45d325">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
