+++
date = '2025-10-21T00:00:00'
months = '2025/10'
draft = false
title = 'LLMが脳腐敗する可能性？ AIの知性がおかしくなるってホント？'
tags = ["AI", "LLM", "機械学習", "データ", "品質管理"]
featureimage = 'thumbnails/cyan4.jpg'
+++

> LLMが脳腐敗する可能性？ AIの知性がおかしくなるってホント？

引用元：[https://news.ycombinator.com/item?id=45656223](https://news.ycombinator.com/item?id=45656223)




{{<matomeQuote body="LLMの”脳腐敗”の研究って、AIにとっての”認知衛生”って捉え直すことで、訓練データをどう調達し、フィルターし、維持するかっていう指針になるんだって文章、もし俺がLLMが書いたのを見たなら、これだね。著者の人たち、自分たちも脳腐敗と戦ってるみたいだよ。" userName="avazhi" createdAt="2025/10/21 17:41:15" color="#ff33a1">}}




{{<matomeQuote body="あれは確かにLLMが書いた文章だよ—em dashを使ってるだけじゃなくて、同じ文中でリストを2回も並べてるんだ—典型的なLLMの行動で、その出力が目立って、明らかで、HN読者にはすぐわかるんだよね。" userName="standardly" createdAt="2025/10/21 19:30:27" color="#ff33a1">}}




{{<matomeQuote body="この記事、もうここで話題になったと思うけど、俺はいまだに考えちゃうな。em dashを使うの、大好きなんだよね！でも人間らしく聞こえるために、もう使わない方がいいなんて、悲しいよ。https://bassi.li/articles/i-miss-using-em-dashes" userName="turtletontine" createdAt="2025/10/21 19:45:51" color="#ff5c5c">}}




{{<matomeQuote body="意図した情報が伝わるなら、何が悪いの？君は津波と戦ってるようなもんだよ。みんな、これからずっとLLMを使って文章を書くようになるんだから。" userName="askafriend" createdAt="2025/10/21 17:41:53" color="#ff5733">}}




{{<matomeQuote body="俺はもう何十年も前からそうしてるよ。例えばこれを見てくれ：多くのプログラミング言語には例外処理の機能があるけど、それ自体に問題があるんだ—もしクリーンアップコードから例外が発生したら、どちらかの、あるいは両方の例外が失われ、そのレベルの残りのクリーンアップコードは実行されないんだ。当時はUnicodeのem dashじゃなかったけど、かなり早くから切り替えたんだ。人間の作家だって、何世紀も前からem dashやカンマ区切りのリストを使ってるのを簡単に見つけられるよ。https://www.mail-archive.com/kragen-tol@canonical.org/msg000..." userName="kragen" createdAt="2025/10/22 10:54:18" color="#38d3d3">}}




{{<matomeQuote body="em dashは使い続けたらいいよ。もし誰かがem dashを使ったってだけでLLMが作ったって推測するなら、俺たちはもう負けてるか、そいつがバカかだよ。もっとはっきり言うと、LLMはem dashを特定の使い方がするから、em dashの周りのスペースを変えたり、二重ダッシュ（—）を使ったりすれば、人間が書いたってわかるかもしれないね。" userName="JumpCrisscross" createdAt="2025/10/22 00:22:44" color="#785bff">}}




{{<matomeQuote body="em dashの使用に関する悩みは、たぶん一時的なものだよ。もし俺だったら、今まで通り使い続けるね。そのうちAIがあらゆる句読点や文法のパターンを真似するようになったら、みんなと同じように無視されるようになるからさ。" userName="janderson215" createdAt="2025/10/21 19:55:07" color="#ff5c5c">}}




{{<matomeQuote body="突然、みんなが”em dash”について話し出したな。あれってひどいよ。見た目も悪いし、文章のまとまりをぶっ壊すんだ。LLMが使うのも納得だね。" userName="landdate" createdAt="2025/10/22 00:08:48" color="">}}




{{<matomeQuote body="LLMはいつもem dashを使ってたわけじゃないよ。ウォーターマークみたいに、意図的に使ってるんじゃないかな。他にも”wild”とか”vibes”みたいなバズワードで（LLMって）わかるよ。" userName="astrange" createdAt="2025/10/21 22:32:02" color="#ff5c5c">}}




{{<matomeQuote body="LLMが作る文章はひどく、一貫性を壊すって意見に、俺も全く同感だよ。NabokovとかJoyce、Dickinsonが言語について何を知ってたって言うんだよな、冗談だけど。" userName="JumpCrisscross" createdAt="2025/10/22 00:23:19" color="#38d3d3">}}




{{<matomeQuote body="俺も同じだよ。最近LLMが原因だって知ったけど、ずっとこんな感じで使ってたんだよね。関連情報も見てみて:<br>https://news.ycombinator.com/item?id=45226150" userName="jader201" createdAt="2025/10/21 21:29:28" color="">}}




{{<matomeQuote body="解決策は明らかだね: Unicodeには暗号署名付きのダッシュと空白文字が必要だ。" userName="lxgr" createdAt="2025/10/22 06:24:55" color="#45d325">}}




{{<matomeQuote body="マジか、これすごいな。俺だけか分かんないけど、大学の時に、たくさん読んでるものによって自分の文章スタイルや”声”がガラッと変わるのに気づいたんだ。避けられないくらいLLM生成コンテンツを読むようになったら、自然とLLMみたいに書き始めちゃうのかな。" userName="hunter-gatherer" createdAt="2025/10/21 19:52:09" color="#ff5733">}}




{{<matomeQuote body="LLMを使うこと自体は悪くないんだ—でも、どの段落もLinkedInでバズるためにA/Bテストされたみたいに聞こえ始めたら、それが脳腐敗の始まりだね。問題はAIを使うことじゃなくて—マーケティング部門を感動させようとするAIみたいに聞こえちゃうことだよ。そうなったら、もうループが閉じたってことさ。" userName="uludag" createdAt="2025/10/21 17:47:51" color="#ff5c5c">}}




{{<matomeQuote body="LLMの脳腐敗についてLLMに書かせることの皮肉が理解できないなら、何を言えばいいか分からないな。LLM研究者が、LLMが脳腐敗を引き起こす可能性を示唆する論文で、自分たちの思考をLLMにアウトソースすべきじゃないって期待は変わらないよ。" userName="avazhi" createdAt="2025/10/21 17:46:01" color="#785bff">}}




{{<matomeQuote body="見事な表現だね—鋭くて簡潔、みんなが分かるけど名前を付けられないあの不気味な”AIが磨き上げたような”抑揚を完璧に捉えてるよ。機知と警告のバランスがちょうど良い感じだ。" userName="drusepth" createdAt="2025/10/21 18:03:17" color="">}}




{{<matomeQuote body="あなたがこだわってるのは書き手のスタイルであって、中身じゃないだろ。思考をLLMにアウトソースしたってどうしてそんなに言い切れるんだ？ LLMがジャンクな内容しか作らないから、人間の脳腐敗に繋がるって決めつけてないか？ もし囲碁みたいに質の高い内容だったら？ その文章を研究したいと思わないのか？" userName="nemonemo" createdAt="2025/10/21 17:53:40" color="#ff33a1">}}




{{<matomeQuote body="何と結びつくって？ 人間の思考をデジタルで表現する時に、証明可能で、暗号的に完全性を保つ方法を示してくれよ。そしたらノーベル賞と人道に対する罪で裁かれる、その両方をもらえるだろうね。" userName="TeMPOraL" createdAt="2025/10/22 07:02:43" color="#785bff">}}




{{<matomeQuote body="LLMは理解もせずにもっともらしいフレーズを吐き出す、古くて意味のない駄文生成器だよ。意図された情報が何なのか分かってないし、記事の例からして関わった人間も分かってなかったんだ。文章を愚鈍にして、全部同じ退屈で陽気だけどちょっと混乱したトーンにしちゃうのは、書き方として全然ダメだね。" userName="grey-area" createdAt="2025/10/21 19:11:11" color="#ff5c5c">}}




{{<matomeQuote body="「emダッシュ」の長年のユーザーだってさ。他のHNコントリビューターもそうらしいよ。ChatGPT登場前のemダッシュユーザーのリーダーボードがここにあるって。https://www.gally.net/miscellaneous/hn-em-dash-user-leaderbo…" userName="tkgally" createdAt="2025/10/22 00:49:42" color="">}}




{{<matomeQuote body="「〜だけでなく」とか「XはYなだけじゃない、AやBでもある」みたいな言い回し、なんでいつも使うんだろうね？LLMが登場する前からあのわざとらしい回りくどい表現は嫌いだったのに、今じゃどこにでもあるじゃん。LinkedInでそういう投稿が10個以上並んでて、マジで脳卒中になるかと思ったわ。" userName="itsnowandnever" createdAt="2025/10/21 19:39:20" color="">}}




{{<matomeQuote body="「意味を理解せずにありきたりなフレーズを吐き出すテキスト生成器で、陳腐で無意味な駄文を生み出す」って、それLLMのこと？それともSNSユーザーのこと？コンテンツの作成方法とその品質を混同しないでよ。「このくらい賢くないと（背が高くないと）投稿（乗車）できない」みたいなルールはとっくの昔になくなってるんだからさ。スピーカーズコーナーは今や世界中のステージで、書かれたものは全部本当だって信じられてるみたいだね。" userName="zer00eyz" createdAt="2025/10/21 19:39:48" color="#785bff">}}




{{<matomeQuote body="著者が執筆補助にLLMを使っちゃダメな理由って何？問題なのはツールを使うこと自体じゃなくて、どう使うかってことだろ。" userName="askafriend" createdAt="2025/10/21 17:45:32" color="">}}




{{<matomeQuote body="もしウォーターマークを入れたいなら（俺は入れないのは無責任だと思うけど、回避する奴がいてもそいつの勝手）、ゼロ幅スペースみたいな空白文字を戦略的に配置したり、genius.comが歌詞のGoogleクロールを捕まえるためにしたみたいにモールス信号で何かを綴ったりできるんじゃない？（あの時は左右の apostrophes だったと思うけど）。" userName="jazzyjackson" createdAt="2025/10/21 23:01:42" color="#38d3d3">}}




{{<matomeQuote body="まさにだからこそ、LLMはこういう手法をよく使うんだよ。すごく一般的なんだ。" userName="_AzMoo" createdAt="2025/10/22 11:05:42" color="">}}




{{<matomeQuote body="俺が言ってるのはLLMのことだけども、SNSも品質が低いのは一緒だね。そういうテキストの品質（の低さ）なんて、見れば一目瞭然だろ。それが分からないなら、俺にはもう助けられないよ。" userName="grey-area" createdAt="2025/10/21 20:52:30" color="">}}




{{<matomeQuote body="残念ながら、LLMはemダッシュの使い方にかなりムラがあるんだ。正しくないのにスペースを挟むことがよくあって、それが昔、人間だと誤解して指摘しちゃった原因にもなったな。" userName="jdiff" createdAt="2025/10/22 04:24:54" color="">}}




{{<matomeQuote body="みんなも経験あるみたいだけど、LLMの出力読んでると話し方や書き方が変わっちゃうよね。このままだと、LLMみたいに話し出す人が増えるかもって心配してるんだ。" userName="wholinator2" createdAt="2025/10/21 23:04:15" color="#785bff">}}




{{<matomeQuote body="emダッシュなんて簡単なフィルターで消せるけど、ちゃんとした文法に直すにはちょっとコードがいるよね。" userName="landdate" createdAt="2025/10/22 00:12:43" color="">}}




{{<matomeQuote body="みんなもCommon Crawlのデータを見てみなよ。https://data.commoncrawl.org/crawl-data/CC-MAIN-2025-38/segm...でやばいデータ見つけたんだけど、これって学習前に消されるはずだよね？Llamaモデルで試したら変な出力出たから、あんまり掃除されてないのかもね。" userName="andai" createdAt="2025/10/21 18:04:51" color="#38d3d3">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="Karpathyも言ってたけど、Common Crawlのデータってほとんどゴミなんだって。WSJの記事みたいな良いデータはめったになくて、モデルが何か学習できるのが奇跡みたいだね。" userName="dist-epoch" createdAt="2025/10/21 20:29:50" color="#ff33a1">}}




{{<matomeQuote body="LLMは教育コンテンツから早く学べるんだって。Common Crawlのデータは質が悪すぎて、学習の邪魔になるらしいよ。ネットのページってひどいデータばっかりだから、その中から良いデータを見つけるのが大変なんだよね。KarpathyのX（https://x.com/karpathy/status/1797313173449764933）とか、FineWeb-Eduの取り組み（https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb...）が参考になるよ。" userName="andai" createdAt="2025/10/21 22:39:33" color="#45d325">}}




{{<matomeQuote body="torrented ebooksの大量データも忘れないでね。これに関する記事もあるよ（https://www.tomshardware.com/tech-industry/artificial-intell...とhttps://www.classaction.org/news/1.5b-anthropic-settlement-e...）。" userName="WA" createdAt="2025/10/22 05:32:58" color="#785bff">}}




{{<matomeQuote body="これが、ちゃんとしたモデルを作るための“秘伝のタレ”だと思うんだ。" userName="nativeit" createdAt="2025/10/27 01:35:08" color="">}}




{{<matomeQuote body="今日のWSJのトップ記事見出しはこれだよ。「Paul Ingrassia’s ’Nazi Streak’」<br>「Musk Tosses Barbs at NASA Chie After SpaceX Criticism」<br>「Travis Kelce Teams Up With Investor for Activist Campaign at Six Flags」<br>「A Small North Carolina College Becomes a Magnet for Wealthy Students」<br>「Cracker Barrel CEO Explains Short-Lived Logo Change」。もしこれが質の高い学習データってことなら、俺たちやばいかもね。" userName="jojobas" createdAt="2025/10/21 23:30:06" color="#785bff">}}




{{<matomeQuote body="WSJの記事はだいたいよく書けてると思うよ。今日のニュースがどうでもいい内容なのは、彼らのせいじゃないし。" userName="anigbrowl" createdAt="2025/10/22 03:45:13" color="">}}




{{<matomeQuote body="WSJの編集部はマジで恥ずかしいと思うね。知的ぶってるけど、保守主義に媚びてるだけじゃん。" userName="dclowd9901" createdAt="2025/10/22 05:12:31" color="">}}




{{<matomeQuote body="編集部の編集方針とかテーマの選択は嫌いだけど、ニュース記事の書き方は技術的にうまいって言いたいのさ。" userName="anigbrowl" createdAt="2025/10/22 06:38:08" color="">}}




{{<matomeQuote body="時の試練に耐える著作物なんて、ごくわずかだよな。多分、本当の苦い教訓は、トレーニングデータの質って規模と反比例するってことなんじゃないか？技術力はあっても、それが実現できないってことなのかもな。" userName="stocksinsmocks" createdAt="2025/10/22 00:40:24" color="#785bff">}}




{{<matomeQuote body="「プリトレイン前にデータクリーニングでそういうコンテンツは削除されてる？」って？何の話をしてるのか確認してないけど、主要プロバイダーは最先端の分類器でそういうコンテンツを検閲・フィルタリングしてるはずだよ。それがダメなら、RLHFでそういう行動を抑えることもできるしね。Garbage in/garbage out（ゴミを入れたらゴミが出る）って言いたいんだろうけど、ちょっとでも優位性があるとしたら、そういうデータセットのフィルタリングと、Common Crawlみたいに無料じゃない、もっと大規模なデータソースを使うライセンスの購入なんだ。" userName="throwaway314155" createdAt="2025/10/21 18:16:41" color="#ff5c5c">}}




{{<matomeQuote body="「大規模データソースのライセンス購入」については、このNPRの記事を読んでみて。<br>https://www.npr.org/2025/09/05/g-s1-87367/anthropic-authors-..." userName="jedimastert" createdAt="2025/10/22 11:25:40" color="">}}




{{<matomeQuote body="LLMを大量のジャンクデータで学習させたら、悪くなったって？それが驚くような、あるいは面白い結果だとは思えないんだけど？どういうこと？" userName="Version467" createdAt="2025/10/22 06:55:48" color="">}}




{{<matomeQuote body="彼らはそのダメージを修復しようともしたんだよ、部分的にだけど。それに、科学ってのは仮説を経験的に検証する必要があるだろ？研究者の間でこの問題に注目を集めるには、研究して結果を共有するのが一番良い方法なんじゃないかな。" userName="nazgul17" createdAt="2025/10/22 07:05:19" color="#785bff">}}




{{<matomeQuote body="うん、それはわかるんだけど、こういう研究ってすでにたくさんあるんじゃないかな。「Garbage in, garbage out」なんて、ML分野全体のスローガンみたいなもんだし。この研究の貢献は、「脳腐敗」みたいなテキストがゴミだってことなんだろうけど、それが自明に思えても科学的な調査には値する。だとしたら、論文はそこに焦点を当てるべきだろ。「LLMが‘脳腐敗’する可能性？」みたいなクリックベイトなタイトルじゃなくてさ。この研究そのものには特に異論ないけど、注目集めのためのタイトルには不満があるな。" userName="Version467" createdAt="2025/10/22 10:12:15" color="#ff5733">}}




{{<matomeQuote body="わからないんだけど、これって単に悪いデータでLLMを学習させたら、悪いLLMになったって話？だったら、違うモデルを使えばいいじゃん？悪いデータで学習させなければいいし、RAGがぶっ壊れたら新しいセッションを始めればいいだけじゃないの？俺、なんか見落としてる？" userName="yieldcrv" createdAt="2025/10/22 07:09:36" color="">}}




{{<matomeQuote body="「脳腐敗」の概念って知ってる？ここでの肝は、良い脳に悪いデータを与えると悪くなるってことなんだ。赤ちゃん（真っ白な脳）に悪いデータを与えたら悪くなるのは当たり前だけど、これは「腐敗」についてなんだよ。" userName="chipsrafferty" createdAt="2025/10/22 13:42:00" color="#ff5c5c">}}




{{<matomeQuote body="「脳腐敗」の概念、わかる？要するに、悪いデータで学習させると（脳に悪い情報を与えると）悪くなっちゃうってことなんだ。" userName="ramon156" createdAt="2025/10/22 07:23:21" color="">}}




{{<matomeQuote body="一番シンプルな実験や観察でも役立つ結果が出ることはあるよね。自分の信念を疑わないと科学はできないしさ。今回の結果は特別じゃないけど、間違いなく新しい知識を生み出すし、もっと面白い発見につながるかもしれないよ。" userName="Sxubas" createdAt="2025/10/22 12:21:49" color="">}}




{{<matomeQuote body="モデルは何でも学習させられるって主張を見たことがあるから、それも確認する研究が必要だよね。" userName="Perz1val" createdAt="2025/10/22 07:53:20" color="">}}




{{<matomeQuote body="認知衛生って言うけど、LLMは認知してないよ。ひどい比喩だね。問題の根源を隠してる。プロバイダーがデータ調達をケチったせいで、LLMが偽物や著作権侵害のゴミでいっぱいになったんだ。" userName="themafia" createdAt="2025/10/21 20:47:46" color="#38d3d3">}}




{{<matomeQuote body="同様に、認知能力がないからこれは認知低下じゃないよ。せいぜい認知低下のシミュレーションだね。" userName="donaldihunter" createdAt="2025/10/21 21:12:53" color="#45d325">}}




{{<matomeQuote body="脳腐敗テキストは有害みたいだけど、脳腐敗動画はしばしばシュールで意味が濃いから、パフォーマンスを向上させる可能性もあるんじゃないかな（このドイツの脳腐敗分析 https://www.youtube.com/watch?v=-mJENuEN_rs&t=37s で議論されてるみたいに）。例えば、Švankmajerはまさにプロト脳腐敗だけど、美術館で見て考えるようなものだしね。つまり、ここで測ってるのがペラペラの記事か濃密な記事か、ってことなのに、脳腐敗って用語はちょっと話が逸れてる気がするな。" userName="gaogao" createdAt="2025/10/21 17:46:24" color="#ff5c5c">}}




{{<matomeQuote body="そうは思わないな。子どもの脳腐敗動画に関する研究[0]もあるけど、良い傾向を示しているわけじゃないよ。十分に“構築された”ものは脳腐敗の範囲には入らないだろうね。<br>[0]: https://www.forbes.com/sites/traversmark/2024/05/17/why-kids..." userName="f_devd" createdAt="2025/10/21 17:51:36" color="#785bff">}}




{{<matomeQuote body="ああ、シュルレアリスムとか構築されたものが初期のデータミックスには良くないと思うけど、中・後期の訓練データの一部なら妥当じゃないかな。あと、モデルを擬人化するのは多分良くないね。Cocomelonの主な悪影響は子どもたちがCocomelonしか見たがらなくなることだけど、大規模モデルの訓練では、訓練データの分布を選ぶ余地があまりないからね。" userName="gaogao" createdAt="2025/10/21 18:10:20" color="#785bff">}}




{{<matomeQuote body="もしメインのデータセットに脳腐敗が全く含まれていなければ、訓練後工程で注意深くごく少量の脳腐敗を加えることで特定の指標が改善する可能性はあると思う。でも、現在のLLMがどれだけのデータを消費し、どれだけが生産されて再び循環しているかを考えると、それが足りなくなることはないだろうね。" userName="f_devd" createdAt="2025/10/22 08:00:19" color="#ff33a1">}}




{{<matomeQuote body="だからこそ、AIが人々の操作に使われる現在の急増（アートも意図せず操作の一種だけど）は、技術的な情報処理装置としての誇大宣伝された使い方よりもずっと重要だと思う。LLMが作り出す脳腐敗は心配すべきだし、“人を楽しませる”ためのデザインもそうだ。擬人化も確かに怖いよね。" userName="moritzwarhier" createdAt="2025/10/21 17:52:41" color="#45d325">}}




{{<matomeQuote body="LLMの脳腐敗って、推論を飛ばしたり、意味内容より”人気”が指標になったりするって言うじゃん？<br>それって、人気コンテンツが過程をすっ飛ばして結論に飛びつくからでしょ。Twitterみたいなデータで学習したら当然じゃん。キュレーションされたモデルと比較してみたら？" userName="Animats" createdAt="2025/10/22 08:02:59" color="#ff33a1">}}




{{<matomeQuote body="これって結局、「ゴミを入れればゴミが出る」って話に、目を引くタイトル付けただけじゃないの？" userName="pixelmelt" createdAt="2025/10/21 15:33:08" color="">}}




{{<matomeQuote body="”Attention is all you need”だね。" userName="philipallstar" createdAt="2025/10/21 15:39:49" color="">}}




{{<matomeQuote body="今の世の中、”注目”が全てだよ。マーケティングも政治も資金調達も。<br>Trump、Musk、Altman、MrBeastを見ろよ。彼らはそれをわかってる。<br>ネガティブな注目でさえ、システムに割り込んでみんなに認知されるんだ。<br>これって社会のアルゴリズムだけじゃなく、宇宙の基本的な最適化アルゴリズムなのかもしれないね。" userName="echelon" createdAt="2025/10/21 16:29:10" color="#ff5733">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="ChatGPTが”Skibidi Toilet”とか「6 7」の参照ばかりするようになるって想像すると、ちょっと面白いよね。" userName="ashleyn" createdAt="2025/10/21 17:13:56" color="">}}




{{<matomeQuote body="最新のLLM訓練って、大量の”ゴミデータ”（良いものもあるけどね）を食わせてるわけじゃん。だから、それが自明に見えても、その問題点を指摘するのって大事だよね。" userName="wat10000" createdAt="2025/10/21 15:44:44" color="#ff33a1">}}




{{<matomeQuote body="LLMの”脳腐敗”なんて、ただの比喩だろ。<br>LLMは人間の認知を持ってないし、精神医学的な評価の対象じゃない。こんな記事が論文として出版されるなんて、学術界がAIブームで完全にジョークになってるって心配だよ。" userName="Barrin92" createdAt="2025/10/21 15:59:10" color="#ff33a1">}}




{{<matomeQuote body="最近はLLMに生データをそのまま投げ込んで、良い結果を期待する人なんていないんじゃない？<br>ほとんどのデータセットはフィルタリングされてるし、中にはかなりキュレーションされてるものもあるよ。" userName="CaptainOfCoit" createdAt="2025/10/21 15:48:10" color="">}}




{{<matomeQuote body="そんなに高度にキュレーションされてるとは思えないな。あらゆる分野の専門家が必要になるだろ。<br>コードみたいな一番キュレーションされるべき分野でさえそうなら、LLMへのパフォーマンス不安が増すよ。" userName="BoredPositron" createdAt="2025/10/21 16:10:32" color="">}}




{{<matomeQuote body="誰かこれ教えてくんない？俺South Parkでこういうエピソード見たけど、アメリカにいないから何が元ネタか全然わかんないんだよね。" userName="stavros" createdAt="2025/10/21 19:18:32" color="">}}




{{<matomeQuote body="これってブログ記事で、GithubとarXivに載ってたんだ。ネット中のデータ（合成データも！）をぶち込む人たちへの、キャッチーな警鐘って感じじゃない？" userName="bpt3" createdAt="2025/10/21 16:16:03" color="#ff5733">}}




{{<matomeQuote body="これって深い意味がないmemeだよ。元はあるけど、特定の何かを指してるって感じじゃないね。詳しくはこちら: https://en.wikipedia.org/wiki/6-7_(meme)" userName="Sparkle-san" createdAt="2025/10/21 20:15:08" color="#38d3d3">}}




{{<matomeQuote body="これ面白い視点だね。LLMが普及したら、AIと共に育って疑問を持つ能力が落ちた次の世代の人類ってどうなるんだろう？その次の世代は？あと、AIが作ったデータじゃない、人間が作ったオリジナルのデータで学習できない次のAIモデルはどうなるの？" userName="pluc" createdAt="2025/10/21 16:25:51" color="#38d3d3">}}




{{<matomeQuote body="お前、大事なこと見落としてるよ。ちょっと勉強した方がいいかもね。" userName="ghurtado" createdAt="2025/10/21 17:21:33" color="">}}




{{<matomeQuote body="OpenAIは、特定の分野の人間の専門家を雇って、オリジナルの学習コンテンツを作らせてるんだぜ。" userName="nradov" createdAt="2025/10/21 16:21:34" color="#ff5733">}}




{{<matomeQuote body="そう、LLMの学習は「ゴミ入れたらゴミが出る」ってやつだね。この論文で言いたいのは2点。<br>1. 悪いデータで事前学習しちゃうと、後からいくら追加学習してもダメってこと。構文は正しくても、変な癖（思考のスキップとか）がついちゃう。<br>2. 『悪いデータ』を分類するのも難しい。ここではLLMで分類するより、エンゲージメントで判断した方が信頼できたみたいだよ。" userName="icyfox" createdAt="2025/10/21 16:38:16" color="#ff33a1">}}




{{<matomeQuote body="彼らは命令がターミナルから来ているって受け入れて、それに従うようになるだろうね。" userName="iwontberude" createdAt="2025/10/21 16:32:59" color="">}}




{{<matomeQuote body="あー、なるほど。つまり子どもたちが言うようなやつなんだね。" userName="stavros" createdAt="2025/10/21 20:18:30" color="">}}




{{<matomeQuote body="大手ラボは専門家を雇って、合成データを慎重に構築・キュレーションしてるよ。ラベル付き非合成データ市場は年間約30億ドル規模。LLMがただのネット上のデータで訓練されてるって考え方は時代遅れだよ。<br>コーディングデータセットは、テスト合格やスタイル、解析ツールでの問題検出とかで品質評価しやすいから、キュレーションが比較的簡単なんだ。" userName="groby_b" createdAt="2025/10/21 16:46:04" color="#ff33a1">}}




{{<matomeQuote body="俺の14年間のコメント履歴を辿ればわかるけど、いつもこの形式で書いてるんだ。<br>LLMは俺（とHacker Newsのコーパス）を学習したんだよ、逆じゃないさ。" userName="echelon" createdAt="2025/10/21 19:09:07" color="">}}




{{<matomeQuote body="データセットはたぶん特定の分野™でほとんど構成されてると思うな。" userName="BoredPositron" createdAt="2025/10/21 16:27:27" color="">}}




{{<matomeQuote body="そうなの？今は”全部”ぶち込んでからファインチューニングするのが主流じゃないの？" userName="satellite2" createdAt="2025/10/21 18:04:36" color="#38d3d3">}}




{{<matomeQuote body="基質飽和を考慮に入れてないよ。もし単にスパムで邪魔して勝てるなら、みんなMacarenaのリミックスバージョンで踊ってるはずだよ。" userName="alganet" createdAt="2025/10/21 19:32:54" color="#ff5c5c">}}




{{<matomeQuote body="”どうやってこんなものが公開されるの？”ってのは、”Webで自己公開された”って意味でしかないよ。<br>この原稿は査読プロセスをまだ通過してないし、科学者が”出版された”（適切に）って呼ぶのは査読を通ったものだからね。" userName="jll29" createdAt="2025/10/22 05:17:48" color="#ff33a1">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
