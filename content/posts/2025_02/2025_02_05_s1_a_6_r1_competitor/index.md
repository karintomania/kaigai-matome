+++
date = '2025-02-05T00:00:00'
months = '2025/02'
draft = false
title = '6ドルでR1超え！？S1の実力とは？AI界隈騒然！'
tags = ["AI", "LLM", "機械学習", "モデル軽量化", "オンデバイスAI"]
featureimage = 'thumbnails/blue.jpg'
+++

> 6ドルでR1超え！？S1の実力とは？AI界隈騒然！

引用元：[https://news.ycombinator.com/item?id=42946854](https://news.ycombinator.com/item?id=42946854)

{{<matomeQuote body="inference scalingの議論で'Wait' hackが出てきたの、マジでシュールだよね。こんなシンプルな方法でパフォーマンスが上がるなんて、まだまだ見落としてる低コストでできることたくさんあるんじゃないかって思っちゃう。コンピュータサイエンスの進歩が、まるで魔法の呪文みたいになってるのが不思議で仕方ないんだけど。どうやったらそんな発想になるんだろう？" userName="mtrovo" createdAt="2025-02-05T16:48:02" color="#785bff">}}

{{<matomeQuote body="distillationとかquantizationで性能が大きく向上するってことは、モデルの仕組みをちゃんと理解できてないってことの証拠だと思うんだよね。もし理解できてたら、空間のsemantic structureを表現するのに必要なパラメータより多いパラメータでモデルをtrainする必要なんてないはずじゃん？でも実際には、パラメータが少ないdistilledモデルでも元のモデルと遜色ない性能が出せる。まだまだ美味しい発見がありそうだよね。" userName="xg15" createdAt="2025-02-05T19:13:11" color="#ff5733">}}

{{<matomeQuote body="distillationがうまくいく理由の一部は、The Lottery Ticket Hypothesis（https://arxiv.org/abs/1803.03635）で説明できるらしいよ。でも、もし理解が正しければ、小さいネットワークを最初からtrainできるってわけじゃないんだよね。初期の大きいネットワークにたくさんのランダム性が必要で、一部のニューロンが”winning”な状態になる必要があるんだって。そして、それらのwinningなサブシステムを小さいネットワークにdistillできる。<br>人間の脳でも同じようなことが起こってるみたいで、それはSynaptic pruning（https://en.wikipedia.org/wiki/Synaptic_pruning）って呼ばれてる。Wikipediaからの引用（https://en.wikipedia.org/wiki/Neuron#Connectivity）:「3歳児の脳には約10^15個のシナプスがあるって推定されてる。この数は年齢とともに減少し、成人期までに安定する。成人のシナプスの推定値は10^14から5x10^14個の範囲で変動する。」" userName="ZeljkoS" createdAt="2025-02-05T23:42:01" color="#38d3d3">}}

{{<matomeQuote body="もっと'成熟'したモデルが、少ないパラメータで、より良いbenchmarkスコアを出す日が来るかもね。" userName="3abiton" createdAt="2025-02-06T05:19:04" color="">}}

{{<matomeQuote body="「Better」だけど、distilled元になったモデルよりは良くないってことだよね、少なくとも僕の理解では。" userName="raducu" createdAt="2025-02-06T08:25:35" color="">}}

{{<matomeQuote body="それって、子供の脳の仕組みにも似てると思うな。親や環境が良ければ良いほど、子供の進化も良くなるってことだよね😊" userName="salemba" createdAt="2025-02-06T13:20:23" color="#45d325">}}

{{<matomeQuote body="LLMのdistilledモデルを写真のJPEGみたいだって言うアナロジーが好きだな。かなり良い、いや、すごく良いかもしれないけど、やっぱりlossyなんだよね。<br>あなたが提起してる疑問は、もっと小さいサイズで、より良い解像度（元の再現性）を得られる新しい圧縮方法はないかってことだと思う。" userName="MR4D" createdAt="2025-02-06T04:42:43" color="#ff5733">}}

{{<matomeQuote body="＞in that a distilled model of an LLM is like a JPEG of a photo<br>＞それ面白いアナロジーだね。僕はいつもLLMのhidden states（とweightsとbiases）を、training dataの圧縮版だって思ってたんだ。" userName="umeshunni" createdAt="2025-02-06T06:30:30" color="#ff5733">}}

{{<matomeQuote body="圧縮って、現象を再現するために必要な最小限のinformationを見つけることじゃない？つまり、自然法則を発見すること。" userName="timschmidt" createdAt="2025-02-06T13:42:13" color="#38d3d3">}}

{{<matomeQuote body="最小限の複雑さの説明を見つけることが、自然法則を見つけることの本質じゃないと思うな。Occam’s razorとしては良いけど、特に理論が新しい場合、最小限のモデルが何なのかはっきりしないことが多いし。それでも自然法則たりえるし、重要なのは自然現象の予測可能性だと思う。例えば、Lagrangian mechanicsの方がNewtonianより少ない第一原理で済むって言えるけど、Newtonの法則も自然法則として認められてるよね。" userName="t_mann" createdAt="2025-02-06T17:43:01" color="#ff5c5c">}}

{{<matomeQuote body="たぶん俺がただの計算主義者だからかもしれんけど、宇宙の最も正確なモデルってのは、一番少ないパラメータで一番正確な予測をするやつだと思うんだよね。NewtonのモデルはEinsteinのより予測精度が低いのは証明されてるし（違う例え使ってごめん）、精度がそこまで重要じゃない場面では役に立つけど、真のGUTを探すときにはパラメータの数はあんま関係ないかなって。俺の理解だと、宇宙の真の構造の正確なモデルは、ありとあらゆることを正確に予測できる一番シンプルな方法になるはず。いつも通り、参考資料はこれね。https://www.sas.upenn.edu/~dbalmer/eportfolio/Nature%20of%20...。どんどん精度は落ちるけど、計算複雑性の階層を上がっていくにつれて、役に立つモデルはたくさんあると思う。Lossy compressionはまさにその一つ。" userName="timschmidt" createdAt="2025-02-06T18:49:09" color="">}}

{{<matomeQuote body="Lagrangian mechanicsはNewtonと全く同じ予測をするんだよね。しかも、3つの法則じゃなくて、たった一つの原理（最小作用の原理）から始まるから、理論としてはよりスパースだと思う。計算が楽になるってのが主な理由で、特に複雑なシステムだとね。相対性理論がない世界では、どっちも最高の予測をするけど、Newtonの法則の方が先に発見された。Lagrangian mechanicsが見つかったら、Newtonの法則は自然法則じゃなくなるの？普通の物理のカリキュラムだとそうはならないと思うよ。Newtonを最初に教えて、Lagrangianは後回しにするのが普通だし、数学的にも難しいし。" userName="t_mann" createdAt="2025-02-06T22:03:49" color="#ff5c5c">}}

{{<matomeQuote body="「最小作用の原理が基礎にある」ってだけじゃ、Lagrangian mechanicsがよりスパースな理論だとは言えないと思う。<br>Newton力学とLagrangian mechanicsに共通していることとして、Minkowski spacetimeなのか、Galilean spacetimeなのかを指定する必要がある。<br>相対性物理学が登場する前は、空間はユークリッド空間だって誰もが思ってた。Newton力学から相対論的力学への移行は、時空のmetricの移行だった。<br>今から振り返ると、Newtonの第一法則はmetricを主張していると認識できる。慣性運動をしている物体は、等間隔の時間で等距離の空間を移動するってこと。<br>時空のmetricの主張を広げると、位置ベクトル、速度ベクトル、加速度ベクトルは時空のmetricに従って加算される、とできる。<br>そうすると、Newton力学を定式化するには、時空のmetricとNewtonの第二法則があれば十分。<br>Hamiltonの停留作用はNewtonの第二法則の対になるもの。Newton力学と同様に、運動の理論を表現するには、metricを指定する必要がある。Galileo metricかMinkowski metricかをね。<br>Lagrangian mechanicsを定式化するには、停留作用を基礎にするだけじゃ不十分で、metricを指定する必要がある。<br>だから、Lagrangian mechanicsはスパースじゃない。Newton力学と同等。<br>一般的に言うと、Newton力学とLagrangian mechanicsの変換は双方向。<br>Newtonの定式化とLagrangianの定式化の切り替えは、デカルト座標から極座標への切り替えに似てる。問題の性質によっては、どちらかの定式化がより効率的な場合があるけど、同じ物理現象を扱ってる。" userName="Cleonis" createdAt="2025-02-08T21:05:28" color="#ff5733">}}

{{<matomeQuote body="君の方が詳しいみたいだけど、第一法則はmetricを誘導する以上のことをしてる気がするんだよね。慣性を公理として仮定してると思ってた。<br>複雑さの考え方もいろいろあるし。Newton力学は、特に複雑なシステムでは、あちこちに力を導入する必要があるから、ちょっとアドホックな感じがする。Lagrangian mechanicsは、そういう導入が少なくて済むことが多いし、より少ない方程式と項で記述できることが多い。より少ない『要素』で同じ現象を説明できるなら、Occam’s razor的にそっちの方が有利な気がする。" userName="t_mann" createdAt="2025-02-09T00:25:21" color="#45d325">}}

{{<matomeQuote body="モデルがどう動くのか、まだちゃんと理解できてないんだよね。<br>仕組みは理解してるけど、使い方が最適化されてないだけだと思う。<br>例えば、ICE車やEV車の仕組みを大体理解してる人がいるとする。ユーザーインターフェースが全然違っても、数分でどんな車でも運転できるようになる。<br>でも、それでレースしたり、ドリフトしたり、難しい地形を運転できるわけじゃない。車が物理的に可能だとしてもね。" userName="teruakohatu" createdAt="2025-02-05T21:13:51" color="">}}

{{<matomeQuote body="例えがあんま良くないかも。Deep learning systemsの仕組みは、根本的に理解できてないんだよね。訓練して評価するブラックボックスみたいなもんだから。MLのイノベーションってのは、大金持ちの魔法使いが「うーん」を「待て」に変えて、何が起こるか見てるようなもん。<br>違うsamplerが役に立つかな？さあ、試してみよう。小さいdatasetが役に立つかな？さあ、試してみよう。5000日間モデルを訓練したら役に立つかな？さあ、試してみよう。<br>車の技術はそれとは真逆で、完全にホワイトボックス。熱力学の法則とかで定義・説明できる要素で構成されてる。" userName="gessha" createdAt="2025-02-05T22:04:54" color="">}}

{{<matomeQuote body="＞_fundamentally_ don’t understand how deep learning systems works.<br>量子色力学がどう動くのか理解してないって言うようなもんだよ。理解してる人はほんの一握りだし、大衆向けにわかりやすく説明できるような知識じゃない。<br>古いCNNがどう動くか調べてみなよ。視覚的にわかりやすい資料がたくさんあるよ。<br>LLMについてもそうなると思うけど、今はまだ分野の進歩が早いから、そういう資料を作る価値がないんだよ。そういう人たちの時間は、LLMを改善するために使った方がいいからね。<br>今の進歩の速さを見てると、LLMの仕組みをちゃんと理解してる人は絶対にいると思う。サルがGPUに物を投げつけてるだけじゃない。" userName="raducu" createdAt="2025-02-06T08:36:47" color="">}}

{{<matomeQuote body="コンピュータビジョンのDeep networkをたくさん訓練したことがある身として言うと、下位レイヤーがどう動くかのクールな可視化はできるけど、上位レイヤーがどう動くかは全くわからん。直感は、たくさんのnetworkを訓練して、ハイパーパラメータ、データのシャッフル、activationなどを試行錯誤して得られる。マジで大変。<br>もし理論があるなら、Karpathyみたいな先生みたいな人が、凡人の院生とか熱心なアマチュアのために説明してるはず。<br>＞The kind of progress being made leads me to believe there absolutely ARE people who absolutely know how the LLMs work and they're not just a bunch of monkeys randomly throwing things at GPUs<br>権威的な意見としてじゃなくて、面白がってる内部の人間として言うけど、MLの院生と一週間過ごしたら、サルがGPUに物を投げつけてるだけじゃないって言う人がいたら笑っちゃうと思うよ。" userName="gessha" createdAt="2025-02-06T13:03:22" color="#ff33a1">}}

{{<matomeQuote body="単純にこういうことかもね。https://youtube.com/shorts/7GrecDNcfMc<br>これが何層も重なってるだけ。深いメカニズムじゃない。それがどう動くかは理解できるけど、そんな小さいメカニズムが脳内で起こってること全てに関わってるなんて、想像もできない。<br>理解できてないって言うより、その先にあるレベル。そんな単純なことが、スケールアップしただけでこんなことになるなんて、想像できないんだ。" userName="bloomingkales" createdAt="2025-02-06T13:29:11" color="">}}

{{<matomeQuote body="それってただのスケールじゃない？小さいLLMでも、車より多くの部品があるじゃん。<br>LLMは経済学、心理学、政治学みたいなもんだと思う。説明可能な中核となる科学があるかもしれないけど、システムが複雑すぎて、質問を定義することすら難しい。" userName="brookst" createdAt="2025-02-06T05:14:30" color="">}}

{{< details summary="もっとコメントを表示（1）">}}
{{<matomeQuote body="もっとデカいICEエンジン（コンテナ船のエンジンみたいな）を作っても、全体の仕組みは理解できるじゃん？パーツは増えるかもしれないけど、ICEエンジンの構造は変わらないし。でもニューラルネットワークって、大きくても小さくても、何が起きてるのか全然わかんないんだよね。重みとかバイアスとか、活性化とか勾配とか、全部見てもマジで何もわからん。逆に、経済学とか心理学、政治学が難しいのって、人の頭開けて何を考えてるか測れないからじゃん？" userName="gessha" createdAt="2025-02-06T13:08:43" color="">}}

{{<matomeQuote body="次のトークンがどう選ばれるかはわかるけど、それを繰り返すことでなんでそんな能力が出てくるのかはわかんないんだよね。創発的な挙動がどう生まれるのか、マジで理解できてない。" userName="spiorf" createdAt="2025-02-05T21:58:02" color="#ff5c5c">}}

{{<matomeQuote body="なんか1900年代に戻ったみたいだよね。誰かの賢いアイデア（と実装）が、Fordの組み立てラインとか、Taylorの石炭をすくうシャベルの最適化みたいに、めっちゃパフォーマンス向上につながるみたいな。" userName="koala_man" createdAt="2025-02-05T17:18:11" color="">}}

{{<matomeQuote body="12ヶ月後の未来を想像してみてよ。2025年2月5日のこの記事が、もう古臭く感じるんだろうね。加速はどんどん増してるし。たぶん、もうすぐ再帰的に自己改善するAI、つまりAI研究をするAIが登場するんじゃないかな。そしたら加速の速度自体が加速するよね。バカみたいだけど、特異点は近いってことだよ。超人的なAIが、ほんの数年以内に登場しそう。マジで怖い。" userName="cubefox" createdAt="2025-02-05T17:13:46" color="#ff5733">}}

{{<matomeQuote body="ここ3ヶ月で起きてることに恐怖を感じてない人は、マジで何が起きてるのか理解してないんじゃないかな。俺は、生きてるうちに本当のAIを見れるとは思ってなかったのに、死ぬ前に見れるかもって思って、さらに10年以内に可能かもって思って、今じゃ3年以内に実現するかもって思って、もしかしたら今年見れるかもって思ってる。つい6ヶ月前までは、pre-trainingが停滞してるんじゃないかとか、限界に達したんじゃないかって言われてたのにね。" userName="zoogeny" createdAt="2025-02-05T21:12:06" color="#ff5733">}}

{{<matomeQuote body="これは主に、”知性”にアイデンティティを置いてるけど、現実世界に根ざしてない人たちを怖がらせてるんだよね。具体的に何を恐れるべきなのか、ちゃんとした説明を見たことがないんだよね。寝室でできるスーパー兵器？アルゴリズムによるプロパガンダ？でもそれらを作るのは人間じゃん。そして”人間のアラインメント”問題は、カインとアベルの時代から未解決なんだよ。AI単体じゃ、ただの画面上の文字だよ。" userName="pjc50" createdAt="2025-02-06T15:18:30" color="#785bff">}}

{{<matomeQuote body="＞without grounding in the real world.<br>”現実世界に根ざしてない”<br>＞I've yet to see really good articulations of what, precisely we should be scared of.<br>”具体的に何を恐れるべきなのか、ちゃんとした説明を見たことがないんだよね”<br>Bedroom superweapons?<br>失業の機会の喪失と不平等の拡大は、現実世界の懸念事項だよ。UBIは勝手にやってこないし。" userName="danans" createdAt="2025-02-06T15:46:18" color="">}}

{{<matomeQuote body="＞The intelligence that will be available to the average technically literate individual will be frightening.<br>”技術的に読み書きができる平均的な人が利用できる知性は恐ろしいものになるだろう”<br>怖いのはそこじゃないんだよね。平均的な雇用者が利用できる、スケールが違う知性が怖いんだよ。資本家ごっこしてる人は多いけど、マジモンの資本家はほんの一握り。一般の人々の幸福よりも、一部の資本家の利益を優先するイデオロギーも文化的な枠組みも存在しないんだよね。AI、特に加速するAIは、生活のために働く必要がある人にとっては悪いニュースだよ。Star Trekみたいなファンタジーにはならない。経済の段階的な変化が起こり、俺たち（とほとんどの消費者製品企業）は衰退していくことになる。" userName="palmotea" createdAt="2025-02-05T22:26:42" color="#38d3d3">}}

{{<matomeQuote body="マジで同意だし、怖いよ。俺の問題は、もしほとんどの人が働けなくなったら、誰がAIで作られた製品やサービスの代金を払うんだ？「AIを使えば週末にSaaSを作れる」とか「AIがエンジニアの仕事を奪う」みたいな話をよく聞くけど、どっちも本当かもしれない。でも多くのSaaSは、エンジニアがお金を払ってくれるから成り立ってる。もしエンジニアがいなくなったら、多くのSaaSも消える。潜在的な顧客を食い尽くしたら、SaaSを急いで作る意味ないじゃん。" userName="101008" createdAt="2025-02-05T23:02:51" color="#785bff">}}

{{<matomeQuote body="＞My problem is: if most people can't work, who is going to pay for the product/services created with IA?<br>”もしほとんどの人が働けなくなったら、誰がAIで作られた製品やサービスの代金を払うんだ？”<br>それらの多くも潰れるだろうね。多くの人が厳しい現実に直面すると思うよ。今の社会と経済が本当に価値を置いているのは、所有権と支配権を持つエリートと、エリートにとって直接的または間接的に価値のあるものを提供する人々だけ。AIによって椅子取りゲームが繰り広げられ、技術の進歩とともに経済参加者が次々と排除され、最終的にはごくわずかな人々が膨大な資源と能力を支配し、個人的な気まぐれのために利用されるようになるだろう。残りの俺たちは、都市のネズミみたいに、社会の片隅で細々と暮らし、邪魔者扱いされ、人目につかないように、食べ残しを漁り、”害虫駆除”の対象になるかもしれない。" userName="palmotea" createdAt="2025-02-06T05:00:40" color="#38d3d3">}}

{{<matomeQuote body="うちの社会と経済がマジで評価してるのは、オーナーシップと支配権を持ってるエリートだけだって？<br>それマジ違うくね？　でかい会社はみんな、アメリカのすげー多い中間層向けに商売してるから金持ちなんだよ。そこが一番儲かるんだって。" userName="kortilla" createdAt="2025-02-06T13:34:16" color="">}}

{{<matomeQuote body="＞それマジ違うくね？　でかい会社はみんな、アメリカのすげー多い中間層向けに商売してるから金持ちなんだよ”<br>いや、マジ本当だって。でも、なんでそう思うのかは分からなくもないよ。ちょっと聞くけどさ、「すげー多いアメリカの中間層」が自動化で置き換え可能になったら、会社は１）中間層の需要を支えるために労働者を雇い続けるか、それとも２）株主に金をさらに渡すために労働者をクビにするか、どっちだと思う？<br>答えは当然２番でしょ。それは何度も証明されてるじゃん（例えば、”Rust Belt”がどうしてそうなったか）。<br>＞そこが一番儲かるんだって”<br>今はそうだけど、将来は分かんないね。AI（もし壁にぶち当たらなければ）がそれを変えると思う。すぐには無理でも、時間とともに。" userName="palmotea" createdAt="2025-02-06T15:16:04" color="#785bff">}}

{{<matomeQuote body="そういう人たちはただの余剰人員になるだけだよ。支配階級の邪魔にならなければ放置されるし、邪魔になったら処分される。歴史の常だね。" userName="immibis" createdAt="2025-02-05T23:42:49" color="">}}

{{<matomeQuote body="それって誤謬じゃね？ほとんどの人が何もしない高度な経済なんてありえないよ。お金は流れ続けないと。もし経済がいくつかのデータセンターがおしゃべりしてるだけになったら、支配階級はどうやって儲けるんだよ？" userName="lodovic" createdAt="2025-02-06T06:30:01" color="#ff33a1">}}

{{<matomeQuote body="R1が推論で「Wait、」をよく使ってるのに気づいたんだけど、そのトークンに何か特別な意味があるのかな？" userName="ascorbic" createdAt="2025-02-05T20:18:49" color="">}}

{{<matomeQuote body="陰謀論っぽく聞こえるかもしれないけど、NVIDIAとかAIのスタートアップは、そういう発見を追求したり公開したりしない方が都合がいいんだよ。もし巨大なモデルとかGPUが必要なくなったら、AIはただのオープンソースのプログラムが暇なPCで動いてるだけになっちゃうからね。<br>AIはNVIDIAにとって、GPUマイニングが衰退した時の救命ボートだった気がする。当分はその後が見えない。" userName="BobbyTables2" createdAt="2025-02-06T03:29:55" color="">}}

{{<matomeQuote body="NVIDIAの未来は明るいと思うよ。<br>有能なLLMをオンプレミスとか自宅で動かせる時代が来てるし。<br>DeepSeek（とその後のもの）がなかったら、NVIDIAのProject Digitsみたいなものを使う理由がない。" userName="philipswood" createdAt="2025-02-06T03:56:07" color="#785bff">}}

{{<matomeQuote body="R1 1.5bをGPUもNPUもない4～5年前のIntel NUCで動かせるんだけど、コアの半分を使って、返信速度は…実用的だよ。<br>モデルがより効率的になり、蒸留が向上するにつれて、LLMを本格的に使うための最低限必要なハードウェアが4090から、多くの人がすでに持っているものに変わった。<br>Digits boxは確かに魅力的だけど、正直、必要かどうか分からないな。" userName="Arn_Thor" createdAt="2025-02-06T06:22:30" color="#785bff">}}

{{<matomeQuote body="モデル蒸留を”盗み”だなんて絶対に思わないなー。科学研究の精神に反するし、それにどのテック企業も、オレが盗みだと思うことを定義する許可なんてとっくに失ってるし。" userName="advael" createdAt="2025-02-06T07:36:08" color="">}}

{{<matomeQuote body="せいぜい不正コピーってとこじゃね？<br>それにしても、OpenAIが著作権ルールをごまかしてるって文句言うのは皮肉だよね。" userName="eru" createdAt="2025-02-06T13:34:21" color="#785bff">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（2）">}}
{{<matomeQuote body="修正第一条は言論の自由だけじゃなくて、読む権利も保障してるんだよなー。問題は、AIにその権利があるかどうか、だ。" userName="downrightmike" createdAt="2025-02-06T15:47:18" color="">}}

{{<matomeQuote body="AIがただ読んでるだけなら、こんなに議論にはならないだろうね。そして、役にも立たないだろうけど。AIが取り込んだコンテンツを基に、独自の派生物を作り出すのが問題なんだよ。" userName="organsnyder" createdAt="2025-02-06T17:41:00" color="#785bff">}}

{{<matomeQuote body="今まで誰も答えたことのない質問に答えることって、派生的な作品じゃないの？人間が歌のパロディを作ったり、新しい音楽が過去の何かに影響を受けたりするのと同じじゃない？" userName="boxcake" createdAt="2025-02-06T19:42:14" color="">}}

{{<matomeQuote body="この議論、マジで意味不明。人間は新しい、自発的な考えを生み出すじゃん。AIにはそれがない。人間のコメントは過去のデータに影響されてるとしても、そのスタイルは独特で意図的。AIには意図的な思考はないし、新しい考えもない。せいぜいモデルの作者が導入した疑似乱数があるくらい。" userName="nrabulinski" createdAt="2025-02-06T21:26:00" color="#ff5c5c">}}

{{<matomeQuote body="それな。<br>この議論、マジ意味不明。<br>人間がAIとは全く違う方法で”新しい、自発的な考え”を生み出してるって証拠はない。今のAIは無理でも、超えられない壁があるって仮説を支持する証拠もない。<br>＞GenAIに無限の時間を与えても、独自のスタイルは生まれないって？<br>もし人間が質的に違うことができる仕組みを知ってるなら、ノーベル賞もん。AIモデルが制限されてるチューリング計算能力を超える方法なんてない。<br>そもそも”新しいアイデア”を形式化する方法すら分からん。" userName="vidarh" createdAt="2025-02-06T23:47:19" color="#ff33a1">}}

{{<matomeQuote body="OpenAIみたいな企業の擁護者がよく言うこの議論は、知的財産の本来の目的、ひいては法の目的を見失ってる。道徳的、法的問題を抽象的な存在論的問題にすり替える、よくある誤魔化しだよ。<br>人間の脳とAIの学習メカニズムが似てるかってのは哲学的な問題で、知財法が作られた理由とは関係ない。知財法は人間の創作活動を経済的に促すためのものなんだから。" userName="advael" createdAt="2025-02-07T07:55:19" color="#ff5c5c">}}

{{<matomeQuote body="道徳や法律の話をしてるんじゃないんだ。人間が魔法のように特別な存在だって主張してる人に反論してるだけ。話をそらしてるって言うなら、そいつに言ってくれ。" userName="vidarh" createdAt="2025-02-07T17:29:28" color="">}}

{{<matomeQuote body="なるほどね。でも多くの人が同じような主張をしてるみたいだけど、それ自体も怪しいんだよねー。人間の学習について完全にはわかってないし、機械学習の仕組みがそのまま当てはまるって仮定も、根拠が必要なのにされてないし。そもそも、ここで大事なのは存在論的な問題じゃないってことを、もっと指摘していくべきだよね。" userName="advael" createdAt="2025-02-08T12:59:35" color="">}}

{{<matomeQuote body="＞さっきの主張は怪しいって言ったけど、それは人間の学習を完全に理解してなくても言えることなんだよね。ボクの主張は、Turing計算可能な範囲を超える計算の証拠がないってことだけに基づいているんだ。<br>そんな計算が見つかったら物理学も論理学も数学も覆るし、ノーベル賞もんだよ。<br>ちゃんと根拠も示したじゃん。単純な話で、Turing計算可能な範囲を超える関数は知られてないし、Turing完全なシステムならどんな関数でも計算できる。<br>拡張されたChurch Turingのテーゼによれば、既知の物理法則の範囲内では、自然システムも同じことが言えるんだ。<br>つまり、未知の物理法則でも見つけない限り、人間の脳は電子計算機と同じ限界を持つコンピューターでしかないってこと。<br>電子計算機にはできないような新しいものが人間から生まれるって考えは、根拠のない仮説だよ。<br>＞存在論的な問題は重要じゃないって言うけど<br>キミにとってはそうかもしれないけど、ボクにとってはキミが議論したいことはどうでもいいんだ。" userName="vidarh" createdAt="2025-02-10T08:34:31" color="">}}

{{<matomeQuote body="認知＝計算って決めつけてたら、そりゃそういう結論になるよね。でもその前提が間違ってるんだよ。脳がコンピューターだって決めつけてる時点で、結論も同じになるのは当たり前じゃん。一番重要な部分の根拠がないから、真剣に受け止める気になれないな。" userName="advael" createdAt="2025-02-17T05:36:13" color="">}}

{{<matomeQuote body="＞言い換えれば、現在の状態に対するTuring計算可能な関数としてってことだよね。<br>もっと詳しく説明する必要があるよ。Turing計算可能な関数は停止して、最終的に値を返さないといけないんだ。（そして、停止することも証明する必要がある。）<br>＞AIモデルが制限されているTuring計算能力を超えるメカニズムは知られていない。<br>どのAIモデルの話をしてるの？コンテンツを作る時、人間は今のAIモデルよりもはるかに多くの計算資源を使えるんだよ。例えば、バケツの水をかき混ぜて、そこからインスピレーションを得ることだってできる。今のAIモデルには、バケツの水をシミュレートする計算資源もないし、ロボットアームやカメラを使って実際に触れ合うこともできない。" userName="eru" createdAt="2025-02-07T00:16:32" color="#785bff">}}

{{<matomeQuote body="＞もっと詳しく説明する必要があるよ。Turing計算可能な関数は停止して、最終的に値を返さないといけないんだ。（そして、停止することも証明する必要がある。）<br>細かいことを言うなよ。停止しない関数でも、ステップ関数とループに分解できるんだから。大事なのはステップ関数のほうでしょ。それに、人間の人生はいつか終わるんだから、人間の思考プロセスも停止する関数として扱える。<br>＞どのAIモデルの話をしてるの？コンテンツを作る時、人間は今のAIモデルよりもはるかに多くの計算資源を使えるんだよ。例えば、バケツの水をかき混ぜて、そこからインスピレーションを得ることだってできる。今のAIモデルには、バケツの水をシミュレートする計算資源もないし、ロボットアームやカメラを使って実際に触れ合うこともできない。<br>AIモデルが計算資源を持ってるわけじゃない。ただの数字の集まりでしょ。重要なのは実行環境に縛られない、理論上の計算能力の話だよ。<br>それに、Church-Turingのテーゼは時間とストレージが無制限にあることを前提としてるし。" userName="vidarh" createdAt="2025-02-07T17:33:47" color="">}}

{{<matomeQuote body="そうそう、だからChurch-Turingのテーゼよりもっと強いものが必要なんだよね。<br>https://scottaaronson.blog/?p=735<br>「哲学者が計算複雑性を気にするべき理由」を見て。<br>要するに、脳が短い時間（例えば多項式時間）でできることは、コンピューターも多項式時間でできるってこと。<br>これをテーゼにするなら、こんな感じかな。「物理的に実現可能な計算機（脳を含む）は、BQPがすでに許可している以上のことを多項式時間で行うことはできない」<br>https://en.wikipedia.org/wiki/BQP" userName="eru" createdAt="2025-02-09T04:45:00" color="#785bff">}}

{{<matomeQuote body="もしコンピューターの方が効率が悪いって言うなら、まだ議論の余地があるかもしれないけど、脳の方がコンピューターよりも能力が高いって主張してる人は、効率の問題じゃなくて、脳には本質的にもっと高い能力があるって言ってるんだから、遠回りな議論だよ。" userName="vidarh" createdAt="2025-02-10T08:49:05" color="">}}

{{<matomeQuote body="＞人間は新しい、自発的な思考を生み出す<br>そうは思わないな。メディアを見てみればわかるけど、映画やテレビのプロットは「男の子と女の子が出会うPocahontas」みたいなものばかりじゃん。<br>モデルは静的なデータセットしかないから新しいものを作れないって言うかもしれないけど、人間だって経験から得た有限な知識しか使えないんだから、同じことだと思う。例えば、ハイファンタジーの世界でも、エルフは耳が違うだけの人間でしょ？ゴブリンは肌が緑色の小さい人間だし。ドラゴンはただの大きいトカゲ。ミノタウロスは人間と牛のハーフ。人間はほとんど新しいアイデアを生み出してないんだ。人間が何かを創造したとしても、それは既存のものの焼き直しでしかない。<br>人間が全く新しい経験をすることはほとんどないと思う。<br>無料のchat gptにファンタジー種族を作らせてみても、既存の概念に基づいたものばかりが出てくる。<br>https://imgchest.com/p/lqyeapqkk7d" userName="fennecfoxy" createdAt="2025-02-10T15:26:41" color="#ff5733">}}

{{<matomeQuote body="＞決定論と自由意志の両立はまだ議論の余地があるよね。人間は実際には何も「創造」していない可能性も十分にある。<br>決定論と自由意志はここでは関係ないんじゃない？<br>P=NPじゃない限り、疑似乱数システムと真の乱数システムを区別する方法はないし。<br>それに、人間の決定論とAIの決定論は熟慮とは関係ないと思うよ。<br>最近のAIモデルは熟慮することもできるんだ。<br>少なくとも、いくつかの意味ではね。<br>＞自由っていうのは、偶然に左右されるんじゃなくて、理由によって自分で決めることだからね。<br>人によって定義が違うよね。どれも納得できるものではないけど。" userName="eru" createdAt="2025-02-07T00:20:26" color="">}}

{{<matomeQuote body="＞決定論じゃ熟慮なんてありえないって。<br>マジレスすると、宇宙の法則は全部決定論的だよね。（量子力学も含めて。）人間も物理法則に従ってるっしょ。<br>（一応説明：量子力学は理論としては完全に決定論的で線形なんだよね。コペンハーゲン解釈みたいな古い解釈はランダム化を使うけど、解釈は理論自体に影響しないし。多世界解釈みたいな広く受け入れられてる解釈は決定論を維持してるし。）<br>あと、ニューラルネットは普通サンプリングされるし、マジで良い乱数生成器（物理乱数生成器とか）も使えるよ。でも、それでニューラルネットの能力が変わるとは思えないけど。" userName="eru" createdAt="2025-02-07T13:57:58" color="#ff5c5c">}}

{{<matomeQuote body="それ、まさに彼ら（と俺）の主張じゃん。AIと違って人間は「新しいもの」を作れるって言ってる人に対してね。「新しいもの」を「現在の世界の状態から決定論的に導き出せないもの」として解釈しないと意味ないってこと。純粋な決定論的アルゴリズムと人間の意識を区別しようとしてるんだよ。" userName="vidarh" createdAt="2025-02-07T17:44:35" color="#45d325">}}

{{<matomeQuote body="まあね。憲法全体とか修正条項は、何かをする権利を与えてくれるわけじゃないんだよね。やりたいことはいつでも自由にできる。憲法は政府が何を阻止できるかを定めてるんだ。" userName="INGSOCIALITE" createdAt="2025-02-07T02:41:23" color="">}}

{{<matomeQuote body="ここってUSの’First Amendment’（修正第一条：表現の自由）は関係なくね？ DeepSeekは中国にあるし。" userName="eru" createdAt="2025-02-07T00:11:05" color="">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（3）">}}
{{<matomeQuote body="それって違法ですらないんじゃない？少なくともアメリカでは、AIの出力は著作権保護の対象にならないし。" userName="antimatter15" createdAt="2025-02-06T20:20:59" color="#38d3d3">}}

{{<matomeQuote body="それよりも、無料APIを使ったか有料APIを使ったかが問題だと思うな。<br>OpenAIとか他の会社が、計算時間やアクセスに対してお金をもらってるなら、他のモデルが生成したコンテンツを使うのはフェアだと思う。なぜなら、それはアクティブで継続的なコストであって、パッシブなコストじゃないから。<br>俺のくだらないツイートとかHNの投稿で学習されたとしても、それはパッシブなコストだから別に良い。自分の時間を使って発言して、それなりのメリット（部族的な社会的交流）を得てるから、もう価値は得てるんだ。" userName="fennecfoxy" createdAt="2025-02-10T14:37:14" color="#ff5733">}}

{{<matomeQuote body="そうかもね。でも、最先端を維持するには、お金が必要だもんね。薬の研究と似たような問題かも。" userName="surajrmal" createdAt="2025-02-06T16:31:29" color="">}}

{{<matomeQuote body="アーティストやライターだって生活費を稼ぎたいんだよね。ウチらが彼らを切り捨てたんだから、いっそのことOpenAIも切り捨てて、マジで使えるオープンAIを手に入れようぜ。" userName="ClumsyPilot" createdAt="2025-02-06T18:40:47" color="">}}

{{<matomeQuote body="OpenAIに投入されてる投資額って、実際に意味のある進歩の割にめっちゃインフレしてる気がする。<br>最先端の研究における革新的なブレークスルーは、ただ単に金をつぎ込んで前例のない高価なデータセンターを建設すればいいってもんじゃないってのは明らかだよね。<br>それに、たとえそれが有効な方法だったとしても、法を利用して民間企業を研究の最前線に立たせるべきじゃないと思うんだよね。特にこんなにもめちゃくちゃなやり方ではさ。" userName="advael" createdAt="2025-02-06T20:20:25" color="#45d325">}}

{{<matomeQuote body="chain of thoughtが、モデルがテキストを処理するための一時的な”レイヤー”を提供するスクラッチバッファとして機能するなら、このバッファを独立したFNNとattentionを持つ別のコンテキストにすることが理にかなうか気になるな。つまり、完了までに無限の時間がかかる”推論”のマクロプロセスと、この不可解な埋め込みベクトルのストリームを自然言語で記述するミクロプロセスがあり、エンコーダ/デコーダアーキテクチャに戻るけど、両方が自己回帰的であるような。たぶん、これは人間のテキストを模倣することに縛られない、より密度の高い”思考”の表現をくれるんじゃないかな。" userName="pona-a" createdAt="2025-02-05T14:06:28" color="#ff5c5c">}}

{{<matomeQuote body="子供の頃から考えてたアイデアがあるんだけど、シェアしてもいいかな。確か”The Minds I”を読んだ頃だったと思うんだけど、AIと意識について考えてたんだよね。<br>ポピュラーな心理学の意識と無意識の概念について考えたんだ。それぞれを、意識の流れの詩のような独立したトークンのストリームとして考えたんだ。でも、その流れに沿って、意識ストリームが無意識ストリームによって編集されるジョイントポイントがあったんだ。無意識ストリームは、意識ストリームに対してCRUDのような操作を実行すると考えられる。意識ストリームは短期記憶のバッファとして機能し、無意識ストリームは長期記憶のバッファとして機能する。たとえば、無意識は長期目標に関連する命令を持っており、意識ストリームは短期目標に関連する命令を持っている。<br>知覚は、入力が意識ストリームに供給され、実行される前に無意識ストリームによって編集されると想像できる。<br>このアイデアを今実際に実装することは完全に可能だと思う。だって、子供の頃の夢だったけど、今は実験できるかも！" userName="zoogeny" createdAt="2025-02-05T21:22:56" color="#ff5c5c">}}

{{<matomeQuote body="意識は無意識が意識じゃないふりをしてる、みたいな？薄いラッパーみたいな。CRUDは確かにしっくりくる。<br>仏教とか、マジで全ての宗教に通じるよね。" userName="barrenko" createdAt="2025-02-06T08:29:28" color="">}}

{{<matomeQuote body="キミのアイデアを思い出させる論文があるよ。<br>https://arxiv.org/abs/2501.19201<br>Metaのlarge concept modelのアイデアとも、そうかけ離れてないね。" userName="easeout" createdAt="2025-02-05T15:37:30" color="">}}

{{<matomeQuote body="昨日全く同じこと考えたわ。<br>もう一層レイヤーを追加して、これを監視してレイヤーの追加を止めるようにしてもいいと思う。このメタ認知こそが必要なものだって考えてるんだ。<br>裏付けになるデータはないけどね。だから、話半分に聞いてくれ。" userName="bluechair" createdAt="2025-02-05T15:09:36" color="">}}

{{<matomeQuote body="まさにそこを目指してたんだけど、君の方がうまく説明してるね。状況を監視する実行プロセス、意識の流れ、実際の出力があって、心理学に戻ると、出力（スピーチ）が自我、超自我が実行プロセス、idが＜思考＞内部モノローグ＜/思考＞って感じかな。厳密には違うけど、まあ近いよね。" userName="hadlock" createdAt="2025-02-06T01:05:28" color="#ff5c5c">}}

{{<matomeQuote body="同じ推測だけど、全てのトークンが同じ潜在空間にあるのか、それとも複数の空間にあって、それぞれの論理ユニットが独立して学習するのか…？" userName="larodi" createdAt="2025-02-05T15:23:40" color="">}}

{{<matomeQuote body="＞この理解不能な埋め込みベクトルの流れを自然言語で説明するのは、ある意味encoder/decoderアーキテクチャに戻るってことだよね。<br>これってただの標準的なデコードで、ベクトルの流れはk/vキャッシュって呼ばれてる。" userName="whimsicalism" createdAt="2025-02-05T15:27:20" color="">}}

{{<matomeQuote body="問題は、RLがめちゃくちゃ非効率ってこと。LLMをfine tuningしてchain of thoughtのトリックをやらせるのはいいけど、思考をゼロから構築するのは別問題。pretrainedなLLMがかなり頑張ってるんだよ。<br>novelなトークン空間には”思考”のデータセットがないから、君のアイデアを実現するにはRLしかない。既存のLLMトークン空間にもないけど、ベースモデルがあるからね。英語で表現された思考は、トークン間の関係性をすでに知ってるから、それを”思考”に応用してるだけ。" userName="cakealert" createdAt="2025-02-06T01:48:06" color="#ff33a1">}}

{{<matomeQuote body="＞問題は、RLがめちゃくちゃ非効率ってこと。<br>え、マジで？それって変な定義だね。まるでチューリングマシンがTSPを解くのに非効率って言ってるみたい。少なくとも複雑さで定義するか、ドメインや観測可能性の文脈に入れるべきだよ。<br>RLは、定義上、選択したドメインで効率的な問題を見つける分野[1]。LLM/LRM学習には、RLがかなり効率的な場合もあるかもしれない。たとえば、Dynamic Programmingを使うと、状態空間Xアクション空間で多項式時間になるから、MDPを”より”効率的に解けるんだ[1]。[1] https://web.stanford.edu/class/psych209/Readings/SuttonBarto..." userName="itissid" createdAt="2025-02-06T02:25:40" color="">}}

{{<matomeQuote body="RLはディープラーニングにとって非常に質の低い学習シグナルしか提供しない。教師あり学習よりも桁違いに悪い。何もないよりはマシだけどね。<br>OPが言ってるのは、pretrainedなLLMをhuman readableな出力を生成するように誘導する目的で、RLを使ってtransformerをゼロから学習させるのに近い（つまり学習トークンなし）。おそらく収束すらしなくて、収束したとしても膨大な計算量が必要になるだろうね。" userName="cakealert" createdAt="2025-02-06T03:25:58" color="">}}

{{<matomeQuote body="教師あり学習の領域では、何がシグナルで何がノイズかを暗黙的に決定してるから、確かにその閉じた設定では、教師あり学習の方がはるかにサンプル効率がいい。でも、強力なベースモデルがあれば、RL学習での「アハ！」体験で、「言語自体からシグナルを絞り出す」ことが可能になり、教師あり学習の例よりもはるかに幅広い潜在知識が得られて、固定されたデータセットよりもはるかに大きな範囲に一般化できる可能性があるってことを学んでいる気がする。abiogenesisを思い出させるような、とても興味深いことだよ。今のモデルがまだ苦手なことを見ると、突拍子もない話に聞こえるかもしれないけど…限界まで行けば、非常に重い裾野が存在する可能性がある。" userName="pizza" createdAt="2025-02-06T04:44:28" color="#ff33a1">}}

{{<matomeQuote body="pretrainedなLLMがあれば、ほとんどの作業は終わってる。RLはモデルを'thinking'モードに誘導するだけ。それがうまくいくためのシグナルは十分にあるし、非効率さは問題にならない。<br>デメリットは、モデルが出力するのと同じ言語で思考を制限してしまうこと。全ての人間がそうやって考えてるわけじゃないって主張もできるよね。自分は言語やイメージで考えることはほとんどなくて、ただ概念（正しい言葉かすらわからないけど）が混ざって変化して、最終的に言語に変換することさえしないことが多い。ただ行動するだけ。" userName="cakealert" createdAt="2025-02-06T07:03:32" color="#ff5733">}}

{{<matomeQuote body="めっちゃ同意。実際、思考プロセスに一番合ってるのは、Marcolli、Chomsky、Berwickが提唱してるmultiset tree/forestワークスペースアプローチみたいなものだと思う。線形化された文字列の（非平面的な）埋め込み、またはセマンティック多様体に外部化できるHopf代数。" userName="pizza" createdAt="2025-02-06T08:13:21" color="#38d3d3">}}

{{<matomeQuote body="chain of thoughtの出力でモデルを学習させれば、次のトークン予測で停止問題を解決できる（例：この思考の連鎖は、この別の思考の連鎖と一致する）。" userName="bloomingkales" createdAt="2025-02-05T15:49:00" color="">}}


{{< /details >}}


[記事一覧へ]({{% ref "/posts/" %}})
