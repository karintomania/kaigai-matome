+++
date = '2025-03-04T00:00:00'
months = '2025/03'
draft = false
title = '事前学習なしのARC-AGIがもたらす新たな可能性とは'
tags = ["AI", "機械学習", "ジェネラリティ", "情報理論", "メタ学習"]
featureimage = 'thumbnails/blue4.jpg'
+++

> 事前学習なしのARC-AGIがもたらす新たな可能性とは

引用元：[https://news.ycombinator.com/item?id=43259182](https://news.ycombinator.com/item?id=43259182)

{{<matomeQuote body="幅広い前訓練が一般性の精神に反してる気がする。3つの例から4つ目を予測できるプログラムを作れるなら、オラクル合成を解決したことになる。もし全人類の知識でネットワークを訓練して、99％をファインチューニングしたら、ただの高価な圧縮装置になっちゃう。" userName="pona-a" createdAt="2025-03-04T20:01:20" color="">}}

{{<matomeQuote body="これは「知識」や「理解」の考えが非常に単純だね。AGIがプラトン的な論理や理由にアクセスできるって考えは間違い。意味や論理は文脈なしでは成り立たない。AGIの真の試験は、異なる情報を一つの世界観にまとめる能力だと思う。前訓練はそれを助けるものなんだよ。" userName="Valectar" createdAt="2025-03-05T03:59:42" color="#ff33a1">}}

{{<matomeQuote body="AlphaGoでAGIはここにあったと思う。ただ、一般化すべきと思っている人が多いけど、AlphaZeroが他のゲームもできるようになっても十分でないとされる。AIがいつか懐疑者を満足させるほど一般的になるのは難しい気がする。" userName="gitfan86" createdAt="2025-03-05T13:00:13" color="">}}

{{<matomeQuote body="今はまだだけど、ゲームがもっと複雑になって、人間の環境にマッチすれば、人間のような適応が求められることがなくなるとは限らないよ。" userName="luke-stanley" createdAt="2025-03-05T17:45:17" color="">}}

{{<matomeQuote body="でもAlphaZeroはもっとリッチなゲームをプレイできないから、この文脈では大した意味はない。" userName="Jensson" createdAt="2025-03-06T00:43:53" color="">}}

{{<matomeQuote body="“懐疑者を満足させるためにAIが一般的になることはない”って言ってるけど、“一般”が一つのAIがどんな仕事もできるって意味じゃないってことをみんなが勘違いしてる。人間も特化してるし、一つの仕事をするのに長い訓練が必要だし、簡単にタスクを切り替えるわけじゃない。" userName="FrustratedMonky" createdAt="2025-03-05T13:08:30" color="">}}

{{<matomeQuote body="人間は常にタスクを切り替えやすいし、多くの仕事が短時間に何度も切り替わる。私たちの知識を蓄積して実行する能力は、種としての適応力の一部なんだよ。多くのタスクを理解して改善する能力が重要だよ。" userName="devmor" createdAt="2025-03-05T15:34:40" color="#ff5c5c">}}

{{<matomeQuote body="小さいタスクの話をしている。人間がMBAを取って、その後Physics Labで働けると思っている？無理だよ。でもAIには同じように、全ての仕事を同じくらい上手くやることを期待しているんだ。" userName="FrustratedMonky" createdAt="2025-03-05T18:17:08" color="">}}

{{<matomeQuote body="それはAIに求めている結果だけど、AGIの包括的な定義ではない。自動化のステップがあれば、AGIを作らなくてもその結果は達成できる。最近の試みは人間のコミュニケーションに似ているだけで、人間の認知を模倣しているというわけではない。" userName="devmor" createdAt="2025-03-05T19:48:44" color="">}}

{{<matomeQuote body="AIの一般的な知能についての話をしてるけど、人間も意外と限定された存在で、完璧に一般的なわけじゃないよね。実際、限定的にトレーニングされたり、嘘をつくこともあるし、人間を基準にするのが適切か疑問だな。" userName="FrustratedMonky" createdAt="2025-03-05T22:47:47" color="">}}

{{<matomeQuote body="人間は私たちが目指している知能の唯一のモデルだから、他の目標は空想に過ぎない。人間はすごく一般的で、どんなこともできる。AGIは人間のように一般的でいてほしいけど、もっとスケールが大きくて物理的な制約に縛られない存在になってほしいんだ。" userName="devmor" createdAt="2025-03-06T05:26:11" color="#785bff">}}

{{<matomeQuote body="一つのアーキテクチャで電気工学者や医者になることができるなら、それが本当の一般知能だよね。今は専門的なアーキテクチャが使われているけど、同じ技術でどちらにも対応できたら面白い。でも、多くの人が一般を一つのAIで何でもできることとして考えてる気がする。" userName="FrustratedMonky" createdAt="2025-03-07T12:12:58" color="#ff33a1">}}

{{<matomeQuote body="人間がテニスを上手くなるにはルールを学ぶ必要があるのに、AIにそんなことを期待しないのは変だと思う。" userName="gitfan86" createdAt="2025-03-05T15:59:35" color="">}}

{{<matomeQuote body="機械が自分でトレーニングの方法を決められるなら、それは一般知能の精神に反しないと思う。そもそも人間も何かを上達させるためには練習方法を見つけるものだから。" userName="jshmrsn" createdAt="2025-03-04T21:50:14" color="">}}

{{<matomeQuote body="その通り。今の多くのパラダイムには本当の一般化が許されていないから、AGIはしばらく出てこないって言われてるんだ。" userName="fsndz" createdAt="2025-03-04T22:02:50" color="">}}

{{<matomeQuote body="「真の一般化」って実際、多くの人間もできないんだよね。" userName="exe34" createdAt="2025-03-04T22:25:12" color="">}}

{{<matomeQuote body="LLMは、最もバカな人間ですらできるような一般化すらできてない一方で、最も賢い人間でもできないこともやってるんだよ。" userName="fsndz" createdAt="2025-03-04T22:44:26" color="">}}

{{<matomeQuote body="Moravecはこういうことを80年代に語ってたね。" userName="taneq" createdAt="2025-03-05T08:12:46" color="">}}

{{<matomeQuote body="もっと知りたいな。具体的に何かある？それとも調べるだけ？" userName="K0balt" createdAt="2025-03-05T09:53:14" color="">}}

{{<matomeQuote body="Moravecの逆説についてチェックしてみてね。<br>https://en.wikipedia.org/wiki/Moravec's_paradox" userName="fsndz" createdAt="2025-03-05T13:03:05" color="">}}

{{< details summary="もっとコメントを表示（1）">}}
{{<matomeQuote body="人間の学びは感覚的な入力から来ることが多いと思う。機械が背景なしでうまく一般化するとは思えないな。" userName="tripplyons" createdAt="2025-03-04T21:05:05" color="">}}

{{<matomeQuote body="赤ちゃんや幼児は視覚的・触覚的な物体認識や『民間物理学』の概念を理解している気がする。<br>CompressARCではできないことがたくさんあるよ。" userName="aithrowawaycomm" createdAt="2025-03-04T21:38:34" color="#ff33a1">}}

{{<matomeQuote body="ここで言う『先天的』って、進化した脳構造や神経系を含むと思う。一般性を達成するには、今のところ広範な事前学習が最良だね。" userName="Ukv" createdAt="2025-03-04T21:44:46" color="#ff5733">}}

{{<matomeQuote body="数十億使って良い手法やアーキテクチャを探しても、現代のLLMには持続的な構造ができていないってこと？" userName="SiempreViernes" createdAt="2025-03-05T02:24:40" color="">}}

{{<matomeQuote body="赤ちゃんの脳は空っぽじゃないし、現在の私たちの理解を超える複雑さがある。哺乳類は遺伝子に本能的な知識を持って生まれてるよ。" userName="mystified5016" createdAt="2025-03-05T01:36:43" color="#ff5733">}}

{{<matomeQuote body="＞もし生まれた瞬間に隠れたり生き延びられなかったら食べられちゃう<br>いや、大抵の赤ちゃんは生まれた瞬間に隠れたり生き延びたりできないよ。" userName="leptons" createdAt="2025-03-05T09:00:04" color="">}}

{{<matomeQuote body="発達心理学についてもっと調べてみて。赤ちゃんは君が思ってるよりずっと高度なんだから。" userName="mystified5016" createdAt="2025-03-05T16:35:12" color="">}}

{{<matomeQuote body="一般知能は膨大な知識がないと無意味だよ。事前学習が知識であって、知能じゃないから。" userName="ta8645" createdAt="2025-03-04T20:28:05" color="#ff5733">}}

{{<matomeQuote body="長いコンテキストがあれば、広範な知識がなくてもAGIは使えるんじゃね？ Arecibo Messageみたいなブートストラップシーケンスをコンテキストに入れて、それからプロンプトを続ければいいし。十分に計算能力のある一般的な推論機はコンテキストを理解して、プロンプトについて考えられるはずだ。" userName="dchichkov" createdAt="2025-03-04T20:50:36" color="#ff33a1">}}

{{<matomeQuote body="確かにそうだけど、それって実質的に事前学習を再現してることになる。抽象的な解決策を考えるためには、原子が何かとか、人間の知識をすべて説明しなきゃならないし。知識のあっても、効果的に行動できるかは違うから、知識量が重要なんだよ。" userName="ta8645" createdAt="2025-03-04T21:00:12" color="#ff5c5c">}}

{{<matomeQuote body="神経科学には詳しくないけど、人間や動物は主に感覚入力から学習して知能を得るんじゃないかな。" userName="tripplyons" createdAt="2025-03-04T21:06:49" color="">}}

{{<matomeQuote body="生まれる前から遺伝子に多くのことが組み込まれてると思わない？" userName="FergusArgyll" createdAt="2025-03-04T21:19:59" color="">}}

{{<matomeQuote body="そんなことはないと思う。役立つ専門問題ってのは、ただのパターンに過ぎないから。IDEが一致する文字列の例を5つ受け取って、きちんと動くregexを出せるなら、Togoの首都や細胞の代謝経路について知らなくても大丈夫なんだ。事前学習がなければ、新しいプログラミング言語やライブラリ、タスクに一般化できるし、消えそうなアフリカの言語の文法を分析したり、ヘミングウェイのスタイルで物語を書いたり、患者データから癌を診断することもできるんだ。" userName="pona-a" createdAt="2025-03-04T20:50:18" color="#45d325">}}

{{<matomeQuote body="もちろん、誰もが完璧な知識を持っているわけじゃない。俺もTogoの首都は知らない。でもIDEが何か、技術スタックの中での位置とか、文字列とは何か、その依存関係は知ってるんだ。問題にアプローチするには大きな知識が必要で、2000年前の賢い人にその課題を出したら、彼らはただ呆然とするだろう。彼らの知識では理解できないからね。" userName="ta8645" createdAt="2025-03-04T21:16:16" color="#ff33a1">}}

{{<matomeQuote body="＞ 知識が事前学習で、知能はそれを復元するための副作用だって思うけど、知識がトレーニングセットで、知能はその知識を再現することで生まれる副作用じゃないの？" userName="raducu" createdAt="2025-03-04T20:39:30" color="">}}

{{<matomeQuote body="知識をエンコードするのに知能が必要で、知識が多ければ多いほど、さらに賢く知識をエンコードできると考えるんだ。でも、一旦知識のデータセットを持ったら、特に何も浮かび上がらないし、ただそのまま放置されるだけ。知能は、エンコードされた知識にアクセスして何かを生み出すアルゴリズムにあるんだ。" userName="ta8645" createdAt="2025-03-04T21:03:56" color="#ff5c5c">}}

{{<matomeQuote body="データセットは欠陥があってノイズが多く、断片化されてるんだ。それを正しくするのには知能が必要で、無駄なくつなげるのにはさらに知能が必要だ。" userName="esafak" createdAt="2025-03-04T21:47:31" color="#ff5733">}}

{{<matomeQuote body="欠陥があってノイズが多い、それが断片化されていることを知るには知識が必要だよ。何かを『修正』する理由がないのは、過去に『理解されていた』データが実際に欠陥のある結果を生んだと知識がなければ、それがわからないから。強化学習って、正確な知識獲得が必要なアルゴリズムだから、効果的にはできないんだ。" userName="ta8645" createdAt="2025-03-04T22:06:05" color="#ff5733">}}

{{<matomeQuote body="Lex FriedmanのポッドキャストでMarcus Hutterについて考えてたんだけど、Joshua Bachが知性を現実を正確にモデル化する能力と定義してるのは面白いね。ロスレス圧縮は知性そのものなのか、最適なモデルなのか、それに違いはあるのだろうか？<br>https://www.youtube.com/watch?v=E1AxVXt2Gv4" userName="AIorNot" createdAt="2025-03-04T20:26:31" color="#ff5733">}}

{{<matomeQuote body="ちなみに、ARC-AGIのクリエイターであるFrançois Cholletは、この2020年のLex Fridmanのポッドキャストで知性は圧縮ではないと言ってるよ。<br>https://youtu.be/-V-vOXLyKGw" userName="meowface" createdAt="2025-03-05T01:18:14" color="">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（2）">}}
{{<matomeQuote body="圧縮は有限データに基づくもので、AIモデルは新しいデータを取り込める必要があるから、もっと贅沢に扱うべきだと思う。" userName="visarga" createdAt="2025-03-05T04:33:20" color="">}}

{{<matomeQuote body="複雑な現実を高精度かつ低遅延で予測するシンプルなモデルを見つける能力が重要なんだ。知性を測る簡単なテストは、Cの関数を読んで、入力の変化が出力にどう影響するか教えることだと思う。<br>本当に理解しているかどうかを見るのも面白いね。" userName="akomtu" createdAt="2025-03-05T00:19:40" color="#45d325">}}

{{<matomeQuote body="Hutterの立場の結果はHutter賞として知られ、ARC-AGIと同じような目標を持っているけど、知性の目安として圧縮そのものを見ているんだ。<br>http://prize.hutter1.net/" userName="fastball" createdAt="2025-03-05T13:02:29" color="#38d3d3">}}

{{<matomeQuote body="彼らのアプローチの本質を抽出したいんだけど、詳細に隠れていて捉えにくいんだ。最もシンプルなモデルを最適化する方法が新しいんだ。<br>これは典型的なMLのやり方とは全く違っていて、データを記憶するための最適なモデルを見つけるのとは逆のことなんだ。" userName="cocomutator" createdAt="2025-03-05T13:38:56" color="#ff33a1">}}

{{<matomeQuote body="複雑さを最小化する発想は新しいわけじゃないけど、最近はあまり重要視されていないんだ。古典的な正則化が最近は流行らなくなってきてるから、面白いかもしれないね。" userName="getnormality" createdAt="2025-03-05T14:06:05" color="">}}

{{<matomeQuote body="そうだね、複雑さの上限が先に決まってて、最適化してると考えるべきだよね。それで、予算内の最良のモデルを得るってことなんだよね。" userName="cocomutator" createdAt="2025-03-05T14:16:59" color="">}}

{{<matomeQuote body="そうだね、双対性によりこれは実際には異なることではないんだ。条件付きで複雑さとデータ忠実度を最適化すると、他のアプローチとそれほど違わなくなるかもしれないね。" userName="getnormality" createdAt="2025-03-05T14:18:00" color="">}}

{{<matomeQuote body="ああ、君の言いたいことがわかったよ。全体のアプローチには、最小限の複雑さの解を見つける特性があると思う。情報理論がこの測定に役立ってるんだね。<br>今後の可能性もありそうだね。" userName="cocomutator" createdAt="2025-03-05T15:25:56" color="#45d325">}}

{{<matomeQuote body="この発見の重要な要素に関してあなたが正しいと思うけど、これはARC-AGI特有の結果のような気がする。各パズルは似たフォーマットで、パズル内の情報はルールを導き出すために必要なものだけに近い。ルールを表現するために必要な情報量を減らすことで、実際にルールが何をしているかに焦点を当てざるを得なくなる気がする。ノイズがあったり適当なデータがあれば、このテクニックは機能しないだろう。パズルが「パズルの場所を特定すること」であってはならないが、各例がパズルそのものに関する純粋な情報だからこそ成立している。" userName="ealexhudson" createdAt="2025-03-05T14:05:15" color="#785bff">}}

{{<matomeQuote body="あなたのノイズのない性質についての観察には同意する。この問題を「複雑さを最小化してX-yの関係を正確に記憶する」と定義できる。その概念をノイジーなケースに一般化する必要があるかもしれない。正確な記憶を要求する代わりに、エラーバジェットを設ける必要がある。しかし、このエラーバジェットは効果的な複雑さのメタパラメータのようにも思えるから、結局交差検証の最初の段階に戻ってしまう。" userName="cocomutator" createdAt="2025-03-05T14:13:31" color="#45d325">}}

{{<matomeQuote body="‘バジェット’をビデオ再生の帯域制限に似たものと考えるなら、ある限界を下回ると映像が非常に理解できなくなる感じかな。大体これはスライダーのようなもので、バジェットが少ないほど、再生精度がほんの少し低くなる。クリーンなデータだからこそ、正しいルールをエンコードするコーデックが類似の解法よりも明らかな帯域削減を達成できるのではないかと思う。最も優れたルールセットは、少なくともこのパズルのセットにおいて、圧縮性が当然良くなる。そして、さまざまなエンコーディング戦略を試して正しいルールをほぼ強引に特定できる。" userName="ealexhudson" createdAt="2025-03-05T14:27:29" color="">}}

{{<matomeQuote body="面白いね。最近、機械学習の進むべき方向は、むしろ「機械学習」から離れ、プレトレーニングやデータ、探索を減らし、より直接的な表現や象徴的な処理、制約満足、メタ学習などに向かうべきだという結論に近づいている。そういうものを減らす必要があるというのは雑然としていて、力任せだ。これらを扱うと、データの質に依存してしまうから、データマイニングには向いても、データの根本的な原因をモデル化するには向かない。彼らがやろうとしていることの理解に基づくと、解法/問題空間の最小表現を見つけようとしているようだ。" userName="EigenLord" createdAt="2025-03-05T04:50:58" color="#45d325">}}

{{<matomeQuote body="素晴らしいドキュメントと説明だね。ありがとう。自分の内省をサポートする内容があってうれしい（ハハ、自分のプロフィールにも書いてる！）<br>＞知能とは情報を不可分な表現に圧縮することだ。" userName="pyinstallwoes" createdAt="2025-03-05T03:40:38" color="">}}

{{<matomeQuote body="知能の説明が気に入ったよ。" userName="mmazing" createdAt="2025-03-05T05:39:51" color="">}}

{{<matomeQuote body="＞知能とは情報を不可分な表現に圧縮することだ。<br>物理学の話だと思ったよ。" userName="programjames" createdAt="2025-03-05T05:22:23" color="">}}

{{<matomeQuote body="＞2019年に導入されたARC-AGIは、最小限の例から抽象的ルールを推測・一般化するシステムの能力を試すための人工知能ベンチマークだ。このデータセットはIQテストのようなパズルから成り、各パズルは基盤となるルールを示すいくつかの例画像と、そのルールを適用する必要があるテスト画像を提供する。ARC-AGIを解決することが人工知能一般（AGI）の到来を示すかもしれないと主張する人もいるが、その真の目的はAGIに向けた進歩を妨げる現在の課題を浮き彫りにすることだ。知能が情報を圧縮して一連のルールにする能力とも定義されているので、その通りだと思う。" userName="d--b" createdAt="2025-03-04T22:02:29" color="#38d3d3">}}

{{<matomeQuote body="あなたが言っているほど循環的でも明白でもないよ。本当にARC-AGIの問題を試したことある？かなり微妙で、広範囲な抽象概念をテストしているよ。参考までに、o1-previewのスコアは公的評価で21％、OPでは34％だ。" userName="bubblyworld" createdAt="2025-03-05T09:47:40" color="#ff5733">}}

{{<matomeQuote body="（やや）関連したSchmidhuber。" userName="fragebogen" createdAt="2025-03-05T11:05:37" color="">}}

{{<matomeQuote body="考えたらこの相互作用は面白い！CompressARCはトレーニングセットで34.75%の成績で、評価セットで20%だって。ただ、1問ずつ処理するのに約20分かかるから、100問のチャレンジでは33.3時間もかかっちゃって、12時間の目標を越えちゃうんだよね。でも、すごいアプローチだと思う！" userName="naasking" createdAt="2025-03-05T13:58:33" color="#785bff">}}

{{<matomeQuote body="これ、標準的なベイジアン深層学習アプローチに近い気がするよ。ただ、かなりエンジニアリングされたアーキテクチャだけどね。" userName="unixpickle" createdAt="2025-03-05T03:41:03" color="">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（3）">}}
{{<matomeQuote body="少ないデータポイントで深層学習を使う方法が見えてきてワクワクしてる！情報圧縮に焦点を当ててるのが興味深いけど、コードzがフォワードパスに明示的に参加するのがこの手法の新しさなんじゃないかな。彼らは言ってるよ、＞”そんな方法が圧縮を行う理由は明らかではない”。そんなに独特の視点だとは思わなかったけどね。" userName="cgadski" createdAt="2025-03-05T11:03:33" color="#45d325">}}

{{<matomeQuote body="このコメントいいね！小規模データでの潜在空間の崩壊をどう避けるのか疑問だったんだ。等変換性を強みとも弱みとも見るべきかな？良い圧縮を学ぶのは助けるけど、そもそも等変換層を選ぶのが重要だよね。" userName="bubblyworld" createdAt="2025-03-05T15:55:43" color="">}}

{{<matomeQuote body="彼らのやったことはこれだ：ランダムサンプルを選んでパズルのエンコーディングにする。特定のzとθから、ピクセルカラーの分布をデコードする。実際の色に合うようにエラーεを追加して、KL（デコードされた色 || 実際の色）を指定する。どんどんビット数を減らしていくことで、正しい答えへ近づけるってわけ。" userName="programjames" createdAt="2025-03-04T22:15:51" color="#785bff">}}

{{<matomeQuote body="統計や情報理論のバックグラウンドなしで理解する希望はあるかな？今のところ、旧式の事前学習は単純でわかりやすい分、評価が高いよね。" userName="throwaway314155" createdAt="2025-03-05T02:51:08" color="">}}

{{<matomeQuote body="高水準なヒューリスティック理解は可能だと思う。彼らは各問題に対して新しいネットワークをゼロから訓練するんだ。損失関数は入力と出力をマッピングすることと、ネットワークの重みを小さく保つことを目指してる。シンプルな関数がテスト入力でもうまくいくことを願ってるけど、成功率は20~30%だって。" userName="essexedwards" createdAt="2025-03-05T03:43:46" color="#45d325">}}

{{<matomeQuote body="すごく良い説明ありがとう！フォローアップがいくつかあるんだけど、時間ある？a. どうしてこれがこんなに上手くいくの？圧縮やパラメータが少ないことでより良い答えを引き出せる理由は？b. 異なる領域を評価するベンチマークに自然に転移するかな？それとも事前学習と似たアプローチが必要かな？c. 20-30%の成功率で、これが拡張可能だと思う？それとも単一の大きなネットワークが複数の問題を処理できるようになるのかな？" userName="throwaway314155" createdAt="2025-03-05T05:10:43" color="#ff33a1">}}

{{<matomeQuote body="＞”時間があるならFollow-upがいくつかある”って強調したよ。誰も答える義務は感じてほしくないんだ。そこは分かってるつもりなんだけど。" userName="throwaway314155" createdAt="2025-03-05T08:46:44" color="">}}

{{<matomeQuote body="説明するね。知性は圧縮に関係してるって言われてるんだ。何か現象を説明するには、プログラミング言語みたいな形式で記述する必要がある。例として、現象を算法の加重和で表現する。短いアルゴリズムに重みが集中するから、シンプルな説明がいいんだ。著者たちはシンプルなアルゴリズムを見つけようとしていて、これによってパズルの解法を学ぶことを狙ってる。初めからプログラムを列挙するより、特定のネットワークを使って効率よく探索しているんだ。入力や重みは正規分布で初期化して、正しい答えを出すために調整していくんだ。" userName="programjames" createdAt="2025-03-05T03:54:53" color="#38d3d3">}}

{{<matomeQuote body="zの役割がよくわからないな。μやΣをθに吸収できる気がする。ただ、zを分割してそれぞれの入力に対応させて、f_θを反復的に処理するなら理解できるかも。" userName="uh_uh" createdAt="2025-03-05T12:50:57" color="">}}

{{<matomeQuote body="同意するよ。zはμやΣに吸収されるべきだと思う。例えば、常に[1 0 0 ... 0]を入力して、NNの最初の層が基本的にzを出す感じ。ただ、KL(q(θ)||p(θ))をO(θ^2)で近似するのは止めないと、計算効率が悪くなるかも。" userName="programjames" createdAt="2025-03-05T23:05:25" color="">}}

{{<matomeQuote body="そうかもね。θの正則化ペナルティを緩めないといけないし、オーバーフィッティングしないようにするのが難しそう。今の設定だとθが”ダム”で、NNがアルゴリズムの役割を担うことが促されている気がするよ。" userName="uh_uh" createdAt="2025-03-06T13:00:39" color="">}}

{{<matomeQuote body="メソッドの大きな欠点は、ガウススプラッティングみたいに毎回全てのパズルに対してNNを訓練しないといけないことだよね。著者は「パズル間の重み共有による共同圧縮」って部分でこれを回避する方法を議論してる。" userName="naasking" createdAt="2025-03-05T13:52:01" color="#785bff">}}

{{<matomeQuote body="小さなNNだから、”ハイパーネットワーク”を使って特定のパズル用にμ、Σ、θを予測したり、パラメータの訓練方法を予測できるかもね。Kurt GodelかDouglas Hofstadterが眉をひそめるだろうけど。" userName="mmazing" createdAt="2025-03-05T05:18:11" color="">}}

{{<matomeQuote body="＞『効率的な圧縮が知性の核心にある』ってアイデアは新しくないよね。実際にその実証を見せるんじゃなくて、理論の議論を繰り返すのはどうかと思う。例えば、34.75%のARC AGIの証拠がある。カル・セーガンが指摘したように“観察：何も見えなかった。結論：恐竜”。" userName="YeGoblynQueenne" createdAt="2025-03-05T02:52:25" color="">}}

{{<matomeQuote body="＞『効率的な圧縮が知性を示す』って主張はどうしても論争になるとは思えないよ。長い時間で見て、知性がシステムをモデル化して正確な再現を可能にすることに賛成？それって観察よりもモデルの方が常に小さいんだから、知性が最適に圧縮したってことでしょ？" userName="naasking" createdAt="2025-03-05T13:42:06" color="#785bff">}}

{{<matomeQuote body="＞『知性は観察を正確に再現できるモデルを構築できる』って言うけど、誰がそう言ったの？ただの任意の理論じゃないのか？モデルが小さいからって、それが観察を”最大限圧縮した”ってことにはならないよ。モデルの最適性を見落としてる。無理に過大評価するのは良くない。" userName="YeGoblynQueenne" createdAt="2025-03-05T15:38:22" color="">}}

{{<matomeQuote body="知性には特定の能力があると思う。君の意見では知性はその能力を満たせるかどうか？だって知性に関しては特定の仮定が必要だから。" userName="naasking" createdAt="2025-03-05T16:19:37" color="">}}

{{<matomeQuote body="＞”実際の観測値を生成する関数よりも小さな関数は存在しない”って言いたいのか？俺がしょぼいプログラム書いて、”hello”を１００万回コピーしてそれを生成するってのがついでにできるとしたら、圧縮するアルゴリズムがそれより小さくならないってなるのか？理論を作る前にコンピュータサイエンスも少し勉強したほうがいいよ。情報理論やKolmogorovの複雑性について調べてみたら？圧縮と知能についての背後にある考え方を理解するために。" userName="YeGoblynQueenne" createdAt="2025-03-05T21:52:10" color="#ff33a1">}}

{{<matomeQuote body="俺はSolomonoff Inductionには詳しいんだ。質問に答えるつもりはあるのか、それとも逃げるために悪意のある言い訳を続けるつもりなのか？" userName="naasking" createdAt="2025-03-06T01:48:49" color="">}}

{{<matomeQuote body="＞”知性について深いことを考えた”お前の半端な理論に何を答えるんだ？知性についての洞察があるなら、役に立つことに使え。論文を書いてみるとかさ。いい加減、知性に関するくだらない理論にはうんざりだ。知性が圧縮だと思うなら、圧縮して知性を生み出してみろよ、やってみろ。まずは自分の理論を証明してから人を非難するんだ。" userName="YeGoblynQueenne" createdAt="2025-03-06T22:59:09" color="">}}


{{< /details >}}


[記事一覧へ]({{% ref "/posts/" %}})
