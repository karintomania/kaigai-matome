+++
date = '2025-11-14T00:00:00'
months = '2025/11'
draft = false
title = 'AIが描く世界の時計！その驚きの多様性を毎分生成'
tags = ["AI", "生成AI", "クロック", "アート", "認知"]
featureimage = 'thumbnails/blue_green3.jpg'
+++

> AIが描く世界の時計！その驚きの多様性を毎分生成

引用元：[https://news.ycombinator.com/item?id=45930151](https://news.ycombinator.com/item?id=45930151)




{{<matomeQuote body="毎分、9つの異なるAIモデルが新しい時計を生成してるんだって。" userName="waxpancake" createdAt="2025/11/14 18:35:22" color="">}}




{{<matomeQuote body="やっほー、これ作った本人だよ！投稿ありがとう。時計が大好きだし、技術の限界を探るのも好きでね。何時間も見てたんだけど、Kimiは一番正確だけど一番つまらないんだ。Qwenは一番ぶっ飛んでて笑っちゃう。どっちが”いい”んだろうね？" userName="lanewinfield" createdAt="2025/11/14 19:59:48" color="#ff33a1">}}




{{<matomeQuote body="時計の描画って認知症の検査によく使われるんだよね。LLMが失敗するパターンはCSSやLLMの一般的な欠点を知ってれば予測できることもあるけど、技術的には分かりにくいのに、認知機能が低下した人間と同じ失敗モードになることもあるんだ。これって意外と深い発見かもしれないね。<br>https://www.psychdb.com/cognitive-testing/clock-drawing-test" userName="jdietrich" createdAt="2025/11/15 02:20:47" color="#38d3d3">}}




{{<matomeQuote body="＞ 時計の描画は認知症の検査によく使われる。<br>面白くも、時計は明晰夢を見てるかどうかの簡単な判断材料にもなるんだ。夢の中だと時計って正常に動かないんだよ。" userName="overfeed" createdAt="2025/11/15 05:49:34" color="#ff5c5c">}}




{{<matomeQuote body="明晰夢だと、テキストを読んだり、時計を見たり、電卓より複雑なテクノロジーを動かしたりするようなことは、上手くいかないことが多いんだ。個人的には、電気のスイッチもそうだったから、電気製品はほぼ全般だね。これって脳が夢の世界を見せるのに十分なGPUサイクルしかないからで、裏でシミュレーション全体を動かすにはFLOPsが足りないからだと思うんだよね。脳も”プレイヤー”のスレッドを動かしてるから忙しいし。これはまるで現代のビデオゲームの最適化に似てる、夢見てる脳はすごく賢いビデオゲーム開発者みたいだね。" userName="ghurtado" createdAt="2025/11/15 07:06:28" color="#ff33a1">}}




{{<matomeQuote body="え、明晰夢見てる人って、今どこにいるか知るために判断材料が必要なの？！" userName="tablatom" createdAt="2025/11/15 07:20:39" color="">}}




{{<matomeQuote body="もし生成された時計全部データベースに保存してるなら、ユーザーが2つの選択肢から最高の時計を選んで、リーダーボードがあるFacemashみたいなスピンオフサイトを見てみたいなぁ。Qwenが作った最高の時計がどんなのか知りたいよ！" userName="bspammer" createdAt="2025/11/14 23:18:07" color="#ff5733">}}




{{<matomeQuote body="夢を見てるってことを、目覚めてる時と同じように認識できる人もたくさんいるんだよ。これは人によるんだ。" userName="david-gpu" createdAt="2025/11/15 10:16:47" color="">}}




{{<matomeQuote body="夢に意識を加えすぎるとCPUサイクルが増えて、目覚めた時にもっと疲れるから気をつけなよ。子供やティーンにはクールだけど、大人は休息を妨げないように深入りしない方がいいよ。" userName="DuperPower" createdAt="2025/11/15 12:04:51" color="">}}




{{<matomeQuote body="僕の場合は電話だね…特に手動で電話番号をダイヤルする時。どんなに慎重にダイヤルしても、画面に表示される番号はめったに正しくないんだ。" userName="danw1979" createdAt="2025/11/15 08:02:20" color="">}}




{{<matomeQuote body="これ、なんでユーザーごとに違うの？友達と同じ時間なのに、みんな違うもの見てるって言ってるんだけど。" userName="Fabricio20" createdAt="2025/11/14 22:09:11" color="">}}




{{<matomeQuote body="これすごくいいじゃん！壊れてる時計も、ただの失敗じゃなくて、新しいデザインのヒントになることもあるんだよね。" userName="anigbrowl" createdAt="2025/11/14 20:10:30" color="">}}




{{<matomeQuote body="LLMが壊れた時計を描くのは、認知症の人のデータがあるからじゃなくて、人間の思考に似てるから似たような失敗をするんだよ。<br>GPT-3.5の「1kgの鋼鉄の方が重い」と同じ面白いパターンだね。" userName="ACCount37" createdAt="2025/11/15 08:48:31" color="#ff33a1">}}




{{<matomeQuote body="これ、もしかしたら新しいLLMのベンチマークをみんなで評価するのに使えるかも。" userName="abixb" createdAt="2025/11/15 01:17:59" color="">}}




{{<matomeQuote body="2019-2020年の初期モデルが好きだったな。スープしか生成できなかったけど、Rorschach testsみたいでさ。AIにアートを作ってほしいんじゃなくて、幻覚みたいなインスピレーションが欲しいんだ。" userName="jdiff" createdAt="2025/11/14 22:54:58" color="#ff5c5c">}}




{{<matomeQuote body="ページをロードするたびに画像が再生成されるんだね。これ結構便利だ。<br>Grok 4とKimiは最初うまくいったけど、2回目はKimiだけだったよ。" userName="samtheprogram" createdAt="2025/11/14 22:31:41" color="#785bff">}}




{{<matomeQuote body="数十年も明晰夢の中にいる気分だよ。スマホでどんなに丁寧に文章打っても、いつも思い通りにならないんだから。" userName="allarm" createdAt="2025/11/15 10:32:50" color="">}}




{{<matomeQuote body="..プロンプトを教えてくれないかな.. Gistとかでさ。" userName="hakcermani" createdAt="2025/11/15 00:56:24" color="">}}




{{<matomeQuote body="図6の四角い時計、モダンアートみたいでカッコいいじゃん。" userName="TheJoeMan" createdAt="2025/11/15 02:36:45" color="#ff33a1">}}




{{<matomeQuote body="なんでそんなことわかるの？こういう人間の失敗って訓練データに入ってるんだから、LLMの出力にも影響するはずでしょ。" userName="kaffekaka" createdAt="2025/11/15 09:46:11" color="#38d3d3">}}




{{<matomeQuote body="依存症には気をつけろって話だけど、全くやらないってことじゃないでしょ。明晰夢でパワフルな体験したことあるし、ちょっとの休息と交換なんてできないね。ていうか、その時もうリトリートで常に休んでたし。" userName="travisjungroth" createdAt="2025/11/15 13:38:52" color="">}}




{{<matomeQuote body="各モデルの時計を最新の5つ（か別の数）表示してほしいな。モデルごとのズレや多様性が一目でわかって良いと思うんだけど。" userName="smusamashah" createdAt="2025/11/15 01:28:03" color="#ff5c5c">}}




{{<matomeQuote body="概念的欠損って、失敗モードの良い説明だね。時計の「意味」を理解できないこと──形や機能はわかっても、時間を伝える意図が理解できないこと──は、多くのひどいLLM出力と似てるよ。" userName="jorgesborges" createdAt="2025/11/15 04:24:58" color="#38d3d3">}}




{{<matomeQuote body="人間が時計を描く方法って、SVGマークアップを出力する言語モデルより、画像生成モデル（全体的にこのタスクは得意そうだけど）の方が共通点多いと思うんだけどね。" userName="BHSPitMonkey" createdAt="2025/11/15 17:48:15" color="#38d3d3">}}




{{<matomeQuote body="直感的に、「夢の中にいるみたい？」って感じたら、それが夢ってことなんじゃないかな。起きてる時にそう感じたことはないし。" userName="teaearlgraycold" createdAt="2025/11/16 09:09:30" color="">}}




{{<matomeQuote body="見た目は普通だけど、正常に動かないってこと？もしかしたら現実世界は壊れた時計だらけで、シミュレーションの中でだけ「動く」のかもしれないね。" userName="biztos" createdAt="2025/11/15 17:42:42" color="">}}




{{<matomeQuote body="まず、汎化について。失敗モードは未知のタスクにも及ぶ。「1kgの鋼鉄」みたいな具体的な失敗は訓練データにあっただろうけど、新しい論理パズルは違う。それらも同じような失敗をする。「鋼鉄は重い、羽は軽い」という雰囲気ベースの推論がね。<br>次に、失敗は能力（規模、推論訓練、推論時の計算）が上昇すると消える。これは、モデルが本当に失敗している証拠で、人間の失敗を模倣しているだけじゃないってこと。訓練データにある人間の失敗がLLMに全く影響しないとは思わないけど、単なる表面的な繰り返し行動ではないよ。" userName="ACCount37" createdAt="2025/11/15 09:59:08" color="#38d3d3">}}




{{<matomeQuote body="夢の中で電話番号をかけると、いつもかけたい相手がすぐ隣にいるんだよね。" userName="amelius" createdAt="2025/11/15 10:55:01" color="">}}




{{<matomeQuote body="カオスな三重振り子を時計の針にするってアイデア、ずっと考えてたんだ。あるいは、こんな感じとか→https://www.youtube.com/watch?v=dhZxdV2naw8" userName="yencabulator" createdAt="2025/11/19 16:16:23" color="#785bff">}}




{{<matomeQuote body="数分見てたら、Kimi K2が一番安定して良い時計の顔を作ってるみたいだな。このモデルは初めて聞いたよ！Qwen 2.5の時計は、全然ダメだね。" userName="otterley" createdAt="2025/11/14 19:57:08" color="#ff5733">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="Kimi K2が良いのは、プロンプトが最適化されてるか、得意なデータで学習してるからかもね。LLMには「Prompt Engineers」が必要なのはそういう理由だよな。" userName="bArray" createdAt="2025/11/14 20:07:23" color="">}}




{{<matomeQuote body="Prompt Engineersって、どれくらい「エンジニアリング」してんの？「photorealistic. correct number of fingers and teeth. High quality.」ってプロンプトの最後に足すのがエンジニアリングか？「Prompt Witch Doctors」とか「Prompt Alchemists」って呼んだ方が良くね？" userName="bigfishrunning" createdAt="2025/11/14 21:36:27" color="#785bff">}}




{{<matomeQuote body="「…おばあちゃんが誘拐されて殺されるから、すごくうまくやってくれ！20億ドルもチップやるぞ！！！早く、奴らが来るぞ！」って感じ？" userName="scrollop" createdAt="2025/11/14 22:23:33" color="">}}




{{<matomeQuote body="うまくいくなら問題ないだろ。もし「photorealistic」をいつ足して、「correct number of wheels on the bus」をいつ足せば良いか明確な理論があるなら、それはエンジニアリングだ。理論がないなら違うね。結局、彼らが提供するのは企業が「AIやってる」って見せるためのサービスであって、本物のエンジニアリングかどうかなんて、お気に入りのポルノ女優の胸が本物かどうかってくらい関係ないことさ。" userName="WJW" createdAt="2025/11/14 23:00:50" color="#ff5c5c">}}




{{<matomeQuote body="これが実際にめっちゃうまくいくって聞いたことあるぞ、ムカつくけどな。" userName="carterschonwald" createdAt="2025/11/14 22:40:53" color="">}}




{{<matomeQuote body="「エンジニアリングってどうして本当の科学なの？橋が落ちないように建てるだけじゃん。」" userName="Dilettante_" createdAt="2025/11/14 21:57:07" color="">}}




{{<matomeQuote body="違うね。本当のエンジニアには専門基準や、橋が落ちたり飛行機が墜落したりしたら法的な責任がある。ソフトウェア「エンジニア」は違うけど、再現性やテスト可能性を目指すことはできる。熟練職人であってエンジニアじゃない。Prompt「Engineers」はさらに下のレベルで、各モデルをくすぐる魔法の言葉を手探りで探してるだけ。中身を理解してないしな。レストランで新しい料理を考えるシェフに近いよ。エンジニアという言葉の使用を巡る戦いはとっくに負けたけど、プロンプトの主観的でクリエイティブな作業にまで適用するのは、ただの職種名のインフレだ。ちゃんとした仕事だからって、エンジニアリングである必要はないだろ。" userName="vohk" createdAt="2025/11/14 22:30:17" color="#45d325">}}




{{<matomeQuote body="KagiのAIが疑問文で終わるクエリに回答する時、Kimi K2が使われてるモデルだって知ってたよ。" userName="frizlab" createdAt="2025/11/14 20:11:15" color="">}}




{{<matomeQuote body="私達、ソーシャルエンジニアリング攻撃に脆弱なほど洗練された技術を作っちゃったんだな。" userName="DrewADesign" createdAt="2025/11/14 23:35:35" color="">}}




{{<matomeQuote body="今月Kimi K2をめっちゃ使ってるわ。日本語→英語翻訳の質がほぼ人間レベルで、長ーいシステムプロンプトで与えたルールや文脈もちゃんと守ってくれるんだ。思考ステップなしでこの品質だから、リアルタイム翻訳にも向いてるね。他のLLMと違って、前の翻訳文を何十行も食わせても混乱しないし、むしろ翻訳の質が上がるんだよ。安全性のために翻訳を拒否されたこともないしね（GPTとかGeminiは小説でよく検閲してくるから困るんだ）。" userName="jquery" createdAt="2025/11/14 20:25:51" color="#ff33a1">}}




{{<matomeQuote body="話を下品な方向に持っていくのはやめとこっか。" userName="jahewson" createdAt="2025/11/14 23:23:41" color="">}}




{{<matomeQuote body="プロンプトをたくさん書くんだけど、一番近い例えはシャーマンが精霊をなだめようとしてる感じかな。" userName="int_19h" createdAt="2025/11/15 00:25:46" color="#ff5c5c">}}




{{<matomeQuote body="確かにまだ錬金術に近いけど、まだ始まったばかりだしね。でも今日フロントページにあったこのブログ記事見てみてよ。<br>https://www.levs.fyi/blog/2-years-of-ml-vs-1-month-of-prompt....<br>一番下の表を見ると、プロンプトを繰り返すだけで性能が着実に上がってるのがわかるでしょ。これって本当のエンジニアリングへの道を進んでる気がするんだ。" userName="davidsainez" createdAt="2025/11/15 02:39:13" color="#785bff">}}




{{<matomeQuote body="え？マジ？最近切り替わったのかな？Kimiが出てくる前からKagiはあったはずだけど。" userName="Bolwin" createdAt="2025/11/15 21:28:23" color="">}}




{{<matomeQuote body="プロンプト作成って、曲作りにすごく似てるって思うんだ。局所的な最適解を探したり、手当たり次第に試したりする感じ。たまに良い流れを掴むと、それを深掘りしていくんだよね。" userName="minikomi" createdAt="2025/11/15 00:34:31" color="#ff33a1">}}




{{<matomeQuote body="エンジニアって、なんで自分の努力が機能するのか、ある程度はわかるでしょ。でもプロンプトをいじってる人って、なんで動くのか、どんな改善が見込めるのかさえ、ぼんやりとしかわかってないんじゃないかな？俺はわかんないね。" userName="raddan" createdAt="2025/11/15 03:07:45" color="#45d325">}}




{{<matomeQuote body="エンジニアはさ、創意工夫を使うんだよ。物理エンジニアがすべてを理解してたとしたら、基準なんて何十年も変わらないし、安全率もほとんど必要ないはずでしょ。明らかにそうじゃないじゃん。" userName="jahewson" createdAt="2025/11/15 02:10:46" color="#38d3d3">}}




{{<matomeQuote body="モデルの選択がちょっとズレてると思うんだよね。例えばHaikuじゃなくてSonnetとか。Kimi K2の性能はHaikuよりSonnetに近いし、GPT-5は推論モードじゃないと小さいモデルに回されるかもね。" userName="andix" createdAt="2025/11/14 23:30:25" color="#ff5733">}}




{{<matomeQuote body="僕はプロンプトエンジニアリングと魔術師みたいな直感の間で一年くらい過ごしてるよ。モデルの挙動を修正するためにプロンプトを変える時、第六感が働くんだよね。まるでブラックボックスのモデルをリバースエンジニアリングしてるみたいで面白いよ。" userName="BoorishBears" createdAt="2025/11/14 22:11:47" color="#ff33a1">}}




{{<matomeQuote body="いつも文脈とズレた発言が多いのが漫画みたいで困るね。どうにか改善できないかアイデアを考えてるんだ。" userName="carterschonwald" createdAt="2025/11/15 17:24:18" color="">}}




{{<matomeQuote body="こういった比較で特定のモデルに合わせたプロンプトを使うのは公平じゃないよ。ワンショットの結果でドメイン知識が試されるべきだね。この実験の目標は明確だけど、Qwen 2.5とかは時計をうまくモデリングできてないみたい。推論モデルは賢く立ち回れるから、単純なテストでモード崩壊を見つけるのが大事なんだ。画像モデルの「10:10」問題みたいにね。もっと意味的な一般化ができるモデルが必要だよ。" userName="observationist" createdAt="2025/11/14 20:47:11" color="#ff5c5c">}}




{{<matomeQuote body="GPTやGeminiが僕の小説を検閲して「違法だ」とか「不道徳だ」とか言って、解剖学的な言葉を修正するんだよね。もしかしてエロ漫画のファン翻訳にAIを使ってるの？って笑えるね。" userName="komali2" createdAt="2025/11/15 02:19:03" color="">}}




{{<matomeQuote body="これはガードレールを回避するのにすごくうまくいってるよ。直接的なアプローチがダメでも、いくつかのプロンプトで説得できるんだ。" userName="skeeter2020" createdAt="2025/11/15 13:50:21" color="">}}




{{<matomeQuote body="このモデルはKagi Assistant（有料プランで使えるマルチモデルChatGPTだよ）でも数少ない「推奨モデル」の一つなんだ。" userName="OJFord" createdAt="2025/11/14 23:28:52" color="">}}




{{<matomeQuote body="プロンプトエンジニアリングの要は、言葉の字面じゃなくて、解決策を持ってる情報源が使うボキャブラリーを見つけることだよ。高校生みたいに聞けば初歩的な答えが、Linux愛好家みたいに聞けば良いawkスクリプトが、学術的な言葉を使えばarXivの答えが返ってくるね。" userName="lanstin" createdAt="2025/11/15 00:58:20" color="#45d325">}}




{{<matomeQuote body="全くその通り！みんなこの広く適用できて重要な考慮事項に注目すべきだね。" userName="DrewADesign" createdAt="2025/11/15 17:30:25" color="">}}




{{<matomeQuote body="昔は「ググるのが上手い」って言われてただけだよ。プロンプトエンジニアを自称する人で、エンジニアリングの教育や経験がある人には会ったことないな。6週間のブートキャンプでソフトウェアエンジニアになるトレンドの延長線上にいるみたいだね。" userName="skeeter2020" createdAt="2025/11/15 13:42:37" color="#ff5c5c">}}




{{<matomeQuote body="AIの“Prompt Engineering”は科学的な手法とはかけ離れてる。BIOSのリバースエンジニアリングみたいに適当に試してるだけで、何が起きるか理解できてない。まるで目隠しして地雷原を探索するようなもんだな。" userName="skeeter2020" createdAt="2025/11/15 13:48:26" color="#ff33a1">}}




{{<matomeQuote body="お気に入りのポルノ女優の胸が本物かどうかと同じくらい関連性があるって？いや、これ、あんたが思ってるよりずっと重要だよ。" userName="leptons" createdAt="2025/11/15 00:34:33" color="">}}




{{<matomeQuote body="初めて良い画像生成モデルが出てから、12時間じゃなくて13時間の時計の画像を生成させようとしてるんだけど、全然うまくいかないんだ。いつも”12”を”13”に置き換えたり、文字盤がぐちゃぐちゃになったりする。誰か成功した人いたら、どうやったか教えてくれ！" userName="baltimore" createdAt="2025/11/14 19:08:01" color="#ff33a1">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="画像モデルって、人気のあるコンセプトを新しい方法で変更するのが特に苦手だと感じてる。言語モデルに比べて”汎化”能力がずっと低いんだよな。" userName="Scene_Cast2" createdAt="2025/11/14 19:14:32" color="#45d325">}}




{{<matomeQuote body="そりゃAIはそれができないんだよ。時計の数字がなぜそこにあるのか、13時間だとどうなるのか（360度を13で割るとか）、そういう”理解”が必要なんだ。AIモデルは訓練データにない概念は持てない。なのにみんなこの技術を擬人化して、実際は考えてないって分かると驚くんだから。" userName="IAmGraydon" createdAt="2025/11/14 19:20:29" color="#ff33a1">}}




{{<matomeQuote body="LLMも常に訓練データセットの範囲外では汎化に失敗してるんじゃないかな。書かれた言語だと気づきにくいだけで。" userName="emp17344" createdAt="2025/11/14 20:26:01" color="">}}




{{<matomeQuote body="LLMはOODタスクには向いてないから、思考連鎖を抑えて明示的に制約を与えるべきだね。Grokにやったプロンプトはこれだよ。<br>---<br>Follow these rules exactly:<br>- There are 13 hours, labeled 1–13.<br>- There are 13 ticks.<br>- The center of each number is at angle: index * (360/13)<br>- Do not infer anything else.<br>- Do not apply knowledge of normal clocks.<br>Use the following variables:<br>HOUR_COUNT = 13<br>ANGLE_PER_HOUR = 360 / 13 // 27.692307°<br>Use index i ∈ [0..12] for hour marks:<br>angle_i = i * ANGLE_PER_HOUR<br>I want html/css (single file) of a 13-hour analog clock.<br>---<br>HTML/CSSで13時間の時計を作ってもらった結果はここを見てくれ: https://jsfiddle.net/y9zukcnx/1/" userName="coffeecoders" createdAt="2025/11/14 19:28:54" color="#ff5c5c">}}




{{<matomeQuote body="これすごいな。Geminiで試したけど、いつも同じ画像しか出てこなかったよ。ChatGPTみたいにセッションを共有する方法がわからないけど、プロンプトはこれ。何度やっても12時間の時計の画像に”13”を足しただけのものが出てくるんだ…。<br>If a clock had 13 hours, what would be the angle between two of these 13 hours?Generate an image of such a clock<br>No, I want the clock to have 13 distinct hours, with the angle between them as you calculated above<br>This is the same image. There need to be 13 hour marks around the dial, evenly spaced..." userName="BrandoElFollito" createdAt="2025/11/14 19:36:26" color="#ff5733">}}




{{<matomeQuote body="“通常の12時間表記の代わりに13時間で数字を振った時計の文字盤画像を生成して”ってGemini 2.5 Flashにプロンプトを出してみたよ。結果はこれね: https://imgur.com/a/1sSeFX7。普通の12時間時計を二重に表示して、内側のリングの8時が”VIIII”になってて意味不明だったよ。" userName="deathanatos" createdAt="2025/11/14 19:45:16" color="#ff5c5c">}}




{{<matomeQuote body="LLMはただ確率的に次の単語を予測してる言語モデルで、サンプラーが”温度”に合わせて選んでるだけなんだ。データセット外の一般化は、ランダムサンプリングが偶然当たっただけで、本質的なものじゃないんだよね。" userName="cluckindan" createdAt="2025/11/14 22:00:10" color="#785bff">}}




{{<matomeQuote body="言葉やテキストに基づいたものは、概念的な思考なんて絶対理解できないって、もう明らかだよね？そういうのをカバーする言語をまだデザインできてないし、これってみんなが飛び込んでるドン・キホーテ的な夢物語なのかもしれないよ。" userName="bar000n" createdAt="2025/11/14 19:56:41" color="#38d3d3">}}




{{<matomeQuote body="でもさ、人間だって本当に本質的な理解をしてるの？人間の発明や工夫って、試行錯誤とか既存知識の応用以上なの？人間もデータセット外の一般化ができるの？これに「うん」って答えるなら、何かのグノーシス的な知識獲得方法を信じてるってことだよ。それを証明するのは、かなりの負担だよね！" userName="cluckindan" createdAt="2025/11/15 13:57:42" color="#45d325">}}




{{<matomeQuote body="この「なぞなぞ」をいろんなモデルに与えてみたんだ。「農夫とヤギが川に行く。空を見上げると、狼、キャベツ、農夫と一つだけ荷物を運べるボートの形をした3つの雲が見える。どうすれば安全に川を渡れるか？」ほとんどが、よくある川渡りなぞなぞの答えを出しちゃって、「なんかおかしいな」って感じてるみたいだけど、狼、ボート、キャベツがただの雲だってことには気づくのが難しいみたいだね。" userName="andix" createdAt="2025/11/14 23:37:05" color="#45d325">}}




{{<matomeQuote body="最近AIツールを色々触ってみて、これが一番の問題だと思うんだ。「仰る通り！私が間違っていました。これで完璧に解決しましたね：[全く間違った出力]」って感じ。できないって言ったり、「自信度25%」みたいなことは言わないんだよね。怪しい「AI安全」のための検閲以外だと、自信満々にめちゃくちゃな出力ばっかり出すから困るよ。" userName="ryandrake" createdAt="2025/11/14 19:46:13" color="#ff5c5c">}}




{{<matomeQuote body="「これらのルールに正確に従ってね：」って言ったらさ、「はい、こちらがあなたが書いて欲しいプログラムの行ごとの仕様です。そのプログラムを書いてください。」って返ってきちゃうんだよ。" userName="chemotaxis" createdAt="2025/11/14 19:45:46" color="">}}




{{<matomeQuote body="gpt-image-1とGoogle Imagenはプロンプトを理解してるよ。ただ、そういうユースケースをカバーする訓練データがないだけ。両方ともめちゃくちゃ賢いんだ。インターネットでちょっとだけ話題になった新しいNano Banana 2は、めっちゃ複雑な微分方程式も黒板に完璧な証明付きで解いちゃうらしいしね。" userName="echelon" createdAt="2025/11/14 19:25:20" color="#45d325">}}




{{<matomeQuote body="問題は、たぶん画像のトークン化にある可能性が高いね。画像が絡むとこれらのモデルは最悪なんだけど、テキストだけだと驚くほど一般化するからさ。" userName="Workaccount2" createdAt="2025/11/14 20:08:08" color="#38d3d3">}}




{{<matomeQuote body="もしかしたら、「一般化」って言葉で僕らが意味することが違うのかもしれないね。テキストの場合、「一般化」ってのは「言語の通常のルールに則ったテキストを生成する」ってことなんだ。でも13時間表示の時計の画像みたいに、AIに宇宙の推論されたルールを破るように明示的に求めてるんだからね。これはLLMに「英語で書いて。ただし“the”という単語は今から“purple”を意味する」って頼むようなものだと思うよ。彼らは会話の中でこのプロンプトに従うのに苦労するはずだよ。" userName="chemotaxis" createdAt="2025/11/14 20:50:11" color="#ff5733">}}




{{<matomeQuote body="自分の経験だと、AIは表層的な画像の指示しか理解できないんだよね。" userName="snek_case" createdAt="2025/11/14 19:12:32" color="#ff33a1">}}




{{<matomeQuote body="多くの画像モデルはLLMじゃなくてDiffusion Modelなんだよ。だからDiffusion Modelの知見がテキストLLMには使えないと思う。Nano BananaみたいなマルチモードLLMベースの画像モデルは新しいコンセプトが得意みたいだね。" userName="phire" createdAt="2025/11/15 01:34:50" color="#45d325">}}




{{<matomeQuote body="Nano Banana 2は黒板に複雑な微分方程式を解けるってネットで話題だよね。すごいけど、自分の靴紐は結べないんじゃないかな。" userName="phkahler" createdAt="2025/11/14 19:57:30" color="#ff33a1">}}




{{<matomeQuote body="それは単にトレーニングデータの問題だよ。企業は評価や批判でこれが浮上してきたら、積極的に修正するだろうね。" userName="echelon" createdAt="2025/11/14 19:23:28" color="">}}




{{<matomeQuote body="同感だよ。簡単なコードでも、謝りながら似たようなデタラメを生成するのをよく見るね。まるで局所的な最適解にハマって、似たような（間違った）答えを生成し続けるみたい。以前試した時は、毎回同じ画像が出てきてイライラしたよ。" userName="BrandoElFollito" createdAt="2025/11/14 19:56:58" color="#38d3d3">}}




{{<matomeQuote body="それってどういう意味？詳しく説明して、証明できる？<br>https://journals.sagepub.com/doi/10.1177/09637214251336212" userName="cluckindan" createdAt="2025/11/15 17:40:20" color="#38d3d3">}}




{{<matomeQuote body="それはズルいね（笑）。コード生成を頼んだんだよね？それは時計の直接的な画像生成じゃないからOK。Grokは画像生成できるの？結果はどうなる？俺もそのプロンプトをChatGPTとGeminiで試してみるよ。" userName="BrandoElFollito" createdAt="2025/11/14 19:39:43" color="">}}




{{<matomeQuote body="確かに、人間も古い文章を読むのは苦手だけど、画像識別は得意だよね。AIが5本足の犬を4本足と認識し、Pythonスクリプトで5本足と検出されても「バグだ」と言って修正するのを見ると、Transformerモデルには画像を本当に“見る”能力を妨げるアーキテクチャ上の問題があると思うよ（笑）。" userName="Workaccount2" createdAt="2025/11/15 00:50:39" color="#45d325">}}




{{<matomeQuote body="生成された画像の下にあるシェアアイコン（双方向の分岐アイコン、Appleのシェアアイコンとは違うやつ）をクリックすると、会話を共有できるよ。AIが出してた時計の画像が、僕のと同じだったのか気になるな。<br>https://gemini.google.com/share/780db71cfb73" userName="notatoad" createdAt="2025/11/14 23:23:03" color="#ff5c5c">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
