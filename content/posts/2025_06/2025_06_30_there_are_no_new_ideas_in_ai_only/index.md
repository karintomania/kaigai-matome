+++
date = '2025-06-30T00:00:00'
months = '2025/06'
draft = false
title = 'AIに革新的なアイデアなんてない？あるのは「新しいデータセット」だけだ'
tags = ["AI", "データセット", "機械学習", "技術論", "進化"]
featureimage = 'thumbnails/light-orange3.jpg'
+++

> AIに革新的なアイデアなんてない？あるのは「新しいデータセット」だけだ

引用元：[https://news.ycombinator.com/item?id=44423983](https://news.ycombinator.com/item?id=44423983)




{{<matomeQuote body="正直、AIはまだまだ初期段階だと思う。言語と視覚ではすごい進歩を見せたけど、それだけじゃん。人間って触覚とか味覚とか、いろんな感覚で世界を理解してるのに、今のAIはそこを全然捉えられてないんだ。<br>本当のAIのフロンティアは、人間が生きる感覚に満ちた世界にあるはず。そのためには、新しいハードウェアやデータ形式、学習方法が必要だよ。" userName="voxleone" createdAt="2025/06/30 17:51:39" color="#38d3d3">}}




{{<matomeQuote body="最初のコメントの「言語と視覚は知能の中心じゃない」ってのには反対だな。オンラインの世界では言語、動画、音声で十分だし、人間と猿を比べても、言語とか視覚・聴覚こそが決定的に違う部分だと思うんだ。<br>他の感覚も面白いけど、知能の話ならやっぱりそっちが重要じゃない？" userName="dinfinity" createdAt="2025/06/30 18:39:48" color="">}}




{{<matomeQuote body="「驚くべき進歩」って言うけど、AIは1970年代の技術を今のすごい機械で動かしてるだけじゃない？ これが進歩なのか疑問だし、モデルとか計算方法で劇的に性能が上がる見込みもなさそうに見えるんだけど。" userName="timewizard" createdAt="2025/07/01 00:24:57" color="">}}




{{<matomeQuote body="さっきのコメントで「言語と視覚が知能の中心じゃない」って言っちゃったけど、あれはちょっと言い過ぎだったかも。でも、人間の認知にはどんな感覚も大事だって意見は変えないよ。" userName="voxleone" createdAt="2025/06/30 19:08:38" color="">}}




{{<matomeQuote body="言語って感覚とか認知を抽象化したものだよね。今の生成モデルは出力だけを真似てる感じで、身体性っていう土台がないから、時空間とか因果関係みたいな大事な理解がなくて、推論がめっちゃ弱いんだと思う。" userName="computably" createdAt="2025/07/01 07:48:45" color="#45d325">}}




{{<matomeQuote body="AIに必要なのは、有機的な適応と記憶の持続性だと思う。人間の神経は変化するけど、LLMは固定されててリアルタイムに学習したり記憶したりできないんだ。<br>本当に賢い機械を作るなら、自分でリアルタイムで学んで記憶する能力がないとダメだよ。" userName="mr_world" createdAt="2025/06/30 20:33:39" color="#38d3d3">}}




{{<matomeQuote body="「言語と視覚は始まり」って言うけど、今のAIの仕組みだと、もう終わりが近いかもね。ここ数年LLMのニュースばっかりで、他のAI分野で何かすごいブレークスルーってあったっけ？ 俺はあんまり聞かないな。" userName="chasd00" createdAt="2025/06/30 19:00:30" color="">}}




{{<matomeQuote body="「言語は感覚の抽象化」って意見に反対。言語は感覚とか認知から独立して存在できるよ。プログラミング言語みたいにね。<br>身体性は面白いけど、別に知能に絶対必要ってわけじゃないと思う。量子力学みたいに、身体の感覚が邪魔になることだってあるんだから。" userName="dinfinity" createdAt="2025/07/01 09:18:04" color="">}}




{{<matomeQuote body="最初のコメントの「真のAIは感覚世界に」って話、マジで同意。ドクター・フーのダーレクみたいに、人間も体全体が自分なんだよ。体を運転してるだけじゃないってこと。" userName="Swizec" createdAt="2025/06/30 17:59:02" color="">}}




{{<matomeQuote body="人間の手と指は、並外れた繊細さで知られてるんだ。物を操作する能力で人間に匹敵する動物は数少ないよ。タコ、ゾウ、類人猿だけが、器用さと繊細さにおいて同じくらいだね。" userName="azeirah" createdAt="2025/07/01 12:29:06" color="">}}




{{<matomeQuote body="体の麻痺があるのに、電動車椅子で自分の体を文字通り運転して精神的に発達した人がたくさんいるよね。現代のAIが持ってる入力（テキスト、動画、音声）だけで、瓶の中に脳が存在したり発達したりできないなんて証拠はまったくないと思うな。" userName="nomel" createdAt="2025/06/30 19:54:17" color="#38d3d3">}}




{{<matomeQuote body="視覚は、この宇宙で周りの情報を簡単に集められる最速のスピードを利用してるのが面白いよね。だから特別で、すごく価値があるんだと思う。<br>言語は世界の情報をエンコードして圧縮できるから、もちろん信じられないくらい強力で、コミュニケーションの帯域幅をめちゃくちゃ増やせるんだ。<br>高レベルの認知プロセスには、聴覚と発話が重要な足がかりだったって言えるかな。何らかの理由で、音声で比較的高い帯域幅の信号を生成できる器官を進化させる方が、視覚でそれをするもの（自然界にテ○タビの画面みたいなお腹はほぼない）を進化させるより簡単なようだからね。<br>この意味で考えるのが面白いゲーム：絵しりとりやジェスチャーゲーム。" userName="dinfinity" createdAt="2025/07/01 05:14:16" color="#38d3d3">}}




{{<matomeQuote body="「1970年代の古い技術を引っ張り出してきて、100万倍パワフルなマシンで使っただけ。これを進歩と呼べるかどうかわからない」<br>もしこれが皮肉とかじゃないなら、君には本当にエキサイティングな研究と学びが待ってるよ！今のところ「コンピューターなんてただの足し算と掛け算で、それは何千年も前からあるじゃん！」って聞こえるね。" userName="petesergeant" createdAt="2025/07/01 04:44:30" color="#ff5c5c">}}




{{<matomeQuote body="そうだね、でも新しいアイデアってあるの？それとも単なる願い？" userName="skydhash" createdAt="2025/06/30 18:09:13" color="">}}




{{<matomeQuote body="忘れることってなぜ重要なんだろう？適用されなくなる期限があるものや、本当だと思ってたことが間違いだと判明しても、どこで間違えたのかを見るのに役立つよね。<br>人間はシナプスの数に制限があるから忘れるのが役に立つんだろうけど、機械は使えないものをディープストレージに移して、人間の深い記憶があるきっかけで掘り起こされるのと同じように、必要になったら取り出せるのかもしれないね。" userName="8n4vidtmkvmk" createdAt="2025/07/01 06:28:19" color="#ff5733">}}




{{<matomeQuote body="これは純粋な魔術的思考だよ。AIがくっついてなければ、正しく一蹴されるような話だ。<br>他のことならこんな話し方はしないだろうね。<br>「Rustはまだ表面をかじっただけで、今のところコードにしか焦点を当てていないし、豪邸を建てたり世界の飢餓を終わらせたりすることはまだ探求してない」みたいに、他の何かについてこんな話し方をするのを想像してみてよ。" userName="jdgoesmarching" createdAt="2025/06/30 18:51:12" color="#45d325">}}




{{<matomeQuote body="タッチってかなりクールなスキルをくれるよね。言語、動画、音声はオンラインインタラクションに必要な全部だけどね。タイピングやポインティングにタッチを使うのは、より効率的で効果的なインターフェースがないからなだけかもしれないけど。<br>大人は何か重要なことにタッチを使ってないかもしれない。でも赤ちゃんは周りのものを探検するためにタッチに頼ってるんだ。何でも口に入れるのはなぜ？舌が一番触覚が敏感な器官だからだよ。舌で触ってものを探検してるんだ。<br>そこから何を学んでるかは推測しかできないけど、写真やテキストを処理するだけでは手に入れるのが難しい、幾何学とか物体の表面特性の理解を得てるんじゃないかな。<br>「君のコメントは特に知能についてだった」<br>知能について話すと、LLMは3D空間や物質科学の深い理解や直感なしに人間に匹敵できるとは信じないよ。少なくとも触覚と温度感覚が必要だ。たぶん何十億もの単語でこれらのことを記述したテキストで置き換えることはできるかもしれないけど、それは疑わしいな。" userName="ordu" createdAt="2025/07/01 14:29:40" color="#ff33a1">}}




{{<matomeQuote body="それらの感覚の一つ、あるいは二つを欠いている人でも、普通にうまくやってるよ。" userName="wizzwizz4" createdAt="2025/06/30 19:56:58" color="">}}




{{<matomeQuote body="「瓶の中に脳が存在したり発達したりできない証拠」について。<br>脳はできるよ。もちろんできる。それはただの信号処理マシンだからね。<br>でも、人間が考える上で核になると考える何かを失うことになるんじゃない？認知の一部で苦労するんじゃない？<br>例えば、縦線だけの環境で育った猫を使った実験があったよね。彼らは普通の部屋に入れられた時、平らな表面を理解するのに苦労したんだ。<br>https://computervisionblog.wordpress.com/2013/06/01/cats-and..." userName="Swizec" createdAt="2025/06/30 20:26:00" color="#45d325">}}




{{<matomeQuote body="化学分野でノーベル賞が2つも出てるよ。見てみて：https://www.nature.com/articles/s41746-024-01345-9" userName="nomel" createdAt="2025/06/30 20:09:21" color="">}}




{{<matomeQuote body="視覚コミュニケーションについてだけど、姿勢やジェスチャー、顔の表情を少し軽視しすぎじゃない？話し言葉ほど帯域幅は高くないけど、遅延がすごく少なくて、必要ならかなりステルスにできるんだ。" userName="actionfromafar" createdAt="2025/07/01 12:21:51" color="">}}




{{<matomeQuote body="＞君には本当にエキサイティングな研究と学習が待ってるね<br>研究は終わってるんだよ。だからその点を指摘したんだ。君は反論もせず、見下して失礼だね。それは見せかけの知性の紙帽子だよ。あくびが出るね。<br>＞現時点では「コンピューターはただの足し算と掛け算で、それは何千年も前からある！」みたいに聞こえるね<br>じゃあ具体的に言おう。モデルの問題点は、モデル生成に指数関数的なコスト増加が必要なのに、出力性能は線形にしか増えないことだ。このコストカーブは、現在のハードウェア性能向上のカーブより悪いくらいだよ。つまり、根本的なアルゴリズム改善が全く見られない限り、これは厳しい状況に追い込まれてる。何十億ドルもの投機的資金をつぎ込んでも改善は見られないんだ。要するに、AI冬の時代2.0だよ。それについて何か計画はあるの？それに対処する具体的な研究は？この件について君自身の考えは？" userName="timewizard" createdAt="2025/07/01 09:05:02" color="#38d3d3">}}




{{<matomeQuote body="ノーベル賞を2つも取るって、十分な進歩じゃないの？" userName="ekunazanu" createdAt="2025/07/01 03:36:37" color="">}}




{{<matomeQuote body="なるほど、手話があるもんね。それなら君の言う通りかも。ジェスチャーの帯域幅が話し言葉と比べてどうなのか、興味深いね。これについてもう少し考えてみたんだけど、ジェスチャーより音を使うのが一般的なのは、音が遠距離や視界が悪くても伝わる放送メカニズムだからだと思うな。自分の縄張りを視覚的に示すのは結構大変だもんね。" userName="dinfinity" createdAt="2025/07/01 16:33:11" color="">}}




{{<matomeQuote body="使わないコードを削除する？散らかってるのを片付ける？習慣を変えようとしたことある？" userName="specialist" createdAt="2025/07/03 15:01:07" color="">}}




{{<matomeQuote body="進歩ってノーベル賞で測るの？あれって機関の委員会による投票って理解だけど。それはさておき、2024年の共有賞は1970年代、80年代の研究に贈られたんだよね。これは私のポイントを確認するために言ったの？見事にやってくれたね。2022年にはベン・バーナンキ氏に送るのが適切と判断されたんだ。そう、あのバーナンキだよ。冗談抜きで、金融危機のインパクトに関する研究に対してだよ。皮肉にも、これも元々は1970年代、80年代の研究だ。" userName="timewizard" createdAt="2025/07/01 09:01:14" color="#785bff">}}




{{<matomeQuote body="この考え方への反論の一つは計算コストだと思うよ。AIのすごい進歩は、技術（Transformer）やデータセットよりも、ハードウェアと計算能力の進歩が最大の要因だ。もし20年前にTransformerや今のデータセットがあっても、当時のハードウェアではLLMの学習は無理だった。で、LLMはすでに今の計算能力を限界まで使ってる。だから、新しい10倍とか100倍の計算能力アップがない限り、だいたい今のレベルで停滞する可能性がめっちゃ高い。そうなると、今の100倍のデータでモデルを学習させるなんてほぼ無理で、それは複数のモダリティを追加して組み合わせるのに多分必要だろうね。" userName="tsimionescu" createdAt="2025/07/01 09:53:09" color="#ff33a1">}}




{{<matomeQuote body="CとかJavaって低レベルな動きを無視してるから意味ないの？いや、動くマシンの文脈では重要でしょ。言語にとっても低レベル認知って、C/Javaにとってのマシンみたいに重要かもね。" userName="pjmorris" createdAt="2025/07/01 14:22:24" color="#38d3d3">}}




{{<matomeQuote body="技術進歩と科学進歩って混同しがちだよね。科学は新しいS字カーブを生み出すけど、最初は急成長、後で鈍化。みんな停滞って言うけど、急上昇期は最適化がすごかっただけで、新しい進歩はゆっくりだったんだ。" userName="tippytippytango" createdAt="2025/06/30 17:33:55" color="#ff5c5c">}}




{{<matomeQuote body="うんうん、マジ同意。あとS字カーブと指数関数の区別つかない人多いよね。あるとこだけ見ると似てるけど全然違うんだ。" userName="baxtr" createdAt="2025/06/30 20:25:10" color="">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="2017年にさ、自動化は事務や芸術家をコピーできるけど、人類は置き換えられないって言ってめっちゃ叩かれたんだよね。Moore’s lawとか言われたけど、技術ってこう進むんだよ。新しいもの見つけて、使い倒して、飽きて後始末って感じ。" userName="protocolture" createdAt="2025/07/01 03:13:09" color="#ff5733">}}




{{<matomeQuote body="最近痛感してむかつくことなんだけどさ、正しいことと成功することって違うんだよ。" userName="the_sleaze_" createdAt="2025/07/01 14:03:27" color="">}}




{{<matomeQuote body="マジで大事なのは、今やってるのがエンジニアリングの改善なのか、それとも新しい科学の大発見の一歩手前なのかを見分けることだよ。" userName="TimByte" createdAt="2025/07/01 07:30:58" color="#785bff">}}




{{<matomeQuote body="単なる流行を『技術進歩』って言うなんて、ずいぶん甘い見方するね。" userName="timewizard" createdAt="2025/07/01 00:26:21" color="">}}




{{<matomeQuote body="それは原因と結果が逆だよ。熱力学は蒸気機関の後、飛行は空力学の後、冶金は材料科学の前。LLMだって科学的洞察より試行錯誤の結果でしょ。成功した実験が、後から科学が理論化するネタを作るんだ。" userName="pevansgreenwood" createdAt="2025/07/01 01:07:54" color="#38d3d3">}}




{{<matomeQuote body="John Carmackの実験って結構示唆深いよ。AIに2Dゲームをめちゃくちゃやらせて、知らないレベルやゲームをやらせると全然ダメ。これって知能じゃなくて狭いタスクの専門知識でしょ。汎用AI作るより、ASIでみんなを怖がらせる方が簡単だよね。" userName="EternalFury" createdAt="2025/06/30 18:22:50" color="#ff5733">}}




{{<matomeQuote body="「転移関数が負ってどういうこと？ 同じモデルで、Aを superhuman レベルにしてから似たゲームBをやるのと、最初からBをやるので差があるか実験したのかな？ 差がなけりゃ、知識を転移してないか、プログラムミスかもね。" userName="ferguess_k" createdAt="2025/06/30 18:41:47" color="#45d325">}}




{{<matomeQuote body="問題はね、モデルにパターンマッチングを学習させてるだけで、世界モデルを学んだり推論させたりしてないことだと思うんだ。" userName="tough" createdAt="2025/06/30 18:43:22" color="">}}




{{<matomeQuote body="つまり、彼らはゲームを覚えてるだけで、ゲームのやり方を学んでるわけじゃないってことだね。" userName="NBJack" createdAt="2025/06/30 18:44:35" color="">}}




{{<matomeQuote body="答え自体は覚えてるけど、どうやってその答えになったかのプロセスは覚えてないんだよ。" userName="fsmv" createdAt="2025/06/30 18:51:47" color="">}}




{{<matomeQuote body="そんなの何度も反証されてるじゃん... 彼らは明らかに両方やってるよ。自分で簡単に証明できるって。" userName="IshKebab" createdAt="2025/06/30 19:00:55" color="">}}




{{<matomeQuote body="＞自分で簡単に証明できるって。<br>亡くなった心の哲学者がたくさんいる中で、そんな簡単に証明できるなら、ぜひリンクを教えてくれない？" userName="0xWTF" createdAt="2025/06/30 19:33:40" color="#38d3d3">}}




{{<matomeQuote body="なんでみんなこんな言い方にこだわるんだろうな。きっと目標を達成する方法はあるはずだよ。John Carmackは別にAIの専門家じゃないのに、なんで急に基準扱いなんだか。" userName="justanotherjoe" createdAt="2025/06/30 19:38:29" color="#38d3d3">}}




{{<matomeQuote body="彼（筆者）はこの結論出すのに適切なモデルも最新モデルも使ってないし、2Dゲーム向けの基盤モデルもないんだ。これただの楽しいプロジェクトだよ。<br>ビデオ/ビジョンの真剣な試みなら、ゲーム全般に合うノイズをかけられる確率的潜在空間が必要だろうね。veo3ってモデルは、AIが2Dも3Dも一般化できるって証明してると思うよ。veo3にどんなゲームでも数秒やらせてみれば、ファインチューニングしてなくても大体ちゃんと動くはずだよ。" userName="vladimirralev" createdAt="2025/06/30 18:56:31" color="#785bff">}}




{{<matomeQuote body="すごく簡単だよ。Claudeに行って、新しい質問をしてみなよ。学習データに直接の例がなくても、大抵はちゃんと推論して良い答えを出すからさ。" userName="pdabbadabba" createdAt="2025/06/30 20:14:49" color="#785bff">}}




{{<matomeQuote body="それが新しい質問だって、どうやって分かるの？" userName="MichaelZuo" createdAt="2025/06/30 21:04:22" color="">}}




{{<matomeQuote body="ちょっとさ、ChatGPTとかClaudeに学習データに絶対ないような無理なプログラミングタスクやらせてみてよ。<br>例えば、”隣の文字がアルファベット順で隣接してる場合だけ文字列の文字を残すPython関数を書いて”とかね。<br>暗記だけなら絶対無理だけど、きっとできるはずだよ。<br>これ、ツール使ってる人にはめっちゃ当たり前なのに、いまだに”暗記だけ”って言ってる人がいるの、マジで変だよね。" userName="IshKebab" createdAt="2025/06/30 21:14:02" color="#38d3d3">}}




{{<matomeQuote body="”AI guy”って誰のこと？<br>この分野って結構新しいし、ここ数年でマジで変わったじゃん。<br>ジョン・カーマックは2022年にKeen technology作ったし、2019年から本気でAIやってるよ。<br>ゲーム業界出身だから、線形代数とかGPUとか、基礎となる数学やハードウェアのことめっちゃ知ってるし。<br>だから、ぶっちゃけ彼は今や”AI guy”でしょ。" userName="GuB-42" createdAt="2025/06/30 23:21:09" color="">}}




{{<matomeQuote body="でもさ、その理屈、ちょっと変じゃない？<br>彼が作ったAIシステムがXができなかったからって、XができるAIシステムが他にないってことにはならないでしょ。<br>特に、AIはめっちゃ進化してるって言ってるんだからさ。<br>まあ、Carmackは最新ハードウェアでの計算の最適化に詳しいのは確かだけど、それはAIには必要でも、それだけじゃダメなんだよ。" userName="amelius" createdAt="2025/06/30 23:38:58" color="">}}




{{<matomeQuote body="訓練データに絶対入ってないような、すっごい珍しい質問を思いつくのって、全然難しくないでしょ。" userName="IshKebab" createdAt="2025/06/30 21:15:10" color="">}}




{{<matomeQuote body="LLMってさ、人間みたいに概念を”記憶”してるわけじゃないんだよね。<br>訓練データのトークンパターンから出力を生み出してるだけ。<br>だから、全部の問題を学習しなくても、一番可能性の高いトークンの組み合わせを探して、答えっぽいものを作れる。<br>人間には新しい問題を解いてるみたいに見えるけど、要は統計的なトリック。<br>人間にはできないパターンを見つけて作れるのがすごいけど、それが”知性”かって言われると違うと思うな。" userName="imiric" createdAt="2025/06/30 21:34:22" color="#ff5c5c">}}




{{<matomeQuote body="そういう、本当にユニークな質問の例をいくつか教えてくれない？" userName="MichaelZuo" createdAt="2025/06/30 22:11:01" color="">}}




{{<matomeQuote body="＞ AIシステムXがYができなかったとしても、Yができる別のAIシステムがないとは言えないよ。<br>ここでそれを証明する責任があるのは、あなたの方じゃない？" userName="PeeMcGee" createdAt="2025/07/01 05:26:30" color="">}}




{{<matomeQuote body="＞人間には新しい問題を本当に解いているように見える<br>だってそうなんだもん！<br>これ、意味不明な言葉遊びだよ。こんな馬鹿げた話に付き合うのやめるべきだ。<br>Turing testに結構近いAIがあるのに、まだ知的じゃないって言う人がいるんだからさ..." userName="IshKebab" createdAt="2025/07/01 06:37:32" color="#38d3d3">}}




{{<matomeQuote body="AIモデルがAtariとか2Dゲームを超人的レベルでプレイしたって話、どうなのかなって思ってたんだ。<br>モデルが出る前から、一部の人間はもう超人的なレベルだったのを覚えてるから。<br>たぶん、”平均的な”プレイヤーと比べてってことなんだろうけど、ゲームを極めた人とは違うよね。" userName="goatlover" createdAt="2025/06/30 20:28:33" color="">}}




{{<matomeQuote body="俺も大体同じ意見かな...<br>たぶん、”パターンマッチング”の定義が人によって違うんだろうね。" userName="ferguess_k" createdAt="2025/06/30 19:33:43" color="">}}




{{<matomeQuote body="「genuinely」ってのがよく分かんないけど、コーディングだとLLMはいつも新しい質問に答えてるよ。俺のコードベースは唯一無二だけど、LLMは仕組みやバグを詳しく説明したり、修正したり機能追加もできる。これって「新しいデータセット」だけってわけじゃないんじゃない？" userName="pdabbadabba" createdAt="2025/07/02 13:41:02" color="">}}




{{<matomeQuote body="これ、面白いね。人間が知識を「転移」する能力（初めて見るゲームでもすぐ理解するとか）って、実はそんなに万能じゃないんだ。特定の「近さ」の範囲でしか通用しない。例えば、マリオのフーリエ変換バージョン渡されたら、全然分かんないでしょ？<br>VVVVVVとかBraidみたいな空間変換ギミックは直感的だけどね。つまり、知能は「自然な」変換には強いけど、どんな表現でも対応できるわけじゃないみたい。ハイパースペシャリストしか作れない現状を見ると、「汎化能力」って結局人間ができることの模倣なだけ？って疑問に思うね。" userName="IIAOPSW" createdAt="2025/07/01 06:14:29" color="#785bff">}}




{{<matomeQuote body="パターンマッチングと世界モデルでの推論って、どこで線引くの？知能の多くは、ただ素早くパターンマッチングしてるだけだよ。" userName="antisthenes" createdAt="2025/06/30 19:07:25" color="">}}




{{<matomeQuote body="LLMが「ミラーテスト」に成功した例、知ってるでしょ？スクリーンショットの自分を認識して「私」って言うやつ。あれ、「LLMミラーテスト」なんて概念、1年くらい前まで存在しなかったんだよ。あれこそ「真に新しい問い」への回答じゃないかな。" userName="hackinthebochs" createdAt="2025/06/30 23:53:10" color="#38d3d3">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="なんでそう思うの？AIはもう沢山のゲームで人間を超えてるじゃん。チェス、Go、麻雀、テキサスホールデム、Dota、Starcraftとかさ。AtariゲームでAIが最高の人間プレイヤーに勝てないなんて、マジでありえないくらい驚きだよ。" userName="raincole" createdAt="2025/06/30 20:53:36" color="#ff5c5c">}}




{{<matomeQuote body="Veo3の世界モデルはまだ結構限界があるよ。YouTubeにないような配布外の動画とか、複雑な人間行動を生成させようとするとすぐ分かる。写実的な質感や光は超得意だし、水の流体シミュレーションもそこそこ上手い。でも、複雑な人間行動（特に特定の動き）は訓練データが足りてないんだよね。まあ、これはモデルの欠陥じゃなくて、物理ベースのシミュレーションで補うとか、そのうち克服できると思うけど。" userName="sigmoid10" createdAt="2025/06/30 20:42:12" color="">}}




{{<matomeQuote body="ここで「もう解決済み」「彼は下手なだけ」とか言ってるコメント見るの、嫌だな。筆者はこの問題に長い時間取り組んでるんだよ。分野を進歩させようとしてるんだからさ。それに言うまでもなく、彼はコンピューターエンジニアリングのレジェンドだよ。<br>「彼はただ下手」とか「これは前に解決済み」って言うなら、「解決策」を具体的に指摘して、どう機能するかも示すべきだよ。<br>俺の意見では、今のモデルの問題は、人間みたいに分類的に学ばないこと。「ライオンは動物、動物は生きてる。ヤギも動物だからヤギも生きてる。」みたいな。あるいは、ゲームで「最初はこれでレベル上げして、次にこっちのアビリティを育てる。最初は前者で戦って、後者が育ったらスタイル変えよう」みたいに、理論に基づいて戦略立てて、経験で修正するやり方。今のAIモデルは、全体を最適化問題として、勝率上がるものを適当に探してるだけ。これは人間みたいに理論と経験を組み合わせてスケールさせるやり方ほど効率的じゃない。例えば、人間はゲームにアーリーゲームという概念があって、そこで得たものが後で大きく差になるって innately に理解できる。これもパターンマッチングだけど、もっと高いレベルなんだ。理論は、何でも試すより学習をスケールさせるんだよ。" userName="ozgrakkurt" createdAt="2025/07/01 01:53:51" color="#ff5733">}}




{{<matomeQuote body="Keenには、リチャード・サットンとかジョセフ・モダイールみたいな研究者がいるんだよ。それにジョンはもうフルタイムで5年近くやってるから、彼の経歴や学習能力考えたら、もうAI博士のかなりの割合の人よりAI詳しいんじゃない？" userName="qaq" createdAt="2025/06/30 19:59:10" color="">}}




{{<matomeQuote body="まあね…もし人生でゲームを1つしかやったことなかったら、他のゲームはかなり下手になるだろうね。これってそんなに目新しいことじゃない気がするな。" userName="IshKebab" createdAt="2025/06/30 18:59:31" color="">}}




{{<matomeQuote body="ちょっと思ったのと違うな。新しいアイデアって、全部古いアイデアからきてるんだよ。AIは古いアイデアを速く見つけたり、今までなかった新しい見方で見たりできる道具なんだ。イノベーションって、古いアイデアの隙間（穴とか交差点とか）で見つかるんだって。巨人の肩の上に立つって言うでしょ？AIは巨人の肩への特急エレベーターかもね。結局はAIをどう使うかだよ。" userName="jschveibinz" createdAt="2025/06/30 17:24:45" color="#ff5c5c">}}




{{<matomeQuote body="古いアイデアにアクセスするのは得意だけど、新しい視点はそうでもないかもね。LLMはデータ解釈で手伝えることもあるけど、全く新しいものを作るのはまだ苦手だよ。たいていのことと同じで、真実はその中間にあるんだ。LLMは研究の一部を速くするのには使えるけど、全部じゃないってことだね。" userName="alfalfasprout" createdAt="2025/06/30 17:40:13" color="">}}




{{<matomeQuote body="古いアイデアにアクセスして新しい視点を得るって話、特許データベースで昔はダメだったけど今なら使えるアイデアを探せないかなって思うよ。今の技術や新しい材料、あるいは別の使い方ならイケるかもって。" userName="stevep98" createdAt="2025/06/30 18:58:40" color="">}}




{{<matomeQuote body="記事はAIの革新かデータのどっちが大事かって話をしてるよね。新しいアイデアも重要だけど、システムを良くするにはデータが大事なんだ。多くの人がデータを改善の一番の道だと思ってるよ。昔のAIの話で、データが増える-＞層が増える-＞また繰り返す、っていうサイクルを思い出したな。あなたのコメントが、この二つの改善の道とどう関係するのか、よくわからないんだ。" userName="bcrosby95" createdAt="2025/06/30 18:02:27" color="">}}




{{<matomeQuote body="もし人間が、人類が作った全ての知識をぜーんぶ読み込んで、それでも全く新しいアイデアを出せないなんてこと、想像できる？いや、想像しにくいよね。" userName="baxtr" createdAt="2025/06/30 20:26:54" color="">}}




{{<matomeQuote body="この違いは多分「読む」の意味にあると思うんだ。「読む」って書いたとき、人間は「読んでちゃんと理解した」か「理解しようとして読んだ」って意味で使うけど、LLMの「読む」は「ただ単語を数字に変えただけ」で「意味を理解したわけじゃない」んじゃないかな。「理解する」って何かっていう細かい話になるけど、それは大歓迎だよ。" userName="mdaniel" createdAt="2025/07/01 02:01:39" color="#785bff">}}




{{<matomeQuote body="そう、そこがポイントなんだよ、足りないところ。AIはまだ本当の意味で理解したり、自分の中に取り込んだりできないんだ。それがAGIとかシンギュラリティのレベルだろうね。まだそこにはいない。いくらデータを大量に入れても、今のやり方じゃそこには行けないだろう。もし人間が全てのデータを持ってたら、きっと面白いものを思いつくはず。でもそれも簡単じゃないだろうね。知識があっても、勝手にアイデアが湧いてくるわけじゃないから。AIに、関係なさそうなもの同士を無理やりつなげさせてみたらどうかな？斬新なものって、まだ誰も調べてないけど可能性がありそうなところに隠れてるんじゃない？でも、何が面白いかって、どうやって判断させるんだろう？" userName="8n4vidtmkvmk" createdAt="2025/07/01 06:38:34" color="#785bff">}}




{{<matomeQuote body="そういう全知の人間でも、結局何も新しいアイデアを出せない可能性もあるよね。" userName="hugh-avherald" createdAt="2025/07/01 02:37:29" color="">}}




{{<matomeQuote body="新しいアイデアを思いつくのも大変だけど、それを確かめるための実験方法を考えるのが難しいよね。" userName="melagonster" createdAt="2025/07/01 05:13:06" color="">}}




{{<matomeQuote body="「新しいアイデアは全部古いアイデアから生まれる」って意見に反論。ベンゼン環の構造が分かったのって、夢の中だったんだって。それまで誰も見たことなかったけど、自分の尻尾を噛む蛇のイメージとして思いついたらしいよ。" userName="jjtheblunt" createdAt="2025/06/30 18:10:58" color="#38d3d3">}}




{{<matomeQuote body="AIに革新的なアイデアなんてない？って話だけど、みんな知ってるベンゼンの構造を発見したケクレも、全くの素人がゼロから閃いたわけじゃないんだよ。経験豊富な化学者たちが長年悩んでた問題で、夢で閃いたってケクレ自身が言ったのは25年後だし、その説も10年後に修正してるんだ。アイデアって、既存の知識の積み重ねや組み合わせから出てくるんじゃないかな。<br>https://en.wikipedia.org/wiki/August_Kekul%C3%A9" userName="troupo" createdAt="2025/06/30 21:28:32" color="">}}




{{<matomeQuote body="全くその通り！もし科学の世界で同じような門番ロジック（gatekeeping logic）を使ったらどうなると思う？他の人の研究やその派生物を使っちゃダメってなったら、全く進歩しないよね。ここで唯一まともな反論として見かけるのはIPとか著作権侵害の話だけど、正直そんなことどうでもいいんだ。" userName="gametorch" createdAt="2025/06/30 17:36:52" color="">}}




{{<matomeQuote body="公平に見て、もし人間並みの知能を再現できるシステムを想像するなら、‘データセットを変える’ってのは、異なるモデルを作るために必要なことの妥当な要約だろうね。だって、俺たちの記憶、訓練、教育、背景なんかも、俺たち自身の問題解決能力の非常に大きな部分を占めてるわけだからさ。" userName="kogus" createdAt="2025/06/30 17:17:17" color="#785bff">}}




{{<matomeQuote body="モデルアーキテクチャを扱ったり論文を読んでたら、新しいアイデアがたくさんあるって知らないわけないだろ？面白い結果が出るのはほんの一部だけどね。PyTorchみたいなライブラリが、みんなを既成のソリューションに頼らせて基本的な概念を考えさせなくしてるんじゃないか、ってちょっと疑問なんだ。他の人のtokenizerやvision modelをくっつけて、単にチェックボックスを埋めてるモデル、どれだけあるんだろうね？" userName="strangescript" createdAt="2025/06/30 20:38:52" color="#785bff">}}




{{<matomeQuote body="それは人間の世界のすごく普通のやり方だよ。ある時点で基礎的な探求がROIを生み出さない場合、例えばVC資金で大量の計算力を使って他の場所で進歩できるなら、そっちに少ない人数しか行かない。でも、他の分野が限界に達すると、優秀な人たちは努力に見合う大きな成果が得られる場所を探し始めるんだ。そして、次世代のPyTorchや基盤技術が進化していくんだよ。" userName="thenaturalist" createdAt="2025/06/30 21:35:15" color="">}}




{{<matomeQuote body="ハードウェア（GPU）のアーキテクチャ的な限界の方が、PyTorchよりも研究を遅らせてるかもしれないね。Hardware Lotteryって呼ばれてる現象だよ。<br>https://hardwarelottery.github.io/" userName="delifue" createdAt="2025/07/01 05:24:53" color="#785bff">}}




{{<matomeQuote body="俺は10年間、BitGrid [1] っていうやつをハードウェア・ロッテリーのチケットにしようと頑張ってるんだ。[1] https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu..." userName="mikewarot" createdAt="2025/07/01 18:23:16" color="">}}




{{<matomeQuote body="うん、それでも、最後の結構大きなアーキテクチャ改善からまだ2〜3年くらいだよ。3年って期間がどれだけ短いか分かってない人もいると思うな。でも、データセット以外にも、今たくさんの面白くて役に立つ研究が進んでるよ。LLM以外の分野でもね。俺はLLMやってないけど、新しいものが定期的にたくさん出てくるのを見てるからそう思うんだ。" userName="mardifoufs" createdAt="2025/07/01 00:11:33" color="#ff5733">}}




{{<matomeQuote body="逆だよ。PyTorchみたいなフレームワークはすごく柔軟なんだ。どんなアーキテクチャでも実装できるし、もし足りなければCUDAだって学べる。Kerasはその逆で、君が言ってるみたいに固定的だろうね。" userName="_giorgio_" createdAt="2025/07/01 00:39:06" color="#ff5c5c">}}




{{<matomeQuote body="そういうことを考えないような人たちは、PyTorchがなくてもたぶん実験的な開発なんてしないだろうね。" userName="kevmo314" createdAt="2025/06/30 21:16:22" color="">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
