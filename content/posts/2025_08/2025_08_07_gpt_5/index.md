+++
date = '2025-08-07T00:00:00'
months = '2025/08'
draft = false
title = 'GPT-5と最新AIの衝撃！もう区別できない性能レベルに？'
tags = ["AI", "LLM", "AGI", "GPT", "テクノロジー"]
featureimage = 'thumbnails/red2.jpg'
+++

> GPT-5と最新AIの衝撃！もう区別できない性能レベルに？

引用元：[https://news.ycombinator.com/item?id=44826997](https://news.ycombinator.com/item?id=44826997)




{{<matomeQuote body="AGIを達成した企業が独走するってよく言われるけど、今のところ逆で、AIモデルが進化するほど各社の性能は似てきてるよ。GPT-5、Claude Opus、Grok 4、Gemini 2.5 Pro、どれもかなり優秀だしね。競争は今が一番激しいと感じるから、急激な技術飛躍や勝者総取りみたいな話にはちょっと懐疑的になってきた。AI研究者の意見を聞きたいな。" userName="highfrequency" createdAt="2025/08/07 18:05:12" color="#ff5733">}}




{{<matomeQuote body="テキスト予測の確率的モデルで、高レベル知能のシミュレートは無理かもね。AI研究者の友達も、学習データに対する diminishing returnsでLLMベースのAGIは心配してないらしい。人間は学習データが少なくても汎用性が高いから、LLMとは違うよな。LLMは訓練データにある知識を吐き出すだけだし。でも、AGIじゃなくても世界を変えるAIは作れるはず。検索みたいに、既存のAI＼ML＼SL技術だけで大きな影響を与えられる応用もあるしね。" userName="beeflet" createdAt="2025/08/07 18:17:24" color="#ff33a1">}}




{{<matomeQuote body="ある性能を超えたら、ユーザーがどのAIモデルが優れてるか見分けるのはすごく難しくなるかもな。例えば、ELO 1000のチェスプレイヤーが、マグナス・カールセンと別のグランドマスター、どっちが強いか個人で判断できると思う？AGIやSIの評価が人間の判断頼りだと、AI性能の群化は単なる錯覚って可能性もあるんだよ。" userName="jablongo" createdAt="2025/08/07 21:13:55" color="#ff33a1">}}




{{<matomeQuote body="AGIじゃなくても世界を変えるAIはできるって言うけど、俺、AGIは別にいらないかもって思うんだよね。倫理とか大げさな話は抜きにしても、実用面でも。特定の分野に特化したAIツールが欲しいんだ。仲間とか主人じゃなくて、道具として使いたい。まあ、昔、 Model Tが出る前はみんな「もっと速い馬が欲しい」って言ってたらしいけどね。" userName="JohnBooty" createdAt="2025/08/07 19:36:47" color="">}}




{{<matomeQuote body="問題は、CEOとか投資家がそれを望んでないってこと。彼らは知識労働者をリストラしたいだけなんだから。" userName="alfalfasprout" createdAt="2025/08/07 20:03:24" color="">}}




{{<matomeQuote body="ELO 1000のチェスプレイヤーがマグナス・カールセンとか別のグランドマスターの優劣を判断できるかって話だけど、それは無理。それに、何が間違いかも言えない。でも、今のLLMの欠点は、俺にはかなりはっきり分かるよ。" userName="Wowfunhappy" createdAt="2025/08/07 21:28:46" color="">}}




{{<matomeQuote body="AGIができたら、自己改善で人間の能力をあっという間に超えるはずだ。あらゆる分野でね。でも、俺たちはまだAGIを作る道にすらいないと思う。やってるのは、ある時点の人間の知識を複製してリミックスするソフト作りだよ。固定目標だから diminishing returnsだし、neural networksも diminishing returnsに達する。だから、今の状況と同じで、各社のAI能力は最終的に区別がつかなくなるだろうな。" userName="somenameforme" createdAt="2025/08/08 12:14:59" color="#ff33a1">}}




{{<matomeQuote body="LLMベースAIモデルの本当の革新は、新しい人間とコンピューターのインターフェースを作ったことみたいだね。将来は、開発者が厳密なコードじゃなく、人間が話す言葉でAIに意図を伝えられるようになるだろう。これは革命的だけど、真のAGIじゃない。10年後にはPCやスマホのメイン操作はAIインターフェースへの音声入力になるだろうな。キーボードはパワーユーザー向けになるかもね。" userName="gunnaraasen" createdAt="2025/08/07 18:48:50" color="#ff33a1">}}




{{<matomeQuote body="AIには人間みたいな長期記憶がないってのも事実だよね。コンテキスト長を長期記憶と考えると、人間に比べてとんでもなく短い。何十億、何兆トークンとかになれば匹敵するものができるかもしれないし、誰かが新しい解決策を見つけるかもな。" userName="robotnikman" createdAt="2025/08/07 18:44:11" color="">}}




{{<matomeQuote body="それって未来の話だろ、今じゃないんだよ。" userName="make3" createdAt="2025/08/07 22:29:54" color="">}}




{{<matomeQuote body="未来では、伝統的な通貨の代わりにBitcoinが使われ、デジタルアーティストはNFTを売って、超音速ジェット旅行や自動運転、空飛ぶ車もあったはず。月には都市があり、小惑星には鉱山があって、核融合発電所もあった。俺は大規模言語モデルも超音速ジェット旅行と同じ未来をたどると思うね。その有用性は実現せず、従来のモデルで十分で、一部のスタートアップは技術を押し付けようとしても、消費者は拒否し続けるだろう。" userName="runarberg" createdAt="2025/08/07 23:27:17" color="#45d325">}}




{{<matomeQuote body="俺は以前AIドゥーマーだったから、これはすごく幸運だと思うよ。今もちょっとそうだけど、少なくとも今の技術的パラダイムが短期的なAI黙示録には繋がらないって70%くらい確信してる。幸運なのは、俺たち人間を“コピーする”のが得意なAIを開発できたことで、それが真に型破りなエージェントになることを制限して、“平均的な人間の”アウトプットに落ち着く感じだからね。でも、原則としてドゥーマーの主張は全部有効だと思う。俺たちの生きているうちに破滅する可能性も十分あるから、脅威は真剣に受け止めるべきだ。" userName="GolDDranks" createdAt="2025/08/07 18:41:07" color="#ff5c5c">}}




{{<matomeQuote body="なんでCEOたちは安全だと思ってるんだ？ AIが知識労働者を代替できるなら、会社を経営することだってできるはずだろ。" userName="verzali" createdAt="2025/08/07 20:55:48" color="#ff5733">}}




{{<matomeQuote body="実際、チェスの解説者はいつもこれをやってるよ。彼らは他の人と相談したり、エンジンを使わずに自由に議論したり分析したりする余裕があるんだ。" userName="alfalfasprout" createdAt="2025/08/08 00:15:03" color="">}}




{{<matomeQuote body="＞そして、少なくともしばらくの間、それは指数関数的に増加する速度でそうするとも推定されるだろう。<br>なんでそう決めつけるんだ？多くの人のAIに対する懐疑論の一部は、こういう話にあると思うよ。何も知らないんだ。それだけだ。なんで進歩は線形じゃないんだ？新しいブレークスルーが出れば、新しいものは見つけにくくなる。もしかしたら指数関数的かもしれないし、線形かもしれない。誰も知らないんだ。" userName="thinkingtoilet" createdAt="2025/08/08 12:28:02" color="#45d325">}}




{{<matomeQuote body="人間でもそうなんだよ。IQ150以上の同僚がいたけど、恐ろしいほど賢い洞察の瞬間以外は、スーパーマンなんかじゃなくて、驚くほど普通だった。彼を貶すわけじゃない、良いやつだったけど、彼の良い性質の多くは、彼の賢さと関係ないって言えるね。" userName="torginus" createdAt="2025/08/07 22:15:44" color="">}}




{{<matomeQuote body="いや、AlphaGoはプロの囲碁プレイヤーがプレイ中に間違いだと思った“直感に反する”手をいくつか打ったけど、後から見ると素晴らしい戦略的な手だと判明したんだ。奇妙な手でもその素晴らしさを認識できるかどうかは、ゲームの複雑さに依存するかもしれない。現実世界はどんなボードゲームよりもはるかに複雑だよ。https://en.m.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol" userName="nopinsight" createdAt="2025/08/08 02:43:12" color="#ff33a1">}}




{{<matomeQuote body="人工汎用知能（AGI）よりも、もっとインパクトがあるAI/ML/SLの応用ってあるのかな？" userName="Mistletoe" createdAt="2025/08/07 18:19:42" color="">}}




{{<matomeQuote body="たとえAIモデルが現状のSOTAで停滞し続けたとしても、それがもたらす途方もない経済的変化にはまだ対処してる途中だよ。超音速旅客機とは違って、あれは可能で実現したけど、広い経済にはほとんど影響がなかったし、全然普及しなかったからね。" userName="eru" createdAt="2025/08/07 23:49:25" color="#45d325">}}




{{<matomeQuote body="AGIがシンギュラリティを起こすのは自己学習能力があるからってのはわかるけど、まだめちゃくちゃ先の話だよ。1970年代のメインフレームと今のLLMくらいの隔たりがあると思うな。俺が生きてるうちにAGIがお目見えすることはないんじゃないかな。" userName="hnlmorg" createdAt="2025/08/07 21:21:07" color="">}}




{{<matomeQuote body="なんでみんなそんなにAIの終末論に傾倒するのか、俺には理解できんね。AIが一体何をして、何ができるようになったら、そこまで悪いって思うわけ？" userName="hattmall" createdAt="2025/08/07 18:44:39" color="">}}




{{<matomeQuote body="もしみんながAIのせいで職を失ったら、AIが作ったものって誰が買うんだ？って話だよな。" userName="therockhead" createdAt="2025/08/07 20:30:49" color="">}}




{{<matomeQuote body="LLMの長期記憶は訓練データにあって、短期記憶はコンテキストウィンドウにあるんだ。" userName="amelius" createdAt="2025/08/07 18:50:00" color="">}}




{{<matomeQuote body="俺もIQ150超えのグループだけど、それだけでどうこうってことはないと思う。確かにサクッとわかることとか、他人が気づかないつながりを見つけることもあるけど、他の人も似たようなことやってるし、大して変わらないよ。むしろ、経験から学ぶことや、人と協力すること、困難な状況でも諦めずにやり抜く力の方が、生来の知能なんかよりよっぽど大事だと俺は思うね。" userName="alluro2" createdAt="2025/08/07 23:15:22" color="#45d325">}}




{{<matomeQuote body="OpenAIが15ヶ月ものリードを無駄にした件を深読みしすぎじゃない？それより、「たった1社だけがAGIの覇者になる」って予測がそもそもの間違いだよ。政府がそんなこと許すわけないじゃん。よっぽどこっそりやるとか、超AIが一瞬で爆誕するとかなら話は別だけどね。" userName="j_timberlake" createdAt="2025/08/07 18:48:42" color="#785bff">}}




{{<matomeQuote body="AlphaGoはすごいけど、あれは人工的で制限されたデータで訓練されたんだ。目的のスコアを明確にできる時や、システムが自分で訓練データを作れる時って、最適化がすごく楽になるんだよね。" userName="neltnerb" createdAt="2025/08/08 04:26:55" color="">}}




{{<matomeQuote body="AI業界は独占じゃなくて、完全にコモディティ化すると思うんだ。性能が十分になったら、それ以上の進歩って費用に見合わなくなるし。いずれオープンなモデルも「十分使える」レベルになって、消費者向けのPCでも動くようになるはず。2035年には、お前のノートPCでGPT-7レベルのAIがタダ同然で動くかも。そしたら、GPT-10とかにわざわざ金払う意味ある？モデル開発がメインの企業は、別の収益源を探さないと厳しいと思うね。" userName="nerdix" createdAt="2025/08/07 19:14:39" color="#ff5c5c">}}




{{<matomeQuote body="キーボードがなくなるって予測する人がいるのがいつも不思議だよ。みんなタイピング好きなんだから。俺もめちゃくちゃ好きだし。電話に話しかけるなんて絶対無理。特に誰かに聞かれるかもしれない状況じゃあね（って、いつもそうだけど）。" userName="originalcopy" createdAt="2025/08/07 18:57:26" color="">}}




{{<matomeQuote body="AIがコモディティ化するって意見があるけど、だとしたらAI企業がなんであんなにぶっ飛んだ評価額ついてるんだ？投資家は俺たちが知らない何かを知ってるってこと？" userName="joelthelion" createdAt="2025/08/07 19:18:10" color="#785bff">}}




{{<matomeQuote body="超金持ちがみんなをAIやロボットに置き換えられるNPCと見てる想像してみてよ。そしたら、AIやロボットを手に入れたら、ほとんどの人を排除して、AIロボットに自分を支えさせればいいってことになるよね。自分は王様で、生かしておいた人は家臣、AIロボットは奴隷軍隊。誰にも物を売る必要なくて、彼らは生かしてもらうために貢物を払うんだ。売るんじゃなくて税金を取って生産物をもらう感じ。CEOみたいなもんだけど、もっと支配的なパワー関係だね。" userName="ModernMech" createdAt="2025/08/07 20:42:25" color="#ff5733">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="超音速機の衰退はコストが原因だった。今の技術世代の限界も、費用対効果の曲線で決まるかもね。今見てる技術って、すごい民間投資で大規模に補助されてるみたいだし。この手の話は、いつか投資家がリターンを求める時期が来て、それがデータセンターを動かし続けるかどうかの決め手になるだろうな。そうは言っても、超音速飛行は軍事分野ではまだ現役だけどね…" userName="rusk" createdAt="2025/08/08 00:03:30" color="#785bff">}}




{{<matomeQuote body="GPT-5の知識カットオフは2024年9月30日（リリース10ヶ月前）。これに対してGemini 2.5 Proは2025年1月（リリース3ヶ月前）、Claude Opus 4.1は2025年3月（リリース4ヶ月前）。参照URLは以下の通りだよ。<br>https://platform.openai.com/docs/models/compare<br>https://deepmind.google/models/gemini/pro/<br>https://docs.anthropic.com/en/docs/about-claude/models/overv..." userName="surround" createdAt="2025/08/07 17:53:29" color="#ff5c5c">}}




{{<matomeQuote body="ウェブ検索があれば、知識カットオフって本当にまだ関係あるのかな？それともこれは、モデルの事後学習にどれだけ時間がかかったかっていうコメントなのかな？" userName="levocardia" createdAt="2025/08/07 18:18:37" color="">}}




{{<matomeQuote body="俺の経験だと、ウェブ検索は出力の品質を下げることが多いんだよね。コンテキストが詰まるせいなのか、モデルが良いソースとゴミを見分けられないせいなのかは分からないけどさ。俺はデフォルトでウェブ検索をオフにして、必要な時にツールメニューからオンにするようにしてるよ。" userName="mastercheif" createdAt="2025/08/07 18:27:11" color="#ff5c5c">}}




{{<matomeQuote body="知識カットオフが1900年とかのLLMを訓練したら面白そうだな。" userName="asboans" createdAt="2025/08/08 06:31:12" color="">}}




{{<matomeQuote body="それは、未来を推測したり予測できるかを見るために既にやられてるよ。今は論文へのリンクが見つからないけどさ。" userName="ph4evers" createdAt="2025/08/08 06:45:49" color="">}}




{{<matomeQuote body="これかな？”Mind the Gap: Assessing Temporal Generalization in Neural Language Models” https://arxiv.org/abs/2102.01951" userName="creativeSlumber" createdAt="2025/08/08 06:57:09" color="#ff33a1">}}




{{<matomeQuote body="アイデアは合ってるけど、2019年は1930年なんかとは全然違うよね。" userName="MadameMinty" createdAt="2025/08/08 08:40:37" color="">}}




{{<matomeQuote body="1930年には、意識が発達するのに十分な情報なんて世界にはなかったからね。" userName="fmbb" createdAt="2025/08/08 08:52:17" color="">}}




{{<matomeQuote body="人間の意識が最近発達したって説へのメタな言及だね。文字言語以前の人々は、思考がなかったから言語もなかったっていう説だよ。僕らは高性能言語を知ってるから、これは良い思考実験だ。原始言語が原始的だったのは、ニュアンスが欠けてたから？それとも伝達が不十分だったから？口語は書記に先行し、書かれた言語で共同体の意識が生まれる。GPTsが分かりやすい文章を出すことで、意識の証明について一周回った。みんな『GPTは専門的に伝えるけど、本当に意識あるの？単なる入力の反映？意識って本物？』って疑問に思ってるよ。" userName="ClarityJones" createdAt="2025/08/08 13:06:30" color="#785bff">}}




{{<matomeQuote body="ChatGPTのウェブ検索は試してないけど、Claudeのウェブ検索はすごく良かったよ。それが決め手で、LLMを日常的に使うようになったんだ。彼らが残す引用（ChatGPTもそうだと良いんだけど）は、特定の情報がデタラメじゃないか確認するのに最高だね。" userName="jjice" createdAt="2025/08/07 20:05:28" color="#ff5c5c">}}




{{<matomeQuote body="ウェブ検索は、訓練データに（十分に？）ないフレームワークにとって超重要だよ。o3はよくSwiftフォーラムから情報を引っ張ってきて、僕の分かりにくいSwiftの並行処理の問題を解決してくれるんだ。" userName="manmal" createdAt="2025/08/07 20:13:21" color="#ff5733">}}




{{<matomeQuote body="GPT-5の知識カットオフは2024年9月30日、Gemini 2.5 Proは2025年1月、Claude Opus 4.1は2025年3月だね。これらの日付以降の検索結果の大部分は、どうせAIが生成したものだし、そんなものを訓練に使って何になるの？" userName="dotancohen" createdAt="2025/08/08 06:23:51" color="#ff5733">}}




{{<matomeQuote body="Geminiはほぼ全てのクエリでざっとウェブ検索をするよ。おそらく知識カットオフと現在との間のギャップを埋めるためだろうね。" userName="LeoPanthera" createdAt="2025/08/07 18:26:11" color="">}}




{{<matomeQuote body="僕の経験だと、試したフロンティアモデル（o3, Opus 4, Gemini 2.5 Pro）のどれも、ウェブ検索があってもSwiftの並行処理の問題を解決できなかったよ。Swift 6の言語モードには少なくとも不十分だった。モデルは概念全体や、アクター、アイソレーション、タスクがどう連携するか、ちゃんと理解してるみたいじゃないんだ。" userName="fmos" createdAt="2025/08/07 21:49:18" color="#ff5c5c">}}




{{<matomeQuote body="質問なんだけど、GPTが返すウェブ検索結果って、”読まれて”モデルにバックプロパゲーションされるのかな？" userName="havefunbesafe" createdAt="2025/08/07 19:17:54" color="">}}




{{<matomeQuote body="増え続けるAIコンテンツを避けるから、それ（検索結果を訓練に使うこと）が本当に役立つのかどうか、疑問に思うね。" userName="diegocg" createdAt="2025/08/07 18:28:05" color="">}}




{{<matomeQuote body="これって、OpenAIがGPT-5の事前学習にすごく長い時間をかけたってことかな？" userName="xnx" createdAt="2025/08/08 03:58:13" color="">}}




{{<matomeQuote body="最近、Web検索がLLMの出力品質を下げてるみたいだね。普通のWebを使おうとすると、文脈がゴチャゴチャして出力の邪魔をしてる感じ。" userName="gorkish" createdAt="2025/08/07 19:53:11" color="">}}




{{<matomeQuote body="面白いね。俺はAPIを使ってるけど、Claude、ChatGPT、Geminiには引用が全然ないんだ。Kagi assistantだけが引用くれるから、事実確認にはそっちを使ってるよ。君は何のソフトを使ってるの？ネイティブのClaudeアプリ？どのサブスクリプション？" userName="illiac786" createdAt="2025/08/08 04:14:48" color="#ff5c5c">}}




{{<matomeQuote body="俺も同じ気持ち。Web検索を使うLLMは、皮肉にも思慮深い出力が少ない気がするんだ。LLMを使う理由の一つは、斬新なアイデアを探ることなのにね。Web検索だと、全体的な要求よりも結果に強く引っ張られすぎて、遅い検索エンジンみたいになっちゃう。" userName="bangaladore" createdAt="2025/08/07 18:33:50" color="#785bff">}}




{{<matomeQuote body="実際、引用ってどれくらいチェックしてる？やつらは自信満々に引用するけど、ソースに書かれてることと違うことを言ってる時もあるよね。" userName="nicce" createdAt="2025/08/08 08:27:30" color="#785bff">}}




{{<matomeQuote body="初期の人類が複雑な言語がなかったから意識がなかったって言うのは、青って言葉がなかったから青が見えなかったって言うのと同じだよ。" userName="balder1991" createdAt="2025/08/08 15:53:58" color="">}}




{{<matomeQuote body="LLMは全体の概念とか、色んなもの（アクター、アイソレーション、タスク）がどう連携すべきか、みたいなメンタルモデルを持ってないみたいだね。公平に見て、そんなの誰か持ってるの？¯＼_(ツ)_／¯" userName="elpakal" createdAt="2025/08/08 02:17:34" color="#ff5c5c">}}




{{<matomeQuote body="俺は完全に逆の経験をしてるよ（Claudeの場合だけどね）。最近はほとんどGoogle検索をClaude経由でやってるんだ。自分でやるよりずっと早く、うまく情報を見つけて消化・整理してくれる。Web検索なしだと、LLMにデタラメを言わせてるようなもんだから、結果を信用するのは難しいよ。" userName="throw310822" createdAt="2025/08/07 21:46:42" color="#38d3d3">}}




{{<matomeQuote body="ChatGPTのDuckDbに関する知識が古くて、たくさん困ってるんだ。例えば、DuckDbが外部キーを強制しないって思ってるみたい。" userName="stevage" createdAt="2025/08/07 23:04:42" color="#785bff">}}




{{<matomeQuote body="それはわかる。一つには、やつらが即興で解釈してるからだね。もう一つは、カットオフより10ヶ月新しいデータがあったとしても、その間の情報を持ってないからさ。そりゃ大変だろうね。" userName="troyvit" createdAt="2025/08/07 23:17:55" color="#38d3d3">}}




{{<matomeQuote body="質問によるね。父とAppleの製品別収益の話をしてて、ただの雑談だから調べなかったけど、Postgres RLSの概要は重要だったから、ほとんどの引用元を確認したよ。情報の重要性によってLLMの回答の信頼性確認の必要性が変わるってこと。" userName="jjice" createdAt="2025/08/10 13:16:46" color="#38d3d3">}}




{{<matomeQuote body="これだね。僕は長い散歩と熟考、Bachを聴きながらエスプレッソを飲む時間（かなりマジで）の後に最高の仕事ができるんだ。HNやSlack、ClickUp、仕事のメールを見ると、集中力が吹っ飛んで、すぐに頭がクリアにならない。ウェブやLLMでちょっと調べるだけでも汚染される感じ。" userName="clbrmbr" createdAt="2025/08/08 10:47:48" color="#ff33a1">}}




{{<matomeQuote body="Claudeのウェブとモバイル版でPro（20ドル）を契約してるよ。Kagi Assistant（これも使ってる）とすごく似てるって感じたね。" userName="jjice" createdAt="2025/08/10 13:15:13" color="">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="https://openai.com/index/gpt-5-system-card/のシステムカードによると、GPT-5は「統一システム」らしいけど…<br>「スマートで高速なモデルがほとんどの質問に答え、より難しい問題にはより深い推論モデル、そして会話タイプや複雑さ、ツールの必要性、明示的な意図（例えば、『これについてよく考えて』とプロンプトで言うなど）に基づいて、どのモデルを使うか迅速に判断するリアルタイムルーターがある」って書いてる。<br>それって全然「統一システム」じゃないじゃん。そう見せかけてるだけだよね。これは単一の巨大モデルを訓練するんじゃなくて、特別なサブモデルを開発して、別のモデルでそれらを隠そうとしてるみたい。エンドツーエンドのトレーニングが高価になりすぎた時にこうするんだよ。" userName="fidotron" createdAt="2025/08/07 17:49:31" color="#ff5c5c">}}




{{<matomeQuote body="たくさんの小さな特化型モデルがこれからの主流だよ。もし彼らがそうしてるなら、それは良いことだね。" userName="lacoolj" createdAt="2025/08/07 17:52:18" color="">}}




{{<matomeQuote body="これは単なる意味論の議論だけど、単一のインターフェースが自動的に異なるコンポーネントと相互作用するなら、それを「統一システム」と呼ぶのは正しいんじゃない？「統一モデル」ではないけど、「統一システム」と呼ぶのは問題ない気がするよ。" userName="hatthew" createdAt="2025/08/07 19:17:18" color="#ff33a1">}}




{{<matomeQuote body="全然違うよ。新しいモデルの組み合わせから、単に「Bitter Lesson」[1]を再発見するだけになるだろうね。<br>[1] https://www.cs.utexas.edu/~eunsol/courses/data/bitter_lesson..." userName="fidotron" createdAt="2025/08/07 18:03:42" color="#785bff">}}




{{<matomeQuote body="AltmanたちはChatGPTの複数モデルインターフェースがユーザーを混乱させてると言ってたから、ユーザーが使い方を理解しなくてもタスクに基づいてルーティングする統一システムに移行したいと考えてるみたい。おそらくこれは彼らが以前から議論していたことだろうね。彼らが統一された推論アーキテクチャやモデルを目指してるかは分からないけど、どうせ目標は不十分だと言われるだろうね。" userName="fnordpiglet" createdAt="2025/08/07 21:44:05" color="#38d3d3">}}




{{<matomeQuote body="「Bitter Lesson」は、解決策を複数のモデルに分割できないとは言ってないよ。それは、人間がタスクに独自の仮定を注入するよりも、スケールされた計算によるデータからの学習の方が優れているって言ってるんだ。「思考には速いシステムと遅いシステムの2種類がある」みたいな広い一般化は、この範疇には必ずしも入らないね。Transformer自体（と位置エンコーディングの選択など）は、シーケンスモデリングに関する帰納的バイアスを含んでる。ルーターは、おそらくかなり汎用的なアーキテクチャで学習されてるんじゃないかな。" userName="bigmadshoe" createdAt="2025/08/07 18:16:16" color="#785bff">}}




{{<matomeQuote body="タスクをサブモデルに分割する方法について、君が仮定を置いているってことだよね。" userName="fidotron" createdAt="2025/08/07 18:19:09" color="#45d325">}}




{{<matomeQuote body="AIモデルに仮定を丸投げして、あとは最適な選択をしてくれるって期待してるだけじゃない？" userName="dmix" createdAt="2025/08/07 19:56:32" color="">}}




{{<matomeQuote body="高すぎるか、利用可能な学習データが枯渇してもう効果がないのかもな。新しいデータはゆっくり生成されるし、AI生成データで大量に汚染されてるから、役立たずになる可能性もあるぞ。" userName="Therenas" createdAt="2025/08/07 18:11:13" color="#ff5733">}}




{{<matomeQuote body="これは単なるルーターじゃない、将来のモデルの先駆けだよ。システムカードにも「近い将来、これらの機能を単一のモデルに統合する予定だ」って書いてあるしね。" userName="mafro" createdAt="2025/08/07 21:09:08" color="#45d325">}}




{{<matomeQuote body="OpenAIって今、GPTのラッパー商売してんの？ オープンモデルはシンプルなモデルを求める人への逃げ道って感じかな。でも、俺の徹底的なテストではKimi K2と大差ないんだよね。" userName="WorldPeas" createdAt="2025/08/07 21:06:53" color="">}}




{{<matomeQuote body="職場の多くの人は、ただ切り替えればいいのに、ずっと4oのままだよな。自分でモデルを設定することもできるけど、この変更でモデル選択に迷う非技術系の同僚にとっては、出力品質が確実に向上するだろうね。" userName="nickthegreek" createdAt="2025/08/07 22:22:22" color="#ff33a1">}}




{{<matomeQuote body="物体認識や顔認識でも似たようなことやったけど、うまくいったけど最善策じゃないんだ。E2Eネットワークのための十分な計算能力（とデータもかな）がない場合に限って使う方法だよ。" userName="gekoxyz" createdAt="2025/08/07 18:04:11" color="#38d3d3">}}




{{<matomeQuote body="その可能性はもっと悪いと思うよ。自己規制じゃなくて、根本的な限界を示唆してるからね。俺は楽観的でいたいけど、OpenAIが本当に全体的なスケーリングで壁にぶつかってるなら、AIバブルは多くの人が予想するより早く弾けるかもな。" userName="fidotron" createdAt="2025/08/07 18:23:31" color="#ff5c5c">}}




{{<matomeQuote body="AI企業のリーダーが出す予測的な発言を、未だに意味のないノイズ以外として捉える奴は、真剣に考えようとしてないだけだよ。" userName="Icathian" createdAt="2025/08/07 21:13:19" color="">}}




{{<matomeQuote body="どうやら彼らは単一の巨大モデルを訓練してるんじゃなくて、特殊なサブモデルを開発して、それを別のモデルで誤魔化そうとしてるみたいだね。それはエンドツーエンドの訓練が高額になりすぎた時に取る手段だよ。「ビター・レッスン」の逆説がまたしても当たったね。同じ予算なら、手作業で作られたシステムの方が汎用システムよりはるかに性能が良いんだ。" userName="noosphr" createdAt="2025/08/07 21:08:27" color="#ff5c5c">}}




{{<matomeQuote body="APIを使えば、使いたいモデルを直接選べるよ。自動的な思考はChatGPTの機能だね。ChatGPTは元々、その意味で「GPTラッパー」だからね。" userName="erjiang" createdAt="2025/08/08 15:05:38" color="">}}




{{<matomeQuote body="そうだね、同じ計算予算なら、手作業で作ったカスタムモデルは常に一般的な統計モデルより優れてるよ。電力網が飽和状態の今、考えられないことをして、もう一度考え直す必要があるかもね。" userName="noosphr" createdAt="2025/08/07 21:10:36" color="#45d325">}}




{{<matomeQuote body="それは、みんなが信じたいから繰り返してる嘘だよ。データセットの品質は時間とともに評価されてるんだ。2022年以降のデータセットがそれ以前のものより悪いという証拠はないよ。逆の効果の弱い証拠はあるけど、原因は不明。ラボでは「モデル崩壊」は簡単に起こせるけど、現実世界ではそうならないんだ。" userName="ACCount36" createdAt="2025/08/07 20:35:44" color="#45d325">}}




{{<matomeQuote body="LLMだけでもう十分に強力かもしれないね。記号的推論やエピソード記憶などを可能にするには、古典的なAIシステムと接続する必要があるだけだよ。" userName="pillefitz" createdAt="2025/08/07 19:41:43" color="">}}




{{<matomeQuote body="ChatGPTのGPT-5は推論、非推論、ルーターモデルのシステムだけど、APIプラットフォームのGPT-5はChatGPTで最高の性能を出す推論モデルだよ。ちなみに、最小推論のGPT-5はChatGPTの非推論モデルとは異なり、開発者向けにチューニングされてる。ChatGPTで使われてる非推論モデルはgpt-5-chat-latestとして利用可能だよ。https://openai.com/index/introducing-gpt-5-for-developers/" userName="andai" createdAt="2025/08/07 18:29:37" color="#785bff">}}




{{<matomeQuote body="もちろん、機械学習はすべて仮定を伴うよ。「ビター・レッスン」は実際には、特定のタスクをどう実行するかに関する人間の知識といった仮定を最小限にすることだね。仮定をしないという意味なら、あなたの解釈には同意しないな。言語を大規模な全結合ネットワークだけでモデル化しようとすると失敗するよ。レッスンの適用は、タスクに関する「専門知識」からの仮定と、問題の最も一般的な構造に合致する仮定を分離することだよ。「思考時間」はどんな思考システムにとっても基本的な特性だね。これを低と高の2つのモードに分けるのは、強すぎる仮定ではないと思う。多くの特化型サブモデルについては、区別が恣意的で特定の問題に関する人間の知識に基づいている点について完全に同意するよ。" userName="bigmadshoe" createdAt="2025/08/07 19:38:00" color="#38d3d3">}}




{{<matomeQuote body="彼らはAIシステムを作ってるのであって、GPTそのものを作ってるわけじゃないよ。" userName="pertymcpert" createdAt="2025/08/07 21:51:04" color="">}}




{{<matomeQuote body="公平に言って、正しい目的関数を最適化してるなら、それがタスクに合ったものを「選んでくれる」ことを期待するってわけじゃないよ。" userName="bigmadshoe" createdAt="2025/08/07 20:25:17" color="">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
