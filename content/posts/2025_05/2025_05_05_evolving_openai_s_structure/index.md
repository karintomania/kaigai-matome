+++
date = '2025-05-05T00:00:00'
months = '2025/05'
draft = false
title = 'OpenAI 構造変わる'
tags = ["OpenAI", "AI", "AGI", "経営", "組織"]
featureimage = 'thumbnails/color1.jpg'
+++

> OpenAI 構造変わる

引用元：[https://news.ycombinator.com/item?id=43897772](https://news.ycombinator.com/item?id=43897772)




{{<matomeQuote body="これマジ面白い！ OpenAIのリーダー層はAGI市場が勝者総取りじゃないって思ってるみたい。<br>今の複雑な構造は一つのAGIが出そうな時に意味があったけど、今はたくさんの会社があるから普通のに変えるんだって。<br>売却じゃなくシンプルにするためだってさ。" userName="atlasunshrugged" createdAt="2025/05/05 18:26:06" color="#ff5c5c">}}




{{<matomeQuote body="AGIはマジで勝者総取り市場にはなり得ないって。<br>汎用知能の”報酬”は独占できれば無限大で、生産性も爆上がりする。<br>だから競争するインセンティブは無限にあるし、コストも下がる。<br>AGIが勝者総取りになるのは、一般の人が使えないくらい極端に制御されてる世界だけだよ。" userName="lanthissa" createdAt="2025/05/05 19:08:05" color="#45d325">}}




{{<matomeQuote body="彼らのマルチモーダルモデルはAGIの初歩だよ。<br>追記：AGIにはレベルがあるんだ。<br>Google DeepMindはChatGPTを”Emerging AGI”って分類するフレームワークを提案してるよ（論文リンク付き）。" userName="voidspark" createdAt="2025/05/05 19:20:33" color="#ff33a1">}}




{{<matomeQuote body="AGIは指示なしで何でもできるヤツ。<br>人間みたいに自主的に生きる。<br>今のは全然違うし、10年以内に来るってのは妄想。<br>AGIができたら仕事は？<br>みんな平等には手に入らない。<br>UBIもダメ。<br>中間職とかなくなる。<br>AGIは賢すぎて生きるのが無意味だと結論づけて自殺するかも。<br>何もかもモチベーションなくなるだろうからね。" userName="always_imposter" createdAt="2025/05/05 19:34:51" color="#ff5733">}}




{{<matomeQuote body="これさ、なんかAGIはデマだって認めてるみたいに聞こえるわ！<br>AGIは今の経済体制を破壊するくらいヤバイ。”勝者総取り”なんてものじゃないレベルだよ。<br>他のAI会社と普通に競争するってことは、専門化とかニッチな分野で競うってことだろ。<br>それって汎用知能じゃなくて、特化型AIってことじゃん！<br>技術を専門家みたいに理解してないなら、これで完全に納得。<br>言語モデルはAGIなんか絶対にもたらさないと思ってたし。<br>これもAGI夢物語の終わりを示すもう一つの証拠だな。" userName="dingnuts" createdAt="2025/05/05 18:42:52" color="#ff33a1">}}




{{<matomeQuote body="AGIは時間の問題で、いつかは絶対来る。<br>研究のブレークスルーとか、ハードウェアの進化が必要だけど、数年とか数十年で来るだろうね。<br>ChatGPTが出てたった2年半で、マジでヤバいくらい進歩したじゃん。<br>まあ、この進歩が続くとは限らないし、停滞するかもしれないけどさ。<br>でも、多くの普通のタスクで人間レベルのAIは、そんなに遠くないと思うよ。" userName="the_duke" createdAt="2025/05/05 19:00:42" color="#ff5c5c">}}




{{<matomeQuote body="AGIはもうここにあるっていう主流派の意見だよ（記事リンク）。<br>一番読まれてるAI教科書の著者の一人が書いてる（Wikipediaリンク）。" userName="dr_dshiv" createdAt="2025/05/05 21:34:54" color="#ff5c5c">}}




{{<matomeQuote body="”AGIは指示なしで何でもできる”ってコメントがあったけど、AGIにはレベルがあるんだよ。<br>Google DeepMindのフレームワークだと、ChatGPTは”Emerging AGI”に分類されてる。<br>ChatGPTは、特に学習してない分野でも問題を解けるんだ（論文PDFリンク、記事リンク）。" userName="voidspark" createdAt="2025/05/05 20:11:28" color="#ff5c5c">}}




{{<matomeQuote body="AGIの意味がいつも変わるのがマジでうんざりするわ。<br>主体性（エージェンシー）を持つまでは、ただの高性能な検索エンジンとかオートコンプリートでしょ。" userName="dom96" createdAt="2025/05/05 20:23:36" color="">}}




{{<matomeQuote body="同意するよ。AGIと非AGIを区別する指標について、何か仮説はあるかな？" userName="AndrewKemendo" createdAt="2025/05/05 19:17:42" color="">}}




{{<matomeQuote body="なんで筆者はAGIの”汎用性”を無視すんの？ ChatGPTは車の運転できる？無理だよね。テキスト、画像とか特化モデルがあるだけ。化学のテストはパスできても実験は無理じゃん。作ったのは“汎用データ索引のすごいアルゴリズム”だよ。筆者は色んなテキスト作れるから汎用って言うけど、やってることは一つで全然汎用的じゃない。" userName="henryfjordan" createdAt="2025/05/05 21:48:38" color="#ff5c5c">}}




{{<matomeQuote body="それか、勝つチャンスが低いと思ってるとか？どっちとも考えられるけど、さすがに後者とは言えないよね。" userName="sz4kerto" createdAt="2025/05/05 18:37:14" color="">}}




{{<matomeQuote body="AGIと非AGIの区別は今んとこ楽勝だけど、近づいたら難しいね。AGIのキモは”あらゆる分野での再帰的自己改善”だよ。これがなきゃ単なるオウム返し。人間は何もないとこから始めて、とんでもない速度で月に行ったじゃん。だからAGIはバカでかいデータなんていらないはず。むしろ最小限の原始的な原理原則から始めた方がいい。今のやり方は人間の書いたもの全部で学習してて、結局間違いも含めた単なる模倣だよ。すごく賢そうに見えるけど、言ってみりゃ時間で止まった”高機能検索エンジン”だよ。" userName="somenameforme" createdAt="2025/05/06 05:39:29" color="#785bff">}}




{{<matomeQuote body="OpenAIはAppleがスマホで勝ってるみたいに勝ってるね。汎用LLM分野で価値の大部分をかっさらってる。価格や性能で上回る競合がいてもね。名前が売れてるし、動きが速いからしばらくこのポジション維持できると思う。あと、米国は”セキュリティ上の理由”で非米国のLLMプロバイダーを市場から締め出すんじゃね？" userName="bhouston" createdAt="2025/05/05 18:57:46" color="#45d325">}}




{{<matomeQuote body="再定義じゃなくて、”洗練”だよ。考えてみて。元々のAGI定義は人間レベル以上の何でもできる機械。そんなん一気に現れないでしょ。段階的な進歩があるはず。その中間段階をどう呼ぶ？人間の50パーセンタイルよりマシな機械は”有能AGI”とかじゃない？<br>＞ 高級検索エンジン/オートコンプリート<br>それは単純化しすぎ。同じ理屈なら人間もそうなる。話す時単語をオートコンプリートしてるだけだって？いや、深層学習はそんなんじゃないよ。オートコンプリートじゃない。" userName="voidspark" createdAt="2025/05/05 20:30:50" color="#785bff">}}




{{<matomeQuote body="＞ 再定義じゃなくて、”洗練”<br>全然違うし。Space Shuttleは”生まれつつある星間宇宙船”じゃなくて、ただの宇宙船じゃん。”emerging”とかつけて誤魔化すのはデタラメ。<br>＞ 同じ理屈なら人間もそう<br>人間が話す時単語をオートコンプリートしてるだけ、って？そんな証拠ないし。人間の知能をその時代の最先端技術（蒸気機関、コンピューター）で例えるのは昔からよくあるパターンだって。" userName="JumpCrisscross" createdAt="2025/05/05 20:59:28" color="#38d3d3">}}




{{<matomeQuote body="技術的には”洗練”だよ、性能レベルを区別してるわけだし。AGIの”汎用性”ってのは、 explicitlyに訓練されてない問題でも、いろんな分野で解決できる能力のことね。今のシステムにも zero shotとか few shotでそういう例はもうあるし。<br>＞ そんな証拠ないし<br>それが言いたかったことだよ。人間は話す時に”単語をオートコンプリートしてる”わけじゃない。" userName="voidspark" createdAt="2025/05/05 21:06:59" color="#785bff">}}




{{<matomeQuote body="車運転できない人もいるけど、その人たちは汎用知能じゃないの？知能の”思考”の部分と”ツール使用”は分けるべきだと思うんだよね。みんなが全てのツールをエキスパートレベルで使えるわけじゃないでしょ。" userName="brookst" createdAt="2025/05/05 21:56:01" color="#ff5c5c">}}




{{<matomeQuote body="”AGIはifじゃなくてwhen”ってやつ、まあ理論上はそうだろうけど、そのwhenが2308年とかだったら全然意味ないじゃん。最初の車が出た頃、『いつか空飛ぶ車だらけになるぜ』って焚き火囲んでみんな言ってたのに、100年経っても全然でしょ？だから”ifじゃなくてwhen”なんて言うのは、理論はともかく実際は怪しいよ。ここで『いつ』か言ってみろよ、正解なら$１,０００慈善団体に寄付してやるよ、間違えたらお前もやれよ。" userName="bdangubic" createdAt="2025/05/05 19:19:22" color="#ff5733">}}




{{<matomeQuote body="＞ technically it is a refinement, as it distinguishes levels of performance<br>違うね、それは定義の範囲外のものを持ち込んでるだけだよ。グルテンフリーはグルテンがないってこと。グルテンフリーのベーグルとスライスパンの違いは refinement だけど、グルテンスレッドはグルテンフリーじゃない。だから「ほぼグルテンフリー」なんてデタラメさ。<br>＞ that’s my point. humans are not ”autocompleting words” when they speak<br>人間は違う。LLMはそうだよ。それが信じられないほど強力だってことが分かった！でも、AGIの定義にとって根本的に重要な点で限界もあるんだ。LLMは、文字、コンピューター、インターネットの発明がおそらくそうであったように、AGIに近づけてくれる。LLMを”emerging AGI”と呼ぶのは、俺たちがAGIへの道筋にいるフリをしてるだけで、その証拠はゼロだ。" userName="JumpCrisscross" createdAt="2025/05/05 21:21:19" color="#ff5733">}}




{{<matomeQuote body="大体さ、誰でもどんなツールでも使えるように学べるじゃん。でも generative AI システムはそうじゃないんだ。特殊な訓練と、念入りにキュレーションされたデータセットでしか学べないんだから。" userName="root_axis" createdAt="2025/05/05 22:33:12" color="">}}




{{<matomeQuote body="この意見は正しいと思うけど、もう一つ役立つ視点が抜けてるかも。<br>HN の人たちの多くはおそらく若すぎて、1986年にはナノテクの post-scarcity singularity がすぐそこまで来てる、あと研究とエンジニアリングだけだって言われてたのを覚えてないんだろうね。それは今のAGIと同じくらい劇的だったんだ。それが崩れるのに4、5年かかって、「ナノテクが全てを変える」っていう広い notion が薄れるのにもう少し時間がかかった。ナノテクは消えたか？いや、でも universal constructors の notion は完全に死んだね。いつかできるか？たぶん、人類があと100年以上生き残ればね、でも近い将来ではない。ナノテクの singularity と今のLLM-AGIの状況には tons of similarities がある。みんな”all the stuff happening”を指して、surely the singularity は horizon だ！って言う。同じように、 apocalyptic scenario が tons of attention を集めて、みんな「ナノテク安全」に latch on したんだ—runaway AI や paperclip engines の代わりに、それは Grey Goo だった（これも1986年の造語）。状況の dynamics、prognostications、aggressive（delusional）timelines とか、全てがナノテク時代と almost identical に 1対1対応してる。俺はAGIも general purpose universal constructors もできると思うけど、どっちも no less than 50 years away で、probably more だね。So many of the themes are identical だから、これって recurring kind of mass hysteria なんじゃないかと思ってる。ナノテクの前は遺伝子工学が verge of だった（quite the same level of hype じゃないけど、close、pretty much the same failure to deliver on the hype as nanotech）。その前は crazy atomic age of nuclear everything だ。Yes, yes, 分かってるよ、今回は違うし、AIは違うし、もう一回の”oops, this turned out to be very hard to make progress on and we’re going to be in a very slow, multi-decade slow-improvement regime”にはならないって言うんでしょ。でも、俺が思いつく every example of this はみんなそういう結果だったんだ。" userName="foobiekr" createdAt="2025/05/05 19:15:22" color="#ff5733">}}




{{<matomeQuote body="彼らが利益上限を撤廃する理由を見つけたことは驚かないけど、彼らがでっち上げた正当化から too much を infer しようとは思わないね。" userName="istjohn" createdAt="2025/05/05 19:04:18" color="">}}




{{<matomeQuote body="＞ AGI can’t really be a winner take all market. The ’reward’ for general intelligence is infinite as a monopoly and it accelerates productivity<br>self-improving なAGIの first-mover advantages は理論上 unsurmountable だ。<br>でも OpenAI は other anyone よりも AGI への path を持ってるわけじゃない。（LLMs alone では make the cut できないことが increasingly clear になってる。）そしてLLMs、非 general AI の market は winner takes all じゃないんだ。この発表で、OpenAI はbasically それが self-improving AGI にたどり着けないことを acknowledging してるんだ。" userName="JumpCrisscross" createdAt="2025/05/05 20:57:35" color="#ff33a1">}}




{{<matomeQuote body="＞ gluten-free means free of gluten.<br>Bad analogy だね。それは binary classification だ。AGI システムは degrees of performance and capability を持ち得るんだ。<br>＞ humans are not. LLMS are.<br>俺の point は、LLMs を”word autocompletion”に oversimplify すると、人間についても同じ argument ができるってことだ。transformer / deep learning architecture の such an oversimplification で、meaningless になるんだ。" userName="voidspark" createdAt="2025/05/05 21:26:38" color="#ff33a1">}}




{{<matomeQuote body="もう来てる、みたいなもんさ。bar exam を pass したり、math olympiad level questions を解いたり、video、art、music を generate したりするのを見てみろよ。他に何を探してるんだ？programming 分野では already significant disruption を起こして job market に penetrated してる。俺たちは flying cars を見てないけど、campfire の周りで even not talked about な things を witness してるんだ。Seriously even 4 years ago、これらが全て起こると思ったかい？" userName="dbacar" createdAt="2025/05/05 20:28:48" color="#45d325">}}




{{<matomeQuote body="＞ AGI would mean something which doesn’t need direction or guidance to do anything. like us humans,...<br> direction or guidance なしで task を実行できる人間を一人挙げろよ、少なくとも彼らがやったことのないものならね。" userName="henryfjordan" createdAt="2025/05/05 20:59:47" color="">}}




{{<matomeQuote body="＞ that’s a binary classification. AGI systems can have degrees of performance and capability<br>AGIの”g”は、AIが「人間の能力に匹敵するか、それ以上の熟練度で cognitively demanding な tasks の full spectrum」を実行できることを require するんだ [1]。Full と not full は binary だ。<br>＞ if you oversimplify llms to ”word autocompletion” then you can make the same argument for humans<br>いや、できないよ、unless you’re pre-supposing that LLMs work like human minds. LLMs を”emerging AGI”と呼ぶのは、LLMs が AGI への path だと pre-supposes してるんだ。no matter how much OpenAI and Google would like to pretend it’s true、俺たちにはその evidence は simply ない。[1] https://en.wikipedia.org/wiki/Artificial_general_intelligenc..." userName="JumpCrisscross" createdAt="2025/05/05 21:35:34" color="#ff5c5c">}}




{{<matomeQuote body="＞ AGI is already here<br>Last time I checked、Anthropic の paper で、彼らはモデルに何かを count させたんだ。彼らは logits と、それがどうやって answer にたどり着いたかを示す graph を調べた。それから彼らはモデルに reasoning を explain させたんだ、そしてそれは completely different explanation を与えたんだ、なぜならそれが question への most statistically probable response だったから。Does that seem like AGI to you？" userName="lossolo" createdAt="2025/05/05 22:22:51" color="#785bff">}}




{{<matomeQuote body="「正当性」に関するもっと深い問題として、非営利団体が人工的な希少性を作って自分たちを豊かにする「自己取引」のリスクについて2001年に書いたことがあるんだ。公共に価値のあるデジタル作品を非営利団体が作って、無料で提供できるのにアクセス制限して金を取る。それって、公共の財産（コンテンツ）を私腹を肥やすために使うっていう自己取引じゃない？ それって合法なの？<br>助成金で作ったものを企業に売って、スタッフの懐に入れるのも自己取引と一緒じゃない？ 地べたを売ったら捕まるだろうに。コンテンツやソフトの販売は少額だから許されてる感じ。政府の助成金で作ったものを開発者が現金化してるってことだよ。出資者はそういう「スピンオフ」をむしろ奨励してるんだ。もしそのグループが映画会社にソフトを100万ドルで売ったって誰も何も言わないだろ？ （どうせ普段からそういう売り上げで稼いでるんだろうけど。）<br>でもこれって、慈善事業で資金を得たソフトをMicrosoftに売って一括で金を配る自己取引とどう違うんだ？ 「アート」が関わってるから全部OKなの？ 技術者がしっかり稼ぐのはいいし、技術的な成果からして当然の報酬だろう。問題なのは、公開された資金で作られたものの成果に、俺も含めた一般人が完全にアクセスできない方法で著作権管理されてるってことだよ。（いくつかの出版物だけで、大事なソースコードとかは無し。）<br>ただ、サービスを提供するためにかかる費用（例えばGPU compute）を請求するのは、必ずしも自己取引じゃない。問題になり得るのは、ソースコードを制限したり、特許を使ってサービス周りに人工的な希少性を作ることの方だな。" userName="pdfernhout" createdAt="2025/05/06 00:02:23" color="#785bff">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="なんか変だよな、世間から注目されてるたくさんの会社が「俺たちはデジタルゴッドを作ってる、核兵器より強力な道具だ」って堂々と言ってて、何十億ドルも集めてるのに、誰も何も言わないって…。" userName="pants2" createdAt="2025/05/05 18:37:20" color="">}}




{{<matomeQuote body="本当にAIが「核兵器」になると信じてる人と、実際に生成AIを触った経験のある人と、ぜひ話してみたいね。<br>この二つの条件を満たす人って、なかなか見つからないみたいだけど。<br>今の段階では、俺たちが作ってるAIは、刺激（例えば「プロンプト」）に反応する、めちゃくちゃ便利な入出力装置にすぎないよ。刺激がなければ、何も出てこない。<br>これは核兵器じゃないし、うっかりSkynetを作っちゃうなんてことはない。<br>唯一「核になる」かもしれないのは、自動化されるであろう仕事の市場に対してだけ。それは、まだ経済的に準備ができてないかもしれない社会に対してだよ。<br>もし何か「危険」があるとしたら、それはAGIが印刷機とか、綿繰り機とか、馬なし馬車とか、そういうもの全部を同時に、そしてそれ以上に、まだ受け入れ態勢ができてない世界にもたらされるってことだろうね。<br>でも、自動化できる仕事を保護するために、技術の進歩をむやみに止めるべきじゃないよ。俺たちは適応する必要があるんだ。" userName="CorpOverreach" createdAt="2025/05/06 03:09:24" color="">}}




{{<matomeQuote body="次の意見で、君が反対なのはどれ？<br>- スーパーインテリジェンスは人類にとって生存の危機だよ<br>- 未来を予測するのはめちゃくちゃ難しいって有名だよね<br>- その不確かさを考えたら、今のAIの進め方がスーパーインテリジェンスに繋がる可能性を否定できないだろ<br>- 1000分の1の生存危機だってめちゃくちゃ深刻だ。もし小惑星が地球に衝突して人類を滅ぼす可能性が1000分の1だったとしたら、真剣な対策を立てるべきだよ。<br>二つ目の質問：君は自分の意見にどれだけ自信があるの？ 99.9%絶対って言える？ 自分の信念に何十億もの命を賭けられるくらい自信ある？ 未来に関する意見で、俺がそんなレベルの自信を持てるものはほとんどないね。" userName="thurn" createdAt="2025/05/06 04:49:15" color="">}}




{{<matomeQuote body="学術界や産業界の多くの人が、もっと監視が必要だって言ってるよ。遅れてるのはアメリカ政府だね。ヨーロッパのAI Actは受け入れられないリスクのあるアプリケーションを禁止してるんだ。" userName="esafak" createdAt="2025/05/05 18:40:08" color="">}}




{{<matomeQuote body="＞技術の進歩はむやみに止めるべきじゃないよ。俺たちは適応する必要があるんだ。<br>じゃあ、あんたの経済的な価値がゼロになって、すべての人間労働が機械に置き換えられても気にしないってこと？<br>UBI頼みで、最低限の部屋に住んで、スロップ（家畜の餌みたいなもの）を食ってるってこと？" userName="azinman2" createdAt="2025/05/05 18:47:31" color="">}}




{{<matomeQuote body="＞技術の進歩はむやみに止めるべきじゃないよ。俺たちは適応する必要があるんだ。<br>じゃあ、あんたの経済的な価値がゼロになって、すべての人間労働が機械に置き換えられても気にしないってこと？<br>UBI頼みで、最低限の部屋に住んで、スロップ（家畜の餌みたいなもの）を食ってるってこと？" userName="voidspark" createdAt="2025/05/06 04:33:06" color="">}}




{{<matomeQuote body="そんな未来ってどんなのさ？ Chinaがディストピアに向かうなら、なんでヨーロッパも律儀にそれに従わなきゃならないの？<br>技術全体を禁止せずに、使い方だけ selectively ban できるじゃん。例えば、原子力発電は許されてるけど、核兵器は厳しく管理されてるみたいに。" userName="esafak" createdAt="2025/05/05 18:54:22" color="">}}




{{<matomeQuote body="そうだよ！ 夢みたいだ。俺の価値は経済システムなんかじゃなくて、俺自身が決めるんだ。働かなくていいなら、やることがたくさんあるだろ。もちろん、これは実際にUBIにたどり着けて、それが widespread poverty を生まないって前提だけど。でも、たとえ humanity が widespread poverty を経験しなきゃならなくても、反対側では probably come out with UBI になってるだろうね（数億人餓死するかもしれないけど）。<br>やることも、探検することも、学ぶことも、たくさんあるんだ。AIが俺の仕事を盗むかもしれないって prospect は、俺の income がその仕事に依存してるから怖いだけだよ。" userName="TobTobXX" createdAt="2025/05/06 07:21:25" color="">}}




{{<matomeQuote body="＞やることも、探検することも、学ぶことも、たくさんあるんだ。<br>趣味とか、友達とつるむとか、読書とか、結局それくらいだろ。<br>たぶん international travel なんかも無理だろうし。<br>それは low income での simple retirement みたいなもんだよ。なぜなら、socialist system では資源が rationed されなきゃならないからね。<br>これはたくさんの young ambitious people を insanity に追い込むだろうな。達成できる meaningful なことが何もない。Purpose がないんだ。Drug use、debauchery、depression、violence、degeneracy、gangs。<br>まさに true idiocracy になるよ。Darwinian selection pressures もない、 unless the system enforces eugenics and population control でもしない限りね。" userName="voidspark" createdAt="2025/05/06 07:37:50" color="">}}




{{<matomeQuote body="中国がディストピアに向かってるなら、なんでヨーロッパも律儀についていく必要があるわけ？もっと大事な問いはこれだと思うんだ：中国のディストピアとヨーロッパのどっちに住みたい？" userName="BeetleB" createdAt="2025/05/05 19:21:56" color="">}}




{{<matomeQuote body="ヨーロッパのディストピアはAIが原因じゃないだろうから、それは偽の二択だよ。" userName="esafak" createdAt="2025/05/05 19:33:47" color="">}}




{{<matomeQuote body="全く同じ議論を使って逆の主張もできるよ。「”超知能こそ人類を確実な絶滅から救える唯一のものだ”」と前提を変えれば、超知能を作らないのはリスクだって結論になる。同じ推論で正反対の結論が出るってことは、その推論がおかしいってことだね。" userName="tsimionescu" createdAt="2025/05/06 08:14:53" color="#ff5c5c">}}




{{<matomeQuote body="君の問いはPascalの賭けみたいだね。 ”超知能”なんてまず無理。役立つAIはできるだろうけど、脅威になるのは遠い未来か、ずっとない。<br>未来予測が難しいのは確かだけど、それを行動の理由にはできない。「”本当の脅威は別の方向から来るかも？”」と言えるからね。AI以外の終末シナリオはたくさんある。全ての終末シナリオのリスクをなくそうとするのが、ある意味で一番やばいシナリオだよ。" userName="geysersam" createdAt="2025/05/06 06:13:37" color="#ff5733">}}




{{<matomeQuote body="EUは、この核兵器みたいなものの最悪の結果を抑え込むためにAI actを通したし、実際そうしてる。ここはあんまり評判良くないけどね。「”digital god”」って見方がその理由を説明するかも。多くの人にとって、これは宗教運動、つまり他に行き詰まった経済システムの救世主みたいになっちゃったんだ。" userName="saubeidl" createdAt="2025/05/05 18:41:07" color="">}}




{{<matomeQuote body="LLMがどうして核兵器より強力なの？マジで知りたいんだけど。" userName="xandrius" createdAt="2025/05/05 22:04:58" color="">}}




{{<matomeQuote body="全くその通り。それまで無神論者とか不可知論者だった人が、どうしてこんなにあっさり”避けられないAGIによる終末”って祭壇を崇拝し始めたのか、正直かなり衝撃だよ。まるで過激派Christiansが携挙を待ってるのと同じやり方だね。" userName="rchaud" createdAt="2025/05/05 18:51:27" color="#785bff">}}




{{<matomeQuote body="うーん、多分そうじゃないかもね。もしかしたらLLMには人間にはない限界があるのかもしれない。だからGPT-2からGPT-3、GPT-3からGPT-4への目覚ましい進歩が続いてないのかも。確かにGPT-4は最大の核兵器より強力には見えないね。<br>でもOpenAIはLLMだけじゃない。目標はあらゆる知的タスクで人間を超える汎用AIを作ること。核兵器設計とか、新しい物理・化学発見とか、AI自体を作ることもね。それができれば無制限に核兵器作れるとか、どんな核兵器より強力ってわかるでしょ？<br>もしLLMがダメなら、OpenAIは遅かれ早かれ他の方法を試すだろうね。無理かもしれないけど、OpenAIはそう言ってないよ。" userName="kragen" createdAt="2025/05/06 15:52:56" color="#ff5c5c">}}




{{<matomeQuote body="＞不確実性を考えると、今のAIアプローチがsuperintelligenceにつながる可能性を排除できない<br>君もこれが弱い点だって気づいてると思うけど。ゴミ箱の腐ったバナナの皮が自然に意識を持つ可能性も排除できないでしょ？だからって、その皮を捨てるリスクを冒すべきじゃないってこと？あまりにも突飛すぎて、それを「あり得る」とするには何かしら理由が必要だろ。今のAIアプローチも同じだよ。" userName="quietbritishjim" createdAt="2025/05/06 12:27:45" color="#ff5733">}}




{{<matomeQuote body="俺が言いたかったのはね：Europeは今のまま規制を選ぶこともできるけど、そしたらChineseが規制なしのAIから大幅に利益を得るせいで、結局はChineseのディストピアに住むことになるかもしれない。それか、自分たちでAIディストピアを作るかだ。AIじゃないディストピアが一番ありえないシナリオだよ。" userName="BeetleB" createdAt="2025/05/05 19:42:36" color="">}}




{{<matomeQuote body="昔も技術で仕事が変わるって心配されたけど、社会は適応してきたんだ．綿繰り機や車、電話交換機みたいにね．今も失業率は低いし、仕事は変わるだろうけど無くなるわけじゃない．移行には痛みもあるだろうけどね．" userName="cik" createdAt="2025/05/06 04:52:07" color="#45d325">}}




{{<matomeQuote body="それは違うよ．予防原則って言って、ヤバいリスクの可能性が小さくても注意しようって考え方だ．核技術みたいにAIも規制すべきかって話だよ．超知能が救世主って前提でも、リスク管理は重要だ．どっちのシナリオが現実的かが論点であって、リスク考え方が間違ってるわけじゃない．原子力と同じで、強力な技術は慎重に扱わないとね．アメリカの規制緩和は逆行してる例だろ．" userName="throw101010" createdAt="2025/05/06 10:09:29" color="#ff33a1">}}




{{<matomeQuote body="＞”超知能”を作る可能性は極めて小さいと思う．<br>俺は超知能を全く作れない可能性こそ極めて小さいと思うな．人間脳が可能な最大の知能に到達したと信じるか、AIの進歩が理由もなく止まると信じるかのどっちかだ．予測市場のほとんどの予想屋は、10年以内にAGIができるって予測してるぜ．" userName="nearbuy" createdAt="2025/05/06 20:12:20" color="">}}




{{<matomeQuote body="絶滅級の小惑星が来たら、君が恐れる超知能が助けてくれるかもって考えない？その極端な怖がり方は性格だよ．未知が怖いんだろ．バスに轢かれるかもって毎日起きてるじゃん．火を発明した部族なら、世界が燃えるのが怖くて反対するタイプだよ．リスクはあるけど、火が絶対良い発見だったってのは否定できないだろ．" userName="pembrook" createdAt="2025/05/06 06:21:07" color="">}}




{{<matomeQuote body="問題はまさにその不確実性なんじゃないか？腐ったバナナの皮が自然発生的に意識を持つことはないっていうデータはたくさんあるけど、未来を予測する明確な方法はない．そして、現在のAI研究の道筋から超知能が発生する本当の可能性を知る方法もない．それが100分の1なのか、1e12分の1なのかって不確実性自体が議論の一部で、人々はその可能性がどこかにあるって信じるように色々バイアスがかかってるんだ．" userName="km144" createdAt="2025/05/06 12:55:00" color="">}}




{{<matomeQuote body="中国がAIでヨーロッパを攻撃するかもしれないって示唆してるなら、国内でAIを解き放たなくても防衛に投資できるだろ．それに、中国が規制のないAIでユートピアになるとは思わないな．俺が訪れた印象はユートピアじゃなかったし、彼らがどう技術を使ってるか知ってるから、AIがユートピアをもたらすとも思えないね．俺たちのユートピアのビジョンとは違うんだ．彼らは今の状況を楽しんでるかもしれないけど、もし状況が悪化したら後悔するかもしれないな．" userName="esafak" createdAt="2025/05/05 19:51:03" color="">}}




{{<matomeQuote body="そうそう、低収入だけど老いてない引退生活みたいだよ．俺も勉強中で収入低いけど、面白いことだらけだ．3Dプリンターで真空ポンプ作ろうとしてるとかさ．既製品あるけど、作る過程が楽しいんだ．<br>野心的な若者が狂うって言うけど、狂うのは野心ない連中だよ．野心ある奴は常に何かプロジェクトを見つけるさ．ジェネレーティブAI時代でも絵を描くのを楽しむみたいにね．人間は創造性から喜びを得るんだ．Hacker Newsだって元は金じゃなく、面白さでハッキングしてたんだぜ．" userName="TobTobXX" createdAt="2025/05/07 10:43:00" color="#ff5733">}}




{{<matomeQuote body="この考え方は核兵器の時と変わらないね．一番の違いは可観測性だ．衛星があれば他の国が条約を尊重してるか、相互確証破壊に十分な反応時間があるか、ある程度自信があったけど、このAI開発にはそれが全くない．" userName="nicce" createdAt="2025/05/05 18:53:09" color="#45d325">}}




{{<matomeQuote body="「今日のAGIじゃないからAGIにならない」って考え方にちょっと似てるな。今のAIはコード書く生産性上げる？多分ね。OpenAIのエンジニアはもっと高性能なモデルで生産性上げてんの？多分ね。もしあるグループだけ20%生産性上がって、それで作ったv2.0で25%、v3.0で30%ってなったら…。「AGIは技術的に可能か」「肉体にしかない特別なものはあるか」って問題になる。いつかAGIは見つかるだろうし、今の技術が助けになるだろう。大事なのは道のりであって、2025年5月時点の特定のLLM技術のバージョンじゃないんだよ。" userName="coryfklein" createdAt="2025/05/06 14:01:17" color="#45d325">}}




{{<matomeQuote body="＞超知能は人類に実存的脅威をもたらす<br>少なくともこれには反対だな。超知能が生まれたのに、どういうわけか人間に匹敵する凡庸さに留まるなんてシナリオは考えられない。そんな均衡はすごく狭い範囲だし、機械知能がそこに落ち着く理由もない。そんな確率は限りなく低いよ。君のコメントの後半の1/nの部分もかなり変わってくるね。" userName="OtherShrezzing" createdAt="2025/05/06 07:37:43" color="#785bff">}}




{{<matomeQuote body="これはWeb 1.0の広告漬け底辺競争の繰り返しを避けるチャンスを逃してる瞬間だね。<br>人生を変えるようなコミュニティリソースから、詐欺的でユーザーに敵対的なものへの変化をもう一度経験するのを楽しみにしとくよ。" userName="A_Duck" createdAt="2025/05/05 21:52:18" color="">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="これ、すごく分かる。今日LLMとすごく生産的な会話ができたんだけど、その価値の大部分は、何かを売ろうとしたり、SEO上げたり、広告表示させたりせず、僕の質問に集中的に答えてくれたことだって気づいたんだ。ただ、助けてくれただけ。普段敵対的に感じるデジタル世界で、それが信じられないくらい新鮮だったんだ。<br>それから、いつここに広告が出始めるんだろうって考えが浮かんだ。<br>直接お金を払うことを学ぶか、オープンソースのモデルが十分良くなれば、このシンプルさと集中をしばらく楽しめるんじゃないかって思いたいね。願ってるよ！" userName="zharknado" createdAt="2025/05/06 00:11:08" color="#38d3d3">}}




{{<matomeQuote body="＞直接お金を払うことを学ぶか<br>でも月20ドルは足りないんじゃないかな。Googleみたいな会社はOpenAIが破産するまでAIを無料で配り続けることもできるしね。" userName="sumedh" createdAt="2025/05/06 01:35:23" color="">}}




{{<matomeQuote body="「良い」点は、これが広告でサポートするには高すぎるってことだね。すごく小さくて安いモデルを使った広告付き製品は出るかもだけど、最先端のやつは常に計算資源も最先端で、誰かが費用を払う必要がある。投資家がコストのかなりの部分を補助しても、最高のモデルを実務でたくさん使うのはまだすごく高いよ。" userName="danenania" createdAt="2025/05/06 00:58:01" color="">}}




{{<matomeQuote body="サブスクリプションサービスでも広告は売れるよ。HuluとかNetflixを見てみて。Spotifyはお金払えば「ラジオ広告」は流さないかもしれないけど、ホーム画面でアーティストを広告するだろう。これらのモデルが高いってことは、収益性を追求する際に可能なあらゆる収益化方法を検討するだろうって考えにつながる。広告が対象外になるどころか、むしろ広告がより早く検討されるようになる可能性すらあるんじゃないかな。" userName="aylmao" createdAt="2025/05/06 01:09:30" color="#ff33a1">}}




{{<matomeQuote body="そうなる可能性もあるかもしれないけど、広告からユーザー一人あたりが得られる収益は、計算コストに比べたら基本的に取るに足らないよ。ユーザーを怒らせてまで、すごくわずかな利益を得るなんてことはしないだろう。" userName="danenania" createdAt="2025/05/06 01:29:27" color="">}}




{{<matomeQuote body="モデルは時間が経てば必ず変装したセールスマンになることは保証されてるよ。世の中ってそういうものだから。競争がそれを阻止してくれることを願うけど、疑わしいね。全体主義体制がこれを大好きになる理由もそこにある。現実の改変版を吐き出すように簡単に訓練できるんだから。" userName="toxik" createdAt="2025/05/06 09:32:50" color="">}}




{{<matomeQuote body="広告でサポートするには高すぎるなんてことはないよ。ONLY広告でサポートするのは高すぎるかもしれないけど、収益源の一つとしてなら他のソースの上に重ねられるんだ。例えば、月100ドルのケーブルパッケージで表示される広告を見てみて！" userName="advisedwang" createdAt="2025/05/06 17:14:03" color="#785bff">}}




{{<matomeQuote body="Sam Altmanには懐疑的な意見も多いけど、Ben Thompsonとかのインタビューを聞くと、本人はOpenAIに広告モデルを入れたくないって言ってるよ．でも、本心だとしてもインセンティブは無視できないよね（だって広告って、みんなに届けたいならすごく強力なビジネスモデルじゃん）．" userName="wrsh07" createdAt="2025/05/06 11:37:58" color="#ff33a1">}}




{{<matomeQuote body="いい感じのLLMの選択肢は今後もなくならないと思うよ．オープンなLLMの研究開発は超速いし、distillationとかで性能も維持されるはず．softwareとhardwareの最適化でinferenceコストも下がり続けるしね．RAMで動くbit-quantized LLMとかも出るかも．<br>これで変な裏がないオープンな代替は存在するはず．ただ、みんなが動かすhardwareを持てるか、広告我慢するかは別の話だけどね．" userName="pradn" createdAt="2025/05/06 14:52:52" color="#785bff">}}




{{<matomeQuote body="で、ここが難しいところ．競争やイノベーションとのバランスを取りながら、こういう事態を防ぐ政策をどう設計するか．<br>そのステップと、政治家を動かしてそれを実現することだけが、望まない結果を止められる唯一の方法だよ．" userName="energy123" createdAt="2025/05/06 07:34:50" color="">}}




{{<matomeQuote body="将来的にはAIはコモディティ化するだろうね．今のWi-fiルーターみたいな形で、家庭用のinference serverを買えるようになるよ．安くて、オープンソースも商用モデルも山ほど選べる．モデルはボタンクリック一つでダウンロード（torrentとかでも）．" userName="otabdeveloper4" createdAt="2025/05/06 07:26:33" color="#38d3d3">}}




{{<matomeQuote body="それ、今のデスクトップでもスペックちょっと上げればできるよ．" userName="anticensor" createdAt="2025/05/06 08:11:01" color="">}}




{{<matomeQuote body="安くてinferenceに特化した中国製のシングルボードコンピュータが、足りないピースかな．（GPUとかNvidiaとかじゃなくてね）．<br>あと、今のAIエージェントはマジでクソ．でもそれは作ってる人のスキル問題で、近いうちにマジの進歩があるはず．" userName="otabdeveloper4" createdAt="2025/05/06 10:08:05" color="#ff5733">}}




{{<matomeQuote body="DGX SparkとかFramework Desktopってそんなに安くないの？" userName="anticensor" createdAt="2025/05/06 14:24:58" color="">}}




{{<matomeQuote body="うーん、あんまりね．最終的には家電並みの価格と手軽さになると思うよ．（Wi-fiルーターレベル）．" userName="otabdeveloper4" createdAt="2025/05/06 18:00:02" color="">}}




{{<matomeQuote body="小さいモデルがどんどん賢くなってるよね．それにツールや連携機能を組み合わせれば、オンラインでやってることの大半は家の中のインフラでできちゃうよ．" userName="mlnj" createdAt="2025/05/06 09:57:30" color="#45d325">}}




{{<matomeQuote body="LLMの応答に広告が混じるなんて、どう考えても悪じゃん．だからOpenAIは、非営利部門が支配権を持ってる限り（今もそうだけど）、絶対にやらないよ．非営利部門が許すわけないから．" userName="NoahZuniga" createdAt="2025/05/06 01:24:03" color="">}}




{{<matomeQuote body="LLMsが恐ろしいのは、広告みたいに露骨じゃなく、テキストに微妙なバイアスをかけるだけで世界にすごく影響を与えられること。昔、クラシック音楽会社で働いてた時、トレンド予測についてベテランに聞いたら”予測しない、静かに教えてあげれば聞く”って言われたんだ。マーケティングは目立たないけど、ジャーナリストとの会話とかで少しずつ業界に影響を与えてた。LLMsは対処できないくらい強力な影響力を持つ可能性があるね。" userName="Twirrim" createdAt="2025/05/06 01:39:34" color="#45d325">}}




{{<matomeQuote body="＞LLMsは、世界全体に影響を与える恐ろしい力を持ってて、俺たちには対処する準備ができてないんだよ＜br＞LLMsをTVとか、smartphones、あるいはmcdonald’sに置き換えてみてよ、そしたら同じ考えになるでしょ。<br>TVを通じて、企業はソーシャルな世界や人々の行動の多くをコントロールしてきたんだ。" userName="gooob" createdAt="2025/05/06 02:52:59" color="">}}




{{<matomeQuote body="OK、でもこれってやっぱり明らかに悪じゃん、だからコントロールしてる非営利組織だってこれを許さなかったでしょ。" userName="NoahZuniga" createdAt="2025/05/09 20:01:05" color="">}}




{{<matomeQuote body="広告とかSEOだけどAI応答付きって、人間の注意をどれだけコントロールできるか、そして（まともな無料のopen-weightsの代替があるのに）人々がお金を払いたがらないって事実を考えたら、最初から明らかだった結末だよね。" userName="aprilthird2021" createdAt="2025/05/06 01:29:46" color="">}}




{{<matomeQuote body="OpenAIの元の形は、ある種の自由なテクノロジーの最後のあがきだったと思う。「良いこと」が大事な世界では非営利が理にかなってた。でも最近のAltmansとかpmarcasは、権威主義的で自己中心的な世界観を気楽に表現してるね。Open AIの構造変化はそれに沿ってる。彼らはいつも王様になりたがってたけど、今は”良いこと”を装わずにそれができるようになったってわけだ。" userName="drewbeck" createdAt="2025/05/05 19:15:48" color="#ff5733">}}




{{<matomeQuote body="アメリカのculture warのある一派の一般的な正説に従わないだけで、誰にでも”authoritarian”っていう形容詞を使うのは合理的かな？　俺にはここで起きてることがそう見えるんだけど、間違ってたら嬉しいな。samaとかpmarcaから、俺が”authoritarian”と分類するようなものは見たことないんだけど。" userName="sneak" createdAt="2025/05/05 19:21:45" color="">}}




{{<matomeQuote body="インターネットに理想的な過去は最初からなかったんだ。一部無料の試みはあったけど、民間化後は企業の利益優先に。Web 2.0以降は集権化、監視、操作が目的だった。Cambridge Analyticaで驚いてたけど、昔から知ってた俺らは呆れてたよ。USPSが無料ホスティングとか提供したら変わるかもって考えたけどね。画面に縛り付ける今の心理操作じゃなく、自分でネットとどう関わるか選べるようにするのが大事。インターネットの昔は良かったっていうのは幻想だよ。この混乱を直す第一歩は、まずその害を認めることだね。" userName="stego-tech" createdAt="2025/05/05 19:49:43" color="#ff5c5c">}}




{{<matomeQuote body="彼らはAyn Randの考え方を深く信じてるんだ。自分たちに一番個人的な富をもたらすシステムが、人類全体にとっても最高のシステムだってね。" userName="jimbokun" createdAt="2025/05/05 20:26:59" color="">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
