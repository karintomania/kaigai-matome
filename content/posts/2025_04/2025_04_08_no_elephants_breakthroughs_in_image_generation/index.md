+++
date = '2025-04-08T00:00:00'
months = '2025/04'
draft = false
title = 'マジかよ！画像生成AIが激進化！もう「部屋に象」なんて言わせない！'
tags = ["画像生成AI", "AI", "機械学習", "技術革新", "デザイン"]
featureimage = 'thumbnails/color2.jpg'
+++

> マジかよ！画像生成AIが激進化！もう「部屋に象」なんて言わせない！

引用元：[https://news.ycombinator.com/item?id=43590569](https://news.ycombinator.com/item?id=43590569)

{{<matomeQuote body="画像生成のビフォーアフターって感じだね。YouTubeの音楽チャンネルの背景とか、AI生成の適当な画像が多いけど、もうすぐなくなるかもね。でも、LLMとかもそうだけど、意外と使わないんだよね。10年前ならめっちゃ興奮してたと思うけど。プログラミングの質問とかは便利だけど、まだ全然使いこなせてない気がする。" userName="x187463" createdAt="2025-04-08T10:07:49" color="">}}

{{<matomeQuote body="LLMで画像生成するのめっちゃ好き。自分はクリエイティブだけど、芸術的なスキルは全然ないから。でも、想像した画像を言葉で説明するだけで、90%くらいの精度で表現できるから、プレゼン資料とか、オンラインのペットプロジェクト（リスをテーマにした算数ゲームとか）にめっちゃ役立ってる。" userName="Gasp0de" createdAt="2025-04-08T15:14:19" color="#ff33a1">}}

{{<matomeQuote body="＞For many, many websites this is going to be good enough.”<br>多くのサイトで十分って言ってるけど、ストックフォトでほとんど解決してた問題じゃん。今の会社のウェブサイトもストックフォトだらけだし。ビジネス用途なら、AI画像生成がなくても、ストックフォトで十分だったと思うよ。「ビジネススーツを着た男が叫びながら人を蹴り飛ばす」みたいな写真ですらあるし。" userName="nitwit005" createdAt="2025-04-08T18:37:40" color="">}}

{{<matomeQuote body="え、どのストックフォトサービスに、高校で算数とか勉強してるリスの写真があるの？ストックフォトで全てが解決するなんてありえないでしょ。選択肢が多すぎて疲れて妥協することもあるけど、満足してるわけじゃないし。GenerativeAIなら、リスに何でもさせられるじゃん。気に入らなければ、説明を調整すればいいし。便利だと思う人がいてもおかしくないよ。" userName="dylan604" createdAt="2025-04-08T22:52:37" color="#785bff">}}

{{<matomeQuote body="Shutterstockでリスが算数してるのを検索してみたよ。こんなのがあったよ。<br>https://www.shutterstock.com/image-vector/pensive-squirrel-d…<br>ニッチな用途だったり、大量のユニークな画像が必要だったりする場合は難しいけど、ほとんどの場合はストックフォトで解決できるって言いたかったんだ。" userName="nitwit005" createdAt="2025-04-08T23:49:42" color="">}}

{{<matomeQuote body="最近の画像生成は、結局のところ画像検索みたいなもんだよね。画像が以前から存在してたかどうかは、ほとんど関係ない。" userName="sroussey" createdAt="2025-04-09T04:50:27" color="">}}

{{<matomeQuote body="AIは色々イマイチな点もあるけど、ストックフォトの代わりには十分なるよね。低品質な画像とかは、AIに置き換わると思う。ウェブサイト制作会社とかは、ちょっと焦ってるんじゃない？3～5個のプロンプトでレストランのウェブサイトが作れるなら、わざわざ人に頼まないでしょ。" userName="schwartzworld" createdAt="2025-04-08T23:15:13" color="#45d325">}}

{{<matomeQuote body="3～5個のプロンプトじゃ、プロのレストランのウェブサイトは作れないよ。大事なのは「プロの」ってとこ。レストランのウェブサイトは、まずお店とか料理のいい写真を撮るところから始まるんだよ。AIは写真撮りに来てくれないでしょ。予約システムとか、コンテンツ管理とか、メニューの更新とか、色々あるし。HTMLのテンプレートは昔からあるけどね。" userName="exodust" createdAt="2025-04-09T07:11:57" color="">}}

{{<matomeQuote body="ほとんどのレストランのウェブサイトには料理の写真なんてないよ。グーグルマップで適当に探して、ストリップモールにあるレストランのウェブサイトを見てみなよ。メニューがちゃんと載ってればラッキーって感じだよ。写真があったとしても、オーナーの子供がスマホで撮ったやつとかでしょ。ちゃんとやってるところもあるけど、ほとんどはそうじゃない。" userName="lupusreal" createdAt="2025-04-09T10:20:58" color="">}}

{{<matomeQuote body="絵心も経験もないのにリスの絵を描くのって、マジ楽しくないよね。音楽制作でミュージシャンに頼んだ時、自分ができないドラムフィルを何回もテイク重ねてエンジニアをうんざりさせるのも同じ。でも、すごいドラマーが自分のイメージを形にしてくれるのを見るのは超楽しい！" userName="williamcotton" createdAt="2025-04-08T18:34:37" color="#ff5733">}}

{{<matomeQuote body="＞自分のイメージがすごいドラマーによって形になるのを見るのがマジで楽しいって言ってるけど、<br>AIがアイデアを次々に出してくれるのも、同じように楽しい？" userName="schwartzworld" createdAt="2025-04-09T00:07:57" color="">}}

{{<matomeQuote body="LLMで絵を作るのがマジで好き。自分はクリエイティブだけど、絵を描くのはマジで苦手。でも今は、想像したイメージを説明するだけで、90%正確な絵が出てくるんだから。<br>何を使ってるか教えてほしいな。会社の内部チャットボットとコード統合で十分だったから、まだ有料プランには入ってないんだよね。無料版も試したけど、満足できるものができる前に使い切っちゃうし。<br>何にお金払ってるの？" userName="munksbeer" createdAt="2025-04-08T16:23:05" color="#45d325">}}

{{<matomeQuote body="子供たちとゲームの絵を作ったんだけど、アイデアから実行までの速さにマジ興奮してたよ！めっちゃ笑って楽しかった！APIの画像生成にお金払えばもっと早くなるのに、って思ったくらい。<br>会社のロゴも作ったし、友達とのゲームのミームも作った。「犬人間とギリシャの巨人が悪魔をボコボコにするカートゥーン」みたいなやつをAIに作らせたら、マジで面白くて最高の絵が出てきたんだよね！<br>2年前はStable Diffusionとかのローカルモデルで3時間かけてたのに、今は数分でいいものができるんだからマジでヤバい。" userName="wincy" createdAt="2025-04-08T16:40:32" color="#38d3d3">}}

{{<matomeQuote body="ありがとう。どのサービス使ってるか教えて！有料サービス試したいから、おすすめを知りたいんだ。" userName="munksbeer" createdAt="2025-04-08T17:36:13" color="">}}

{{<matomeQuote body="MidjourneyとchatGPTを使ったよ。Midjourneyは、いろいろ試して早く結果を見たい時とか、ちょっと変わった絵が欲しい時に良いね。パラメーターで調整しやすいし。<br>chatGPTは、具体的なイメージがある時にマジで優秀。でも遅いし、Midjourneyみたいに4つのバージョンから選んで発展させるんじゃなくて、1つの画像が出てくるのが遅いんだよね。" userName="HelloMcFly" createdAt="2025-04-08T19:14:15" color="#45d325">}}

{{<matomeQuote body="＞4つのバージョンから選んで発展させるってどういうこと？<br>どうやってモデルに4つの違うバージョンを作らせるの？それとも、4つの違うモデルに同じ推論をさせるの？" userName="throwaway2037" createdAt="2025-04-09T07:40:56" color="">}}

{{<matomeQuote body="知るかよ。アルバム10枚作っても3ドルにしかならなかったんだぞ。市場は飽和してて、10人が金持ちになる代わりに、100万人のアーティストが食えないんだよ。昔からずっとそうじゃん？才能があっても埋もれてる人なんていっぱいいる。戦争とか飢饉とか病気でどれだけのWilliam Shakesmanが死んだと思ってんだ？<br>数ヶ月前に南朝鮮のクーデター未遂の曲をAIに作らせてから、もう音楽は作らないって決めたんだ。ニュースになる前に曲が完成したんだぜ？AIにやらせれば同じ結果になるのに、なんで自分の耳を壊して音楽を作る必要があるんだ？誰も気にしないんだから。<br>https://soundcloud.com/djoutcold/coup-detat-symphony-remix<br>これも聞いてくれよな！<br>https://soundcloud.com/djoutcold/i-aint-even-writing-music-a...<br>ロジバン語だから分からんだろうけどな！" userName="genewitch" createdAt="2025-04-08T17:21:15" color="#45d325">}}

{{<matomeQuote body="＞戦争とか飢饉とか病気でどれだけのWilliam Shakesmanが死んだと思ってんだ？<br>（文脈無視してコメント失礼）<br>そんなに多くないかもね？「文化的な注目」って限られてて、トップの席は少ないのかもしれない。いつも有名なアーティストが数人だけ記憶されて、残りは忘れられるってことかも。ワールドカップで優勝するチームはいつも一つだけだし、普遍的な意味で質が高いとは限らないしね。" userName="Garlef" createdAt="2025-04-08T21:51:07" color="">}}

{{<matomeQuote body="この技術がアーティストに悪影響を与えずに使える方法がないってどういうこと？14歳の子たちがコンピューターサイエンスの授業でゲーム作って、AIで仮の画像を作ったら、それはアーティストを傷つけたことになる？先生は生徒全員のゲームにコンテンツを用意するお金ないし、生徒もアーティスト雇えないじゃん？契約もできないかも。未成年だし。この技術があれば、子供たちはもっと自由に創作できるし、創造的なことに興味を持つ人が増えるかもよ？だから、全面的に悪いって言うのは言い過ぎだと思うな。" userName="ldoughty" createdAt="2025-04-08T17:42:19" color="">}}

{{<matomeQuote body="面白い考え方だね。どういう根拠に基づいているの？人が生活のために働く必要がないってこと？つまり、労働じゃなくて遊びってこと？" userName="satvikpendem" createdAt="2025-04-08T18:58:17" color="">}}

{{< details summary="もっとコメントを表示（1）">}}
{{<matomeQuote body="それって自明の理じゃない？人が労働そのものを楽しんでる時（飢えをしのぐためじゃない時）は、趣味って言うでしょ。だから、人が飢える心配をしなくていいって言うのと同じようなことじゃないかな。" userName="fc417fc802" createdAt="2025-04-08T21:05:04" color="">}}

{{<matomeQuote body="常に明白とは限らないよ。特にこのサイトは、VCと関係が深いから、資本蓄積がテーマになりやすいし。" userName="satvikpendem" createdAt="2025-04-08T21:10:46" color="">}}

{{<matomeQuote body="どういうこと？例えば、獣医さんやアーティストが生活のために働くのは労働？それとも趣味？" userName="esafak" createdAt="2025-04-09T04:07:07" color="">}}

{{<matomeQuote body="まだ完全自動化された豪華なゲイ宇宙共産主義の段階じゃないから、労働は必要悪だね。" userName="65839747" createdAt="2025-04-09T00:17:54" color="">}}

{{<matomeQuote body="スマホのGeminiアプリで音声操作できるの、マジ便利じゃん？運転中に音楽代わりに使えると思ったけど、AIと何話せばいいか全然思いつかないんだよね。LMローカルでも動かしてるんだけどさ。" userName="genewitch" createdAt="2025-04-08T17:15:28" color="">}}

{{<matomeQuote body="AIの潜在能力は高いのに、普段使いしてる人が少ないっての、めっちゃ面白い視点だね。新しい技術が社会や経済に浸透するのには時間がかかるってことかな。<br>たとえAIの技術進歩が止まって、2030年のモデルが今と同じでも、人々や企業が新しい技術を使いこなせるようになるまでには、社会や経済の変化が何年も続くと思う。" userName="loudmax" createdAt="2025-04-08T12:39:55" color="#ff5c5c">}}

{{<matomeQuote body="画像生成ってまだ遅いよね。Googleの画像検索みたいに、たくさんの画像を瞬時に生成できたら、もっと楽しく使えるし、練習して使いこなせるようになると思うんだよね。" userName="skybrian" createdAt="2025-04-08T12:57:11" color="">}}

{{<matomeQuote body="＞AI生成の画像って、よく見ると意味不明なものが多いよね。ジャズチャンネルのコーヒーショップとか、メニューの文字がめちゃくちゃだったり、家具が混ざってたりするし。<br>マジそれな。YouTubeでそういう動画ばっかり流れてくる気がするんだけど、俺のアルゴリズムのせいかな？" userName="nyarlathotep_" createdAt="2025-04-08T13:09:40" color="">}}

{{<matomeQuote body="アニメの中割りのAIはどうなってるのかなと思って昨日調べてみたら、去年の時点ではゴミだったらしい。<br>＞https://yosefk.com/blog/the-state-of-ai-for-hand-drawn-anima…<br>もしかしたら、このマルチモーダルってやつで改善されるかも？" userName="card_zero" createdAt="2025-04-08T10:37:40" color="">}}

{{<matomeQuote body="そのブログ記事、1年前のものだよ。それから結構進歩してるよ。<br>https://doubiiu.github.io/projects/ToonCrafter/" userName="GaggiX" createdAt="2025-04-08T11:34:53" color="#45d325">}}

{{<matomeQuote body="マジですごいね。プロのスタジオによるコンテンツ制作が爆発的に増えるだろうね。CGのセルルックレンダラーみたいにさ。俺は今の低予算3Dモデルよりも、手描き＋AI中割りの方が断然好きだな。" userName="kridsdale3" createdAt="2025-04-08T16:56:00" color="#ff5c5c">}}

{{<matomeQuote body="値段の違いを考えたら、プロも使わざるを得なくなるんじゃない？制作コストが下がれば、クオリティが上がるか、コンテンツが増えるかのどっちかになるはずだから、良いことだと思うけどね。" userName="fc417fc802" createdAt="2025-04-08T21:14:41" color="">}}

{{<matomeQuote body="4oの画像処理は、画像生成内で一発で終わるんじゃなくて、エージェント的なシステムによるワークフローなんじゃないかっていう状況証拠があるみたいよ。つまり、ユーザーが「部屋に象がいない画像を作って」って指示したら、LLMがその指示を解釈して、画像生成AIが理解しやすいようにプロンプトを書き換えるってこと。で、LLMが書き換えたプロンプトが画像生成AIに送られる、と。編集も同じで、もっと複雑で、裏でいろんなツールが使われてるっぽい。自分で試してみて。画像を4oに送って編集を繰り返すと、毎回セピアフィルターがかかって、どんどんセピア色になるはず。これは、ワークフローのステップの一つが、複数回の編集を考慮してないから。もし一発で編集できるなら、セピア問題は起こらないはず。" userName="nowittyusername" createdAt="2025-04-08T16:04:38" color="">}}

{{<matomeQuote body="前にマルチモーダルなStable Diffusionチャットエージェントを作ろうとしたことがあるんだけど、YOLOを使って部分マスクを作ったり、dynamic controlnetsを使ったり色々やった結果、そんな単純なエージェントプロセスじゃないと思うな。プロンプトを使って最適なモデルのチェックポイントとかLoRAを選んだり、モデルに合うようにプロンプトを書き換えるのは、もう昔からよくあることだよ。" userName="vunderba" createdAt="2025-04-08T18:07:40" color="#785bff">}}

{{<matomeQuote body="＞Using the prompt to detect and choose the most appropriate model checkpoint and LoRa(s) along with rewriting a prompt to most appropriately suit the chosen model has been pretty bog standard for a long time now.＜br>それ、どこの会社がやってるの？全然聞いたことないんだけど。ほとんどの画像生成サービスは、スタイル（LoRAとかMidjourneyのsrefとか）を視覚的に選ばせて、裏で読み込むようにしてるよね。それはユーザーが明示的にコントロールしてるじゃん。" userName="echelon" createdAt="2025-04-08T22:04:21" color="">}}

{{<matomeQuote body="それ、画像の生成方法とは関係ないよね？OpenAIが言ってるのは、画像は単一のマルチモーダルモデルによって自己回帰的に生成されるってことだけだよ。嘘はついてないと思うけどな。" userName="nialv7" createdAt="2025-04-08T18:05:57" color="">}}

{{<matomeQuote body="自己回帰的に生成されるのと、一発で生成されるのは違うよね。フィードバックループがある可能性はあると思う。個人的には、小さいフィードバックループくらいはあるんじゃないかな。でも、OPが考えてるような複雑なエージェント的なワークフローではないと思う。" userName="pclmulqdq" createdAt="2025-04-08T21:45:35" color="">}}

{{<matomeQuote body="＞This is because in the workflow that is one of the steps that is naively applied without consideration of multi edit possibility. If this was a one shot solution where editing is done within 4o image model by itself, the sepia problem wouldn't be there.＜br>chatgptでそれを見たことないんだけど。毎回同じクエリを少し変えて実行してるんじゃないかな。例えば、「女性の写真を生成して」って言って、その後に「髪をブロンドにして」って言うと、新しい画像は顔の特徴も変わってたりする。" userName="Suppafly" createdAt="2025-04-09T02:52:02" color="">}}

{{<matomeQuote body="プロンプトの調整は、まあ普通だよね。みんなやってる。Grokでは、ダウンロード名に表示されてたよ。画像編集は面白いね。" userName="renewiltord" createdAt="2025-04-08T16:48:09" color="">}}

{{<matomeQuote body="自分が使ってるstable diffusionのソフトは全部、プロンプトの一部をファイル名にしてる。stable diffusionは最初のトークンを重視するから、CLIP/BLIPの仕組みの副作用だと思う。どの会社もstable diffusionとかtransformersのインターフェースを自作してないと思う。Hugging Faceからのコピペでしょ。llama.cppで動くDiffusion Language Modelが早くリリースされないかな。" userName="genewitch" createdAt="2025-04-08T17:12:55" color="">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（2）">}}
{{<matomeQuote body="Auto1111とかがファイル名にプロンプトを使ってるのは、便利だからだよ。CLIPの仕組みとか関係ない。OpenAIみたいな会社が、自前の推論システムとか画像モデルを使ってないなんて思ってるなら、橋を売りつけるよ。" userName="danielbln" createdAt="2025-04-08T17:23:32" color="#45d325">}}

{{<matomeQuote body="あなたの意見より自分の意見の方が大事。CLIP/BLIPについて私が言ったことを誤解してるみたいね。「ファイル名に表示する」ってコメントへの返信だよ。最初のトークンは後のトークンよりも重要視される。だから、正しくプロンプトを書けば、ファイル名は画像の正確な説明になる。特にdanbooruスタイルなら、スペースで区切ってタグとして使える。" userName="genewitch" createdAt="2025-04-08T20:31:17" color="">}}

{{<matomeQuote body="4oの画像操作って一発でやってないんじゃないかって話が出てるけど、マジそれな？　最初っからそう思ってたわ。なんか一枚の絵をポンって作るんじゃなくて、最初に全部が入るキャンバス作って、そこにパーツごとに生成してる感じじゃん？　誰かがワークフローを調整してるんだろうね。使う前から丸わかりだし、証拠とかいらなくね？" userName="diggan" createdAt="2025-04-08T17:37:54" color="#ff5733">}}

{{<matomeQuote body="画像パッチを自己回帰的に生成してる可能性もあるよね。ピラミッド型でさ。最初はめっちゃ低い解像度のバージョン（キャンバスみたいなやつ）作って、それから個別のパッチを作っていくみたいな。VAR [1] に似てるかも。<br>OpenAIが教えてくれるまでわかんないけどね。[1] https://arxiv.org/pdf/2404.02905" userName="andy12_" createdAt="2025-04-09T08:12:32" color="">}}

{{<matomeQuote body="＞これは、マルチ編集の可能性を考慮せずにナイーブに適用されるステップの1つであるワークフローに原因があります。<br>いや、それはないと思うな。encoder/decoderとかモデル自体のバイアスって可能性もあるし。画像生成モデルってそういう挙動を示すこと多いし。それに、セピアフィルターが常に適用されるってのも変じゃん？　ワークフローなら意味なくね？<br>エージェント的なワークフローだけじゃ無理だと思う。エージェント的なワークフローって人間が手動でできることを速くしてるだけじゃん。画像モデルで2年くらい、出力の制御可能性について研究してたけど、普通のdiffusion modelでそんな編集は無理だよ。だから、エージェント的なワークフローは役に立たないと思う。<br>真のマルチモーダルモデルじゃないと無理じゃね？" userName="Voloskaya" createdAt="2025-04-08T17:53:01" color="#785bff">}}

{{<matomeQuote body="わかるー。自分もレイヤー構造になってるんじゃないかって思ってたんだよね。背景がボケてて、手前にシャープなカートゥーンキャラがいるのを見ると、そう思っちゃう。" userName="lawlessone" createdAt="2025-04-08T18:32:59" color="">}}

{{<matomeQuote body="コーヒーテーブルが入れ替わる例を見ると、画像が再処理されるたびに変化してて、前のバージョンを元にどんどん奇妙になっていくんだよね。伝言ゲームみたい。<br>・テーブルの上の変なバスケットの飾りは、最初は大きなチェーンリンク（ビーチの絵に合わせて錨のチェーンかも）が付いてるけど、3回目のバージョンでは革みたいになってて、バスケットと一体化してる。<br>・壁の燭台は、枝の飾りが付いてるけど、細いミニマリストの金色の鹿の頭になって、最終的にはただの枝になる。<br>・背景の小さなテーブルは、3本足のうち1本がなくなって、重力に逆らってる。<br>・窓の緑色のランプは、最初は普通になるけど、最終的にはトピアリーになる。<br>・カーペットの色褪せを少なくすると、テーブルの木材とか、他のものも彩度が上がる。" userName="card_zero" createdAt="2025-04-08T10:22:17" color="#ff5733">}}

{{<matomeQuote body="リクエストごとに新しい画像を生成してるのは明らかだよね。diffusion decoderって人もいるけど、VARの実装の方が可能性高いと思う。<br>https://arxiv.org/abs/2404.02905<br>ターゲット解像度でパッチを予測するんじゃなくて、最初はめっちゃ小さい解像度で始めて、どんどんスケールアップしていくんだよ。これだと、モデルが編集のために画像トークンをコピー＆ペーストすることを学習するのが難しいのかもね。" userName="og_kalu" createdAt="2025-04-08T13:30:56" color="#ff5c5c">}}

{{<matomeQuote body="それにしても、以前のシーンの再現度がマジで上がってる！　さっき、ネバダのハイウェイでバイカー仲間とセルフィーしてるクオッカとハイラックスの写真を頼んだら、ちゃんとできたんだよ。で、今度は同じ写真で夕方の光を入れてって頼んだら、数ヶ月前なら絶対に無理だったのに、前のコンテキストをちゃんと理解してて、マジすごい。<br>あと、フライングスクイレルが蝶の羽が生えたリスじゃないってことも理解してる！" userName="flkiwi" createdAt="2025-04-08T13:40:40" color="#ff5c5c">}}

{{<matomeQuote body="わかる。4oが他のモデルにプロンプトを送ってるんじゃなくて、4o自身が画像を生成してるってことだよね。モデル内の生成メカニズムについて推測してるんだ。" userName="og_kalu" createdAt="2025-04-08T13:47:24" color="">}}

{{<matomeQuote body="いやいや、反論してるわけじゃないよ。同じ画像を編集してるんじゃなくて、毎回ゼロから描き直してるけど、前の画像のコンテキストを理解して、それを調整してるってのがすごいって言いたかったんだ。完全に同じにはならないけどね。" userName="flkiwi" createdAt="2025-04-08T13:52:40" color="">}}

{{<matomeQuote body="今のGPT 4o画像生成の最大の欠点は、画像の一部だけを編集できないことだよね。毎回、元の画像をトークン化して、プロンプトに従って変換して、最終結果を出力してるんだと思う。ちょっとした編集をしたいだけなのに、画像全体が変わっちゃうから困る。" userName="M4v3R" createdAt="2025-04-08T11:27:40" color="#45d325">}}

{{<matomeQuote body="選択ツールで修正範囲を限定できると思ったけど、試したら選択範囲外も変わっちゃうんだね。知らなかった。例えば、テープのリールとかも違うし。→ https://chatgpt.com/share/67f53965-9480-800a-a166-a6c1faa87c...  https://help.openai.com/en/articles/9055440-editing-your-ima..." userName="atommclain" createdAt="2025-04-08T14:59:38" color="">}}

{{<matomeQuote body="マジで選択ブラシって何なんだろう？LLMへのヒントみたいなもん？" userName="qingcharles" createdAt="2025-04-08T16:54:22" color="">}}

{{<matomeQuote body="手動で合成するってことじゃね？それでもinpaintingのパイプラインとか組むより全然マシ。" userName="danielbln" createdAt="2025-04-08T12:20:16" color="#ff5c5c">}}

{{<matomeQuote body="手動合成ってinpaintingより簡単なの？（しかも良い結果になるの？）簡単な例なら良いけど、3Dが絡むとズレそうじゃない？" userName="wavemode" createdAt="2025-04-08T14:20:33" color="">}}

{{<matomeQuote body="100％。Multimodal imagesは(今は)ComfyUIとかinpaintingより上だよ。画像生成のステップアップって感じ。オープンソースモデルが出てほしいな。DallEとかのオープンソース実装が出たら、コミュニティが色々拡張して、SaaSモデルより良い結果になるはず。" userName="echelon" createdAt="2025-04-08T13:37:10" color="#ff5733">}}

{{<matomeQuote body="GPT 4oとpixlrの組み合わせがマジおすすめ。4oで生成して、pixlrのAIツールで編集。特に削除はpixlrがマジで早くて信頼できる。" userName="iandanforth" createdAt="2025-04-09T02:00:51" color="#ff5733">}}

{{<matomeQuote body="っていうか、ほぼ全部ちょっとずつ変わってるね。椅子の数とか形、枕の模様、カーテンの模様、窓の外の景色、テーブルの木の部分、カーペットの模様とか…。青いソファはほぼ変わらないけど、ちょっとディテールがなくなる…。" userName="rob74" createdAt="2025-04-08T11:27:28" color="#ff33a1">}}

{{<matomeQuote body="最初は静物画っぽいのに、だんだん印象派っぽくなって、最後はただのシミみたいになるね。ガラステーブルの反射とか透明感もおかしくなるし。ずっと同じ画像を修正してたら、Deep Dreamみたいになりそう。<br>暖炉が小さな階段みたいになってるし。:)" userName="card_zero" createdAt="2025-04-08T10:44:30" color="">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（3）">}}
{{<matomeQuote body="ほとんどの人が、この手の画像が使われる場面じゃ、そんな細かいこと気にしないんじゃない？" userName="empath75" createdAt="2025-04-08T14:46:36" color="">}}

{{<matomeQuote body="他のアーティストが苦労して作り上げたスタイルをAIで再現するのはアリなの？ 出来上がったアートの所有権は誰にあるの？ 誰がそれで儲けるの？ AIの学習データに使われてるアーティストは？ 著作権のある作品を学習に使うのは法的に、倫理的にどうなの？ こういう疑問は前々からあったけど、ますます重要になってきてるよね。<br>結論には反対だな。この議論は2、3年前に終わってて、アーティストの作品が無断で使われるのはフェアじゃないって結論になったはず。テック企業が儲けすぎてるから、変えられないってことだよね。" userName="probably_wrong" createdAt="2025-04-08T10:39:34" color="#45d325">}}

{{<matomeQuote body="みんながそう思ってるわけじゃないと思うよ。著作権は広がりすぎてるって思ってる人も多いし（俺もそう）、AIはアートを広めるための進歩だと思ってる人もいる（今はクソだけど、デジカメも昔はクソだったじゃん）。<br>例えば、Studio Ghibliのスタイルがネットに広まったからって損したわけじゃないでしょ。俺はその後Ghibliの映画見たし、他の人もそうだと思うよ。収入は上がってるんじゃない？<br>“どうやってアートで稼ぐか”はまだ社会の課題だけど、AIの制限をなくしたからってアーティストの仕事が減るとは思わないな。" userName="Taek" createdAt="2025-04-08T11:43:10" color="">}}

{{<matomeQuote body="もっと言えば、著作権とか知的財産権って、金持ち（法的に権利を行使できる人）が得するだけの法律上のフィクションだと思う。小さいアーティストはアートを作ることでお金をもらうけど、企業は独占することで利益を得る。" userName="kelseyfrog" createdAt="2025-04-08T16:00:31" color="#ff33a1">}}

{{<matomeQuote body="そうじゃなかったら、小さいアーティストはお金をもらえなくて、企業は非独占から利益を得ることになるよね。" userName="jayd16" createdAt="2025-04-09T05:12:06" color="">}}

{{<matomeQuote body="＞Studio Ghibliのスタイルがネットに広まったからって損したわけじゃないでしょ。俺はその後Ghibliの映画見たし、他の人もそうだと思うよ。収入は上がってるんじゃない？<br>それって「お金は払えないけど、露出の機会になるから！」って言い訳と変わらない気がする。" userName="thwarted" createdAt="2025-04-08T17:05:07" color="">}}

{{<matomeQuote body="露出には価値があるよ！ アーティストに露出で支払おうとするのがネタにされるのは、露出する相手が100人で、そのうち99人がターゲット顧客じゃないみたいな場合だからね。<br>Studio Ghibliは数百万（もしかしたら数億）人に露出したし、そのうち5%以上は潜在顧客だったはず。<br>だから、露出に見合う価値があるなら、露出で支払うのはアリだよ。でも、露出で支払おうとする人のほとんどは、露出の価値を100倍以上に過大評価してるんだよね。" userName="Taek" createdAt="2025-04-08T17:52:21" color="#ff5733">}}

{{<matomeQuote body="＞Studio Ghibliのスタイルがネットに広まったからって損したわけじゃないでしょ。<br>Studio Ghibliは単なるスタイル以上のものがあるんじゃない？ みんなスタイルだけを見て作品を見てるわけじゃないと思うよ。<br>偽物の服とか時計とかアクセサリーを嫌う人が多いのは、スタイルだけじゃないからだよね。" userName="DeathArrow" createdAt="2025-04-08T12:00:58" color="">}}

{{<matomeQuote body="＞偽物の服とか時計とかアクセサリーを嫌う人が多い<br>そうかな？ 多くの人は“本物”を買ったと思ったら偽物だったってパターンが嫌なだけで、高品質な偽物か、めっちゃ安い偽物なら気にしない人も多いと思うよ。" userName="pixl97" createdAt="2025-04-08T21:41:56" color="">}}

{{<matomeQuote body="ほとんどのアーティストがこの技術を悪だって言ってるよ。少なくとも、この企業によるクリエイティブコミュニティへの虐待の被害者たちは、悪いって思ってるみたい。<br>＞AIの制限をなくしたからってアーティストの仕事が減るとは思わないな。<br>そう思ってるのは勝手だけど、実際には仕事が減ってるって言ってるアーティストが多いよ。景気が悪いせいかもしれないけど、この技術が仕事を奪ってるって信じざるを得ない。" userName="__loam" createdAt="2025-04-08T17:15:12" color="#45d325">}}

{{<matomeQuote body="マジレスすると、最近アーティストが仕事減ってるって言ってるらしいよ。<br>マジ？それは社会全体として、もっと安くアートを楽しめるってことじゃん。アーティストの欲に付き合うのはもう飽きたわ。" userName="Ray20" createdAt="2025-04-09T03:11:15" color="">}}

{{<matomeQuote body="AIのおかげでアートは増えるかもしれないけど、人間が作るアートは減るだろうね。" userName="mitthrowaway2" createdAt="2025-04-09T04:58:49" color="">}}

{{<matomeQuote body="Studio Ghibliはまだ影響ないかもしれないけど、それはまだ技術が追いついてないだけじゃん？誰かがプロンプトだけでGhibliっぽい映画作れるようになったらどうなるの？Ghibliはもう十分稼いだんだから、それでいいってこと？<br>そんな簡単に機械にコピーされちゃうなら、誰があんな投資する気になるの？アートの進化はどこから来るの？AIで凄いもの作っても、すぐにコピーされるのが当たり前になったら、誰も投資しなくなるよ。<br>法律はさておき、どんな世界に住みたいか考えるべきだよ。SNSが世界をどう変えたか、もう見てるじゃん。これからどうなると思う？" userName="mrdependable" createdAt="2025-04-08T22:57:03" color="#38d3d3">}}

{{<matomeQuote body="＞誰かがプロンプトだけでGhibliっぽい映画作れるようになったらどうなるの？”<br>別に何も起きないんじゃない？誰かがGhibliのスタイル（ただし、Ghibliのキャラとかブランドは含まない。つまり著作権とか商標に引っかからないもの）で映画を作ったとしても、何も変わらないでしょ。<br>だって、絵柄って著作権ないじゃん？" userName="drdaeman" createdAt="2025-04-09T01:24:06" color="">}}

{{<matomeQuote body="話が全然わかってないね。プロンプトだけで映画作れるなら、誰がGhibliみたいな映画にお金出すの？みんな過去の作品をパクるだけになって、何も新しいものが生まれなくなるよ。" userName="mrdependable" createdAt="2025-04-09T01:53:56" color="#45d325">}}

{{<matomeQuote body="何千万ドルもかかってた映画とかアート作品が、たった数十ドルで作れるようになるのが、なんで悪いことなの？<br>もっと野心的なアートが生まれるってことじゃん。Ghibliはもう成功したんだから、次の世代の番だよ。" userName="Taek" createdAt="2025-04-09T11:17:24" color="">}}

{{<matomeQuote body="＞何千万ドルもかかってた映画とかアート作品が、たった数十ドルで作れるようになるのが、なんで悪いことなの？”<br>オリジナルな絵柄が生まれなくなるからだよ。全部既存のスタイルのコピペになるんだよ、ずっと。" userName="otabdeveloper4" createdAt="2025-04-09T14:53:51" color="#ff5c5c">}}

{{<matomeQuote body="Studio Ghibliみたいな会社はAIのせいで困ってないよ。困ってるのは、フリーランスの小さなアーティストだよ。" userName="wavemode" createdAt="2025-04-08T14:24:58" color="">}}

{{<matomeQuote body="Studio Ghibliも影響を受けると思うよ。昔は「Ghibliっぽい絵柄」ってだけで歓迎されたけど、これからは安っぽい作品の代名詞になるかもしれない。（まるで、ソープオペラっぽい映像が低品質の証拠になるみたいにね。）" userName="masswerk" createdAt="2025-04-08T15:24:01" color="">}}

{{<matomeQuote body="そんなことないと思うよ。「どの映画がパクり元？」　「あ、どれでもない？」　「OK」　みたいな検索は簡単じゃん。" userName="butlike" createdAt="2025-04-08T16:26:18" color="">}}


{{< /details >}}


[記事一覧へ]({{% ref "/posts/" %}})
