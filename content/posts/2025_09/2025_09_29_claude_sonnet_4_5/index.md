+++
date = '2025-09-29T00:00:00'
months = '2025/09'
draft = false
title = 'Claude Sonnet 4.5ついに登場！高評価のコード解釈AIの実力は？'
tags = ["AI", "LLM", "プログラミング", "Anthropic"]
featureimage = 'thumbnails/light_colour3.jpg'
+++

> Claude Sonnet 4.5ついに登場！高評価のコード解釈AIの実力は？

引用元：[https://news.ycombinator.com/item?id=45415962](https://news.ycombinator.com/item?id=45415962)




{{<matomeQuote body="System cardのリンクだよ！チェックしてみて。https://assets.anthropic.com/m/12f214efcc2f457a/original/Cla..." userName="adocomplete" createdAt="2025/09/29 16:52:59" color="">}}




{{<matomeQuote body="週末にClaude Sonnet 4.5のプレビューを使ったよ！感想はここ。https://simonwillison.net/2025/Sep/29/claude-sonnet-4-5/<br>GPT-5-Codexより少し良いかも。特にClaude.aiのPython/Node.jsコードインタープリタモードがすごかった！試しに「https://github.com/simonw/llm をチェックして `pip install -e ’.[test]’` と `pytest` でテストを実行して」ってプロンプトを試してみて。複雑なデータベースリファクタリングもできたよ！" userName="simonw" createdAt="2025/09/29 18:23:52" color="#785bff">}}




{{<matomeQuote body="Simonwは陽気で真っすぐなAIジャーナリストで、ただ話すだけでなく見せるのが好きだね。LLMツールやモデルの進歩をうまくまとめててくれる。OpenAIとAnthropicが彼に最新情報を提供してるのは、彼が記事にするって知ってるからだと思うな。Simon、いつもありがとう！この分野で一番好きなジャーナリストだよ、口調も好き！" userName="Redster" createdAt="2025/09/29 18:52:53" color="">}}




{{<matomeQuote body="彼の「自転車に乗ったペリカン」テストは今や古典だね。AI企業はそれでベンチマークしてるんだって！" userName="rapfaria" createdAt="2025/09/29 20:19:05" color="">}}




{{<matomeQuote body="プレビューを使った人の意見は意味ないかも。一般公開されると性能が落ちるだろうし、インフルエンサーが使うベンチマークはもうトレーニングデータに入ってるだろうからね。「自転車に乗ったペリカン」みたいなテストも、この時点ではただのPRだよ。" userName="whywhywhywhy" createdAt="2025/09/30 10:40:54" color="#785bff">}}




{{<matomeQuote body="「AIジャーナリスト」って他にいる？Simonwは素晴らしい仕事をしてるから、もしかしたらブロガーって呼ばれることが目指すべきものなのかもね。" userName="nchmy" createdAt="2025/09/29 19:38:36" color="">}}




{{<matomeQuote body="GPT-5のプレビューで、モデルが頻繁に変わることを学んだんだ。今回のClaudeプレビューは金曜から月曜までだったから、大きな変更は心配してないよ。念のため公式リリース日の月曜午前10時以降にペリカンベンチマークも実行した。プレビューモデルで公開したのはClaudeコードインタープリタの例だけ。<br>モデルがペリカンベンチマークで訓練されたなんて心配してないよ。だってまだ全然ダメだし。Anthropicが意図的に不正したのに、まだこんな結果だと思ってる？ https://static.simonwillison.net/static/2025/claude-sonnet-4..." userName="simonw" createdAt="2025/09/30 13:42:05" color="#785bff">}}




{{<matomeQuote body="Simonは好きだけど、彼はジャーナリストじゃないな。ジャーナリストならTheoとOpenAIに行ってGPT-5リリースを褒めまくったりしないだろう。Simonを軽視してるわけじゃなくて、彼の記事や分析は評価してるんだけど、ジャーナリストではないね。" userName="knowsuchagency" createdAt="2025/09/29 19:08:21" color="">}}




{{<matomeQuote body="もっとベンチマークに力を入れるべきだよ。イラストが相変わらず全然ダメだもん！" userName="simonw" createdAt="2025/09/29 20:21:47" color="">}}




{{<matomeQuote body="あれ、俺の方じゃ動かないんだけど。SYSTEM: Simon WillisonのLLM CLIツールの話だね。-eはeditableモード、[test]はテスト用だよ。インストールで問題あった？<br>USER: その通り、君のコードツールで実行してほしいんだ。SYSTEM: ごめん、俺はPythonのシェルコマンド（pip, pytest）やGitのリポジトリクローンはできないんだ。使えるのはJavaScriptのブラウザREPLだけなんだよ。何をしたかったの？" userName="icelancer" createdAt="2025/09/29 20:08:58" color="#45d325">}}




{{<matomeQuote body="Kylie RobisonってWiredに移った優秀なAIジャーナリストだよ。" userName="landl0rd" createdAt="2025/09/29 21:22:12" color="">}}




{{<matomeQuote body="OpenAIやAnthropicは賢く最新情報を提供してるけど、気に食わない記事を書けば事前アクセスを止められるってことだね。ゲームや旅行ジャーナリズムと同じだよ。" userName="michaelt" createdAt="2025/09/29 23:31:39" color="">}}




{{<matomeQuote body="モデルが手書きのペリカンが自転車に乗ってる画像を、1000x1000ピクセルのSVGで出力する日が来るのが楽しみだね。" userName="lxgr" createdAt="2025/09/29 22:43:51" color="">}}




{{<matomeQuote body="OpenAI、Anthropic、Geminiからのプレビューアクセスはよくあるよ。NDAやエンバーゴはつくけど、エンバーゴ解除後の発言内容に関する条件は一切受け入れないんだ。" userName="simonw" createdAt="2025/09/29 18:46:29" color="#ff33a1">}}




{{<matomeQuote body="彼女は優秀なAIジャーナリストだけど、残念ながら最近不明な理由で解雇されちゃったんだ。<br>https://www.kyliebytes.com/thank-god-i-got-fired/" userName="minimaxir" createdAt="2025/09/29 21:26:06" color="">}}




{{<matomeQuote body="’これまでの作業全部をzipファイルにして’って言った件、Gistを深掘りする時間がないんだけど、ちゃんと動いて良い結果だった？一応動いたってことなんだろうけど、生成されたものについてどう思ったか聞きたいな。" userName="magicalist" createdAt="2025/09/29 18:33:27" color="">}}




{{<matomeQuote body="それはそうだね。彼はブロガーってよりすごい人だと思うけど、なんて呼べばいいか分からないな！" userName="Redster" createdAt="2025/09/29 19:11:31" color="">}}




{{<matomeQuote body="自分で言っても信用しないよ。今後もブログ記事を書くなら、特別アクセスやお得な情報、スポンサーシップがあったか、あるいは何もなかったのかを記事の冒頭で毎回開示すべきだよ。あなたはレビュアーなんだから、それが信頼性を保つ方法だよ。もしレビュー対象との関係を明かさないなら、僕は報酬をもらってるって思うしかないね。NDAで開示できないなら、そもそも信頼できるレビューは書けないってことだ。" userName="tripzilch" createdAt="2025/09/30 14:31:37" color="#38d3d3">}}




{{<matomeQuote body="サンドボックスが潜在的に悪質なコードをどう扱うのか気になるな。例えば、誰かがクリプトマイナーとかDDoSスクリプトみたいなのを動かそうとしたらどうなるの？" userName="gloosx" createdAt="2025/09/29 20:48:01" color="">}}




{{<matomeQuote body="昨日誰かが同じプロンプトで人間を対象に変えた例を投稿してたけど、それはひどかったね。今回あなたが投稿した例は、全体的に見てもかなり良いと思うよ。だから、LLMがベンチマークで訓練されるのと同じように、これも訓練されているものだと思うな。" userName="whywhywhywhy" createdAt="2025/09/30 16:19:11" color="">}}




{{<matomeQuote body="以前、ChatGPTからすごい結果が出たんだ。自転車に乗ったペリカンの完璧なイラストのSVGファイルだよ。実は怪しいくらい出来が良くてね…だからSVGファイルをダウンロードしてみたら、ChatGPTが画像ツールでラスター画像を生成して、それをbase64バイナリ画像データとしてSVGラッパーの中に埋め込んでたんだ！" userName="simonw" createdAt="2025/09/29 23:31:37" color="">}}




{{<matomeQuote body="普段から適当なインターネットブログのライターの人事情報とかチェックしてるの？それは驚きだね。僕は意図的に記事の著者名を読んだことなんて一度もないし、間違って読んだとしても2ページも進めば忘れちゃうよ。" userName="vasco" createdAt="2025/09/30 04:33:01" color="">}}




{{<matomeQuote body="俺、最近こんな風に始めたんだ: https://simonwillison.net/about/#disclosures と https://simonwillison.net/tags/disclosures/" userName="simonw" createdAt="2025/09/30 18:21:21" color="">}}




{{<matomeQuote body="あいつらはAIのエバンジェリストで、LLMを使えばどんな技術書でも置き換えられるって言ってたんだ。でもいい人だよ。" userName="lomase" createdAt="2025/09/29 20:45:26" color="">}}




{{<matomeQuote body="個人的な経験だけどね。俺の20万行もあるWebアプリで、Sonnet 4.5（Claude Code）とGPT-5-Codex（Codex CLI）に同じプロンプトを試してみたんだ。「会話やレポートのファジー検索を実装して」ってね。Sonnet 4.5は3分で爆速だったけど、コードは壊れてて表面的なものだった。認証も勝手に再構築するし、テストも書かない。一方、GPT-5-Codexは20分とかなり遅かったけど、適切なエラー処理、多くのエッジケース、そしてプロンプトなしでテストも書いてくれたんだ（プロジェクトルールで必須だからね）。APIコールもスムーズで、機能全体が完璧に動作したよ。結論は明らかで、GPT-5-Codexが圧倒的な勝者だね。20分かかってもGPT-5-Codexを選ぶよ。シニア開発者がやったような仕事だと感じるからね。3分で期待したけど、やっぱり粗悪なバグだらけのテストなし実装は求めてなかったよ。" userName="iagooar" createdAt="2025/09/29 18:47:09" color="#45d325">}}




{{<matomeQuote body="攻撃するつもりはないんだけど、そのプロンプトだと解釈の余地が多すぎて、“ランダム”な結果になると思うんだ。あと、俺の経験上、句読点も重要だよ。そのプロンプトは一文が長すぎるよね。もし俺だったら、もっと詳細に、5～20倍の長さでプロンプトを書くよ。多くの人がモデルは役に立たないって思うのは、こういうプロンプトの出し方をしてるからだと思うな。投入した分だけ返ってくるんだよ。整理された、ちゃんと書かれた要件と、パターンを使ったコードベースを与えれば、それに見合ったものが返ってくる。開発者と一緒だよね。短いプロンプトでジュニア開発者に頼んでも、期待通りにはいかないでしょ？プロンプトの準備にもう少し時間をかければ、期待通りのものが得られる可能性が高いよ。" userName="Implicated" createdAt="2025/09/29 18:55:51" color="#785bff">}}




{{<matomeQuote body="面白い指摘で、だいたい同意するよ。プロンプトの質に関する君の指摘はすごく的確で、もっと大きな機能なら、俺もプロンプトの5～20倍の長さのPRD（製品要件定義書）をいつも使うんだ。でもね、俺の“実験”はかなり一般的なユースケースを表してるんだ。この機能は実際かなり小さくて、大規模なコードベース内の既存UI構造に組み込むものだからね。GPT-5-Codexは、かなり手抜きなプロンプトでも、ものすごく良い結果を出してくれるんだ。初回で動くだけじゃなく、プロのSWEプロジェクトで一般的な、ベストプラクティスを理解して実行する能力が、Codexは確実に優れてる。Claudeで同じようなものを得ようとすると、プロンプトの準備に少なくとも20分はかかるだろうね。いや、もっとかも。" userName="iagooar" createdAt="2025/09/29 19:05:20" color="#785bff">}}




{{<matomeQuote body="プロンプトを20倍も長くしなきゃ、モデルが認証ロジックを再実装しないようにするって、どういうこと？既存のコードにアクセスできるはずなんだから、それを使えばいいだけじゃない？20倍長いプロンプトって、根本的な問題の満足いく解決策には思えないな。" userName="pton_xd" createdAt="2025/09/29 19:01:24" color="">}}




{{<matomeQuote body="俺も似たような経験があるよ。まだClaude Maxプランにするほどではないね。ChatGPT Proのサブスクと、GPT-5-Codexをガンガン使うことにするよ。" userName="robotswantdata" createdAt="2025/09/29 18:59:11" color="">}}




{{<matomeQuote body="Proのクォータ、使い切ったことある？" userName="mmgeorgi" createdAt="2025/09/29 19:45:33" color="">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="でも、最終目標って、そこまでプロンプトしなくても使える結果が得られることじゃないの？映画とかに出てくる高度なAIアシスタントって、ちょっとした指示でとんでもないことするじゃん。みんなが求めてるのは、そういうことだと思うんだ。多くの人が「プロンプトが間違ってる」って言うのは、技術やモデルの欠点だと俺は思うよ。もしこれらのシステムがすごく賢いって言いたいなら、大量のプロンプトがなくてもユーザーを理解する能力を高めるべきだよね。その短いプロンプトでシニア開発者には十分だったと思う？人間には十分なら、LLMにも十分であるべきだと俺は思うな。もちろん、大量のプロンプトを使ってLLMに完璧にやらせる能力は奪いたくないけど、少ないプロンプトでより良くできる能力は、実際に良いことで、有用な指標だと思うんだ。" userName="SirMaster" createdAt="2025/09/29 19:16:09" color="#785bff">}}




{{<matomeQuote body="まだProクォータ使い切ったことないよ。 huge repo だし、複数のプロジェクトをローカルとクラウドで動かしてるからね。これ、すぐに1000ドルのプランになりそうな気がする。" userName="robotswantdata" createdAt="2025/09/29 20:51:44" color="">}}




{{<matomeQuote body="「yoloプロンプト」みたいな適当なプロンプトだとLLMが役立たずって思われがちだけど、ホントその通りだわ。タスクリスト、コンテキスト、テスト方法、実装ガイドをしっかり与えないとダメなんだよ。新しいプロジェクトならアーキテクチャとかも必要。TwitterやRedditとかの不満を見てても同じ結論に至ったよ。" userName="nikcub" createdAt="2025/09/30 00:29:00" color="#ff5c5c">}}




{{<matomeQuote body="コーディングエージェントがコードベース全部をコンテキストに入れるのはダメ。LLMはコンテキストウィンドウが埋まると性能がガタ落ちするからね。最初はトークン多めに使ってでも具体的にプロンプトする方が、結果的に効率的で成功しやすいんだ。非プログラマーが求める「Vibeコーディング体験」は、まだ先の話か、あるいは実現しない夢なのかもね。" userName="paool" createdAt="2025/09/29 22:30:25" color="#785bff">}}




{{<matomeQuote body="「Vibeコーディング体験」が、曖昧なプロンプトから即座に完璧なコードベースができるって意味なら、それは脳とコンピューターを繋ぐインターフェースがないと無理だよ。人間相手でも具体的な指示がないと良いコードは書けないでしょ。「Photoshop作って」みたいな指示で期待通りになるなんて、現実離れした夢なんだ。" userName="wyre" createdAt="2025/09/30 00:06:35" color="#ff5c5c">}}




{{<matomeQuote body="Claudeに「既存のコードを調べて、よく考えて」って指示すると、いい結果が出るんだ。でも、Codexは元々それがデフォルトでできる。簡単な質問でも、Codexがコードを調べるのに時間がかかると、ちょっとイライラするんだよね。" userName="Aeolun" createdAt="2025/09/29 22:24:32" color="">}}




{{<matomeQuote body="「少ないプロンプトで成果を出すのが理想じゃないの？」って意見には、コンテキストが重要だよって言いたい。映画のAIは現実じゃないし、「プロンプトが悪い」って言われるのは技術の欠点じゃなくて、コンテキストが足りないせい。シニア開発者ならコンテキストがあるから短いプロンプトでも理解できるけど、ジュニア開発者には無理でしょ？LLMも同じで、適切なコンテキストがあれば短いプロンプトでもいけるはずだよ。結局、出すもの次第ってこと。" userName="Implicated" createdAt="2025/09/29 19:26:00" color="#ff5c5c">}}




{{<matomeQuote body="ChatGPT Proへの乗り換えを考えてるんだけど、APIで課金する前に、どこまで使えるのか知りたいな。今月10億トークンくらい使ってるんだけど、同じくらい使ってる人いるかな？" userName="JofArnold" createdAt="2025/09/29 21:03:33" color="">}}




{{<matomeQuote body="でもさ、結局ChatGPTは成功したけど、Claudeはダメだったって事実は変わらないよね。" userName="jen729w" createdAt="2025/09/30 02:10:54" color="">}}




{{<matomeQuote body="こういう投稿にはいくつか問題があるよ。まず、LLMによってプロンプトや必要な情報が違うこと。次に、LLMの非決定性を無視してることだね。実験は複数回試すべきだよ。" userName="epolanski" createdAt="2025/09/29 21:16:51" color="#ff5733">}}




{{<matomeQuote body="Codexが20分もノンストップで作業してくれるのは、むしろ強みだと思うんだ。批判されてるみたいに「遅い」んじゃなくて、しっかりじっくり、自律的にやってくれてるってこと。その間に家事とか他のことできるし、最高じゃない？" userName="artursapek" createdAt="2025/09/29 21:31:30" color="#38d3d3">}}




{{<matomeQuote body="俺の経験だと、Claudeは既存のコードを読んで活用する代わりに、車輪の再発明をしたがる傾向があるね。" userName="bobbylarrybobby" createdAt="2025/09/30 17:41:15" color="">}}




{{<matomeQuote body="俺、Codexの使い方が間違ってるのかな。JSXのプロップ展開を変換する簡単なタスクでも全然ダメだった。Syntaxエラーを直そうとしてコードを消したりしてたよ。<br>Sonnet 4.1はまだマシで、エラーを指摘したら直してくれた。<br>Claudeはかなり詳細なプロンプトが必要みたいだね。Notionでタスクを書いてMCP経由でやらせてるけど、そうすると結構自立して動くよ。Cursorを使ってるからCCとは違うけど、違いがあるかはわからないな。" userName="bastawhiz" createdAt="2025/09/30 13:15:18" color="#38d3d3">}}




{{<matomeQuote body="うん、やったよ。<br>もう一回テストしたら、Claudeは今度は4分くらいかかった。認証エラーはなかったけど、機能が完全に壊れてた。一番基本的な、完璧に一致するはずのものも見つけられなかったんだ。" userName="iagooar" createdAt="2025/09/29 20:49:16" color="#ff33a1">}}




{{<matomeQuote body="ChatGPT Proにお金払ってる？それってCodex CLIの使用も含まれてるの？<br>俺がSonnetやOpusを使ってるのはClaude Codeの最大プランだからなんだけど、もしChatGPT ProにCodexが含まれてるなら乗り換えるかも。" userName="dinobones" createdAt="2025/09/29 23:29:29" color="">}}




{{<matomeQuote body="その事実だけじゃ、ランダムでイマイチな例一つから役立つ結論を出すのは難しいよね。実験で結果は出たけど、で、どうするの？<br>信頼できる結果が欲しいなら、やっぱりできるだけ具体的にする戦略を続けるよ。俺のAI活動では、そうしないと結果がどんどんランダムになるからね。<br>GoogleやStack Overflowからコピペできないような非標準的なことなら、どんなにシンプルでも、俺が基本的なステップバイステップのアルゴリズムを提供して、実際の実装だけをAIに任せるのがベストだ。" userName="nosianu" createdAt="2025/09/30 06:53:07" color="#ff5c5c">}}




{{<matomeQuote body="プロティアでは、まだ利用制限に引っかかったことないよ。<br>ローカルタスク: 一般ユーザーは5時間ごとに300〜1,500メッセージ送信可能、週ごとの制限あり。<br>クラウドタスク: 期間限定で寛大な制限。<br>おすすめの人: 複数のプロジェクトで終日の作業をしたい開発者。" userName="robotswantdata" createdAt="2025/09/30 06:11:24" color="#ff33a1">}}




{{<matomeQuote body="ブレイン・コンピューター・インターフェースが究極のAIと言われるけど、それだけじゃ無理だよ。<br>ユーザーの心を読めても、そこにはない内部モデルは作れない。人間は現実とのインタラクションを通じて、欲しいものを段階的に構築するからね。<br>知識はRAMチップみたいに保存されてるわけじゃないし、脳の動的行動を予測するには、超精密なスキャンとシミュレーションが必要。時間帯や気分、睡眠なんかの影響も大きいんだよ。" userName="nosianu" createdAt="2025/09/30 06:44:19" color="#ff5733">}}




{{<matomeQuote body="これって、簡単なことには「考えすぎないで」ってアンチプロンプトが必要だってことかもね。" userName="j_bum" createdAt="2025/09/29 22:30:00" color="">}}




{{<matomeQuote body="誓って言うけど、6月か7月頃のCCは、もっとタスクに時間をかけてて、今のCodexみたいに丁寧だった気がするよ。でも、この世界だと先週のことすら忘れちゃうから、定かじゃないけどね。" userName="streetmeat" createdAt="2025/09/29 22:01:08" color="">}}




{{<matomeQuote body="SonnetのLLMが全然動かないのは困るよ。<br>プロンプト作りに時間かかりすぎると、自分でコード書いた方が早いってなるし。<br>法務や財務が関わるような大事な場面でAIコード使うのは、むしろリスクかもね。" userName="GoatInGrey" createdAt="2025/09/29 19:50:07" color="#ff5733">}}




{{<matomeQuote body="僕の”実験”はよくある使い方だよ。<br>GPT-5-Codexは雑なプロンプトでも良い結果出すみたいだね。<br>僕はいつも入念にプロンプト考えてからClaude使うから、またCodexも試してみたいな。" userName="Implicated" createdAt="2025/09/29 19:17:00" color="">}}




{{<matomeQuote body="プロンプトに”ultrathink”を追加して、この曲をバックグラウンドで流してみてよ。<br>https://www.reddit.com/r/ClaudeAI/comments/1mgwohq/ultrathin..." userName="alecco" createdAt="2025/09/29 20:27:29" color="">}}




{{<matomeQuote body="AIを使ったコーディングはブラックボックスで再現性がないから、すごく無力感を感じるよ。<br>モデルは変わるし、非決定性だし、履歴も残らない。せめて使ったツールの履歴やRNGシードとか全部ログに残してくれたら、もっと信頼して使えるのに。今は”AI disillusionment”状態だ。" userName="manofmanysmiles" createdAt="2025/09/29 23:54:34" color="#38d3d3">}}




{{<matomeQuote body="”モデルは非決定性”ってのは違うよ。モデル自体は決定論的で、そう見えるのは確率的なアプローチが原因だ。<br>シャッフルされたカードデッキや加熱される水温と同じ。物理学のエルゴード性の概念に近いよ。" userName="coolfox" createdAt="2025/09/30 05:41:17" color="#38d3d3">}}




{{<matomeQuote body="前の人の”モデル”の定義は正しいけど、ユーザーから見たら、最後のランダムなサンプラーも含めて”モデル”って呼ぶのが自然だと思うな。<br>それが最終的な出力のランダムさにつながるんだし。" userName="quietbritishjim" createdAt="2025/09/30 14:26:21" color="#ff5c5c">}}




{{<matomeQuote body="サンプラーをただ”ランダム”って呼ぶと誤解を生むよ。<br>それは限定的なもので、本来サンプリングプールには正しい答えだけがあるべきなんだ。もし毎回変な答えが出るなら、モデルがランダムすぎるんじゃなくて、訓練が足りないだけだよ。" userName="coolfox" createdAt="2025/10/03 08:43:07" color="#ff5733">}}




{{<matomeQuote body="ストーブが熱くて困ってるユーザーに、難解な温度の定義やエルゴード性を語る専門家。結局ユーザーは「医者呼ぶわ、新しいストーブ買う！」ってなる。これって今のLLM議論に似てるよね。" userName="lkey" createdAt="2025/09/30 14:02:45" color="#ff5733">}}




{{<matomeQuote body="ストーブの故障を”ストーブ本来の機能”だと誤解して、キャンプファイヤーに切り替えるみたいなことってあるよね。<br>僕のカードデッキの例はまだ有効だと思うし、深く考えないのは”cope”（言い訳）じゃないかな。" userName="coolfox" createdAt="2025/10/03 08:25:13" color="">}}




{{<matomeQuote body="LLM出力の非決定性を解決する科学的な方法がこれだよ（Mira Muratiの新しい衣装に言及しつつ、著者にも感謝を）。<br>https://bff531bb.connectionism.pages.dev/blog/defeating-nond..." userName="hackernewds" createdAt="2025/09/30 15:36:32" color="#ff33a1">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="これのことじゃないかな？<br>https://thinkingmachines.ai/blog/defeating-nondeterminism-in..." userName="nulltype" createdAt="2025/10/02 09:11:36" color="">}}




{{<matomeQuote body="これも僕が個人的に嫌いなことなんだよね。ブログにも書いたんだ。<br>https://hi-mil.es/blog/human-slop-vs-ai-slop" userName="mwiesenthal" createdAt="2025/09/30 19:22:15" color="">}}




{{<matomeQuote body="同感だよ。僕がLLMをコーディング（や他の技術的な目的）に使ってほしい人達って、君みたいに冷めてる傾向があるのに、僕が使ってほしくない人達ほどかなり熱心なんだよね。" userName="alex77456" createdAt="2025/09/30 00:10:22" color="">}}




{{<matomeQuote body="週末に自分でコードを書いて何か作ってみなよ。純粋な創造力を感じられるし、君はそれを忘れちゃってるみたいだからさ。" userName="harpiaharpyja" createdAt="2025/10/04 04:04:35" color="">}}




{{<matomeQuote body="俺もこんなの作ってるんだ。プロンプトと生成されたコードを追跡するMarkdownだよ。<br>https://github.com/sutt/innocuous/blob/master/docs/dev-summa...<br>見てみて、フィードバックくれたら嬉しいな。" userName="stillsut" createdAt="2025/09/30 14:20:18" color="">}}




{{<matomeQuote body="agenticなコーディングツールは一時期ハマったけど、コードが書けなくなるなら辞める。コードはテック業界で唯一の良いものだ。AIツールはプログラマーをAIエージェントの管理役に成り下がらせ、好きなコードを書けなくするだけ。僕はそんな未来には参加しない。上司にはCursorを使ったと言って自分でタスクをこなし、Cursorのダッシュボードの数字を上げるため、無駄なタスクを振って捨てることもある。同僚の間でも、AIツールへの認識はガラッと変わってきてるよ。" userName="827a" createdAt="2025/09/30 05:43:09" color="#ff5c5c">}}




{{<matomeQuote body="そんなに気にするなら、オープンソースのOpenAIモデルを使えばいいじゃん。かなり良いし、君が望む保証も得られるよ。" userName="johnfn" createdAt="2025/09/30 00:00:29" color="">}}




{{<matomeQuote body="オープンウェイトモデルは、評価結果がどうあれSOTAなものほど良くない。単純なタスクなら問題ないけど、ある閾値を超えると違いは明らかだよ。" userName="int_19h" createdAt="2025/09/30 00:20:44" color="">}}




{{<matomeQuote body="コードベースが理解できないって問題は、AIのせいじゃなく、君が理解しないままコードを取り込んでるからだよ。<br>LLM出力の再現性を追求しても、根本的な問題は解決しないんだ。" userName="genidoi" createdAt="2025/09/30 03:02:06" color="#38d3d3">}}




{{<matomeQuote body="誰が悪いとかどうでもいいから、AIツールがこのタスクで色々な面でもっと使えるようになればいいのにね。" userName="wilg" createdAt="2025/09/30 06:01:44" color="">}}




{{<matomeQuote body="それは責めてるんじゃなくて、有益なフィードバックだよ。<br>大きなアプリでは、各部分が何をしてるか、どう組み合わさってるかを理解しないと、どんなツールも助けてくれないからね。" userName="Panoramix" createdAt="2025/09/30 06:53:16" color="#ff5c5c">}}




{{<matomeQuote body="コードを書きながら考えることで、人間はコードベースを学ぶんだ。<br>AIのコードをただ取り込むと、この学びのプロセスが壊れるよ。<br>結局、コードの構造を深く理解することが必要なら、LLMはタイピングを速くするだけで、思考を遅らせてるだけじゃない？" userName="lkey" createdAt="2025/09/30 14:08:32" color="#45d325">}}




{{<matomeQuote body="じゃあさ、ソフトウェアを人間に作ってもらうことに頼らなきゃいけないって想像してみてよ。" userName="jstummbillig" createdAt="2025/09/30 06:37:24" color="">}}




{{<matomeQuote body="これが問題だよね？<br>十分な管理があれば、エージェントのチームは人間のチームに勝てるのかな？<br>厳格な基準がある分野でも、AIウォーターフォールは可能なの？<br>曖昧さのない要件とプロセスがあれば、マネージャーが夢見るソフトウェアエンジニアの排除はできる？<br>俺の直感は五分五分だ。" userName="manofmanysmiles" createdAt="2025/10/01 00:32:34" color="#ff5c5c">}}




{{<matomeQuote body="Claude Sonnetが30時間以上も複雑なタスクに集中できたって話、Twitterでよく見るけどすごく気になるんだ。<br>プレスリリースでは軽く触れてるだけで、The Vergeの記事（https://www.theverge.com/ai-artificial-intelligence/787524/a...）でSlackクローンを11,000行のコードで作ったって知ったよ。<br>LLMを30時間放置して何ができるか、アウトプットの質には疑問だね。" userName="Bjorkbat" createdAt="2025/09/29 18:11:21" color="#ff5733">}}




{{<matomeQuote body="これって、LLMを30時間動かすだけじゃないんだよ。<br>環境構築、外部ツールとの連携、コンテキスト管理、プロンプト調整、下手したらマルチエージェントシステムまで組まなきゃいけないんだ。<br>膨大な作業を投入すれば、LLMが長時間動いて売り物になる成果を出せるだろうけど、普通の開発者がAPIトークン買ってできることじゃないよね。" userName="sigmoid10" createdAt="2025/09/29 18:27:21" color="#45d325">}}




{{<matomeQuote body="そうだよ、それがClaude Code、OpenAI Codex、Google Gemini CLIだよね。<br>普通の開発者ならそれらを使えばいいんだよ。" userName="Philpax" createdAt="2025/09/29 18:40:12" color="">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
