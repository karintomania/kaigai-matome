+++
date = '2025-03-05T00:00:00'
months = '2025/03'
draft = false
title = 'リチャード・サットンとアンドリュー・バートが2024年チューリング賞を受賞！AI界の巨星たちの偉業に注目'
tags = ["AI", "機械学習", "ノーベル賞", "研究", "おすすめ本"]
featureimage = 'thumbnails/green1.jpg'
+++

> リチャード・サットンとアンドリュー・バートが2024年チューリング賞を受賞！AI界の巨星たちの偉業に注目

引用元：[https://news.ycombinator.com/item?id=43264847](https://news.ycombinator.com/item?id=43264847)

{{<matomeQuote body="すごいね！実は俺と嫁さんがAndy Bartoとその奥さんの家を買ったんだ。入札戦争があって、彼らが『プライムオファーを出して』と言ったから、彼が数学者だと知ってたからプライムナンバーのオファーを出したんだ。彼が認められて嬉しいよ。" userName="zackkatz" createdAt="2025-03-05T12:28:09" color="#45d325">}}

{{<matomeQuote body="ハハ、それは素晴らしいね。『公平にするために、$2にしようか？』なんて冗談言えばよかったね。" userName="dustfinger" createdAt="2025-03-05T22:17:49" color="">}}

{{<matomeQuote body="プライムナンバーのオファー、まさか$12345678910987654321！？" userName="grumpopotamus" createdAt="2025-03-06T00:15:35" color="">}}

{{<matomeQuote body="いいね！彼らがRLの教科書の両エディションを無料PDFで公開してるのは素晴らしい。1982年からAIの実務者だけど、RLは俺にとってずっと難しい分野で、Sutton/Bartoの本やCourseraのシリーズがかなり助けになった。お勧めだよ！" userName="mark_l_watson" createdAt="2025-03-05T12:06:03" color="#ff5733">}}

{{<matomeQuote body="『The Bitter Lesson』を再読するのに良いタイミングだね。" userName="ofirpress" createdAt="2025-03-05T10:23:41" color="">}}

{{<matomeQuote body="Canonical URL: <http://www.incompleteideas.net/IncIdeas/BitterLesson.html>" userName="cxr" createdAt="2025-03-05T10:50:35" color="">}}

{{<matomeQuote body="確かに厳しい教訓だよ。かつては人間の知識をコンピュータに詰め込むのが好きだったけど、今は全てが大きなブラックボックスになって理解が難しい。Mooreの法則も自己実現的な予言になりつつある。AIは計算パワーを必要とし、チップメーカーは特化型ハードウェアを作り始めてる、まさにそれが回転する車輪になってる。" userName="khaledh" createdAt="2025-03-05T10:30:56" color="#ff5c5c">}}

{{<matomeQuote body="AIが最終的に堅牢で証明可能な論理で構築され、監査できるAIを作れるようになればいいなと思ってる。その時が来るまでリスクのあることには信用できない。残念ながら、そんな選択肢はなくて、不気味に短い時間でブラックボックスが間違った決定を下すことになる。" userName="anonzzzies" createdAt="2025-03-05T10:48:40" color="#ff5c5c">}}

{{<matomeQuote body="AI支援の定理証明器はその方向に進んでるかもね。どう証明に至ったかは分からなくても、その証明を詳細に検証できるから。" userName="tromp" createdAt="2025-03-05T11:32:33" color="">}}

{{<matomeQuote body="そう、会社で形式的証明をしてるチームを持っていて、AIがどうしたかは関係ない。数学的に正しいと言えることが重要なんだ。プログラム合成や証明もしてるけど、これは大規模なこととは遠い。" userName="anonzzzies" createdAt="2025-03-05T13:25:21" color="#785bff">}}

{{<matomeQuote body="どんな会社が形式的検証が必要なんだ？リアルタイムシステムとか？" userName="InkCanon" createdAt="2025-03-05T14:19:12" color="">}}

{{<matomeQuote body="デジタル回路設計の会社がよく使っているよ。VHDLやVerilogでモジュールを書いて、 regressionsを通過してみんなが安心しても、コードがぐちゃぐちゃなのは分かる。そんなときは形式的検証を使えば、2つのコードが機能的に同じか証明できるんだ。形式的検証は通常、数分で終わるから、時間が大幅に節約できるよ。ただし、複雑すぎる論理の場合、制約があることが多いし、逆にバグが見つかることもある。" userName="tasty_freeze" createdAt="2025-03-05T23:12:52" color="#45d325">}}

{{<matomeQuote body="リアルタイムや組込みシステムでの金銭処理や医療、航空/輸送などにも必要だ。でも『必要』って言葉は引っかかる。今はブロックチェーン業界が形式的検証を進めてるけど、重要なシステムはテストがほとんどないことが多いからね。俺が一番心配しているのは、あいまいなシステムがそのまま使われることだ。急いでいるのは分かるけど、ひどいアイデアだよ。" userName="anonzzzies" createdAt="2025-03-05T14:26:55" color="">}}

{{<matomeQuote body="AIが最終的に robustness があり証明可能な論理で構築された AI を作れるかも。これが Max Tegmark と Steven Omohundro の 'Provably Safe AGI' のアプローチだ：<a href=”https://arxiv.org/abs/2309.01933”>https://arxiv.org/abs/2309.01933</a> <a href=”https://www.youtube.com/watch?v=YhMwkk6uOK8”>https://www.youtube.com/watch?v=YhMwkk6uOK8</a>。でも、問題はある。人間の幸福みたいな概念をどうやって形式化するんだろう？" userName="optimalsolver" createdAt="2025-03-05T12:37:27" color="#ff5733">}}

{{<matomeQuote body="＞しかし、問題はある。人間の幸福みたいな概念をどうやって形式化するんだろう？<br>確かにそうだね！でも、AIなら宇宙飛行や構造物の建設、税金や会計、物理、数学などには論理的に正しい脳を作れるかも。でも、他のことには感情を持った脳を作って、両者が協力するというのもありかもしれない。リンクありがとう！" userName="anonzzzies" createdAt="2025-03-05T13:21:06" color="">}}

{{<matomeQuote body="ロジックの正しさは人間の脳の限界にも依存してる。形式論理は普通の前提をもとに構築されてるからね。形式論理システムを作るために、いくつかの証明できない前提から始めなきゃならない。ただ、AIがそれにどうやって役立つかがまったく分からない。" userName="necovek" createdAt="2025-03-05T18:11:37" color="">}}

{{<matomeQuote body="Quis custodiet ipsos custodes？<br>このラテン語のフレーズは、ローマの詩人 Juvenalの詩で見つかるもので、『誰が守るのか、守る者を？』という意味。元々は結婚の忠実さを確保する問題に関するもので、権力を持つ人々の行動を制御する問題を指している。" userName="fuzztester" createdAt="2025-03-05T21:18:28" color="">}}

{{<matomeQuote body="ちょっとふざけた感じで言うと、守る者たちの監視役は誰か？" userName="gsf_emergency_2" createdAt="2025-03-05T22:49:05" color="">}}

{{<matomeQuote body="『監視する』ってのは、子供扱いすることになる。権力を持つ人を子供のように扱うことだ。申し訳なく思う必要はないけど、ちょっと面白いかも。ちょっと楽しめるラテン語。" userName="gsf_emergency_2" createdAt="2025-03-09T09:06:06" color="">}}

{{<matomeQuote body="コンパイラ最適化の例を考えてみて。AIに正しい出力を出すための変換だけを使わせれば、AIの動きが変でも正しい結果が得られるんだ。でも、このアプローチだと望むような最適化ができないこともあるよね。人間が作る最適化アルゴリズムでも似たようなこと起きてるし。" userName="amelius" createdAt="2025-03-05T12:13:49" color="">}}

{{< details summary="もっとコメントを表示（1）">}}
{{<matomeQuote body="AI研究の目的による部分もあるよね。もし人間にしかできないタスクを得意な機械を作ることが目標なら、その過程での教訓は大事だね。でも、機械にXを教えることで人間のXのやり方を理解することが目的なら、複雑な統計的手法はあまり意味がないかも。だからもう少しさまざまな観点から考える必要があるんじゃないかな。" userName="kleiba" createdAt="2025-03-05T11:04:39" color="#45d325">}}

{{<matomeQuote body="少なくとも、一貫した言語や視覚の能力は「経験が必要ない」って分かっているだけでも大きな進展だよ。それは予想外だったけどね。" userName="visarga" createdAt="2025-03-05T16:29:50" color="">}}

{{<matomeQuote body="一貫した言語や視覚の能力が経験なしでできるなんて言っているけど、それは違うと思うな。最近の進展は、実際に「私たちのLLMがXに答えられなかった時、君はどう答える？」と人に聞いている時間が増えたからこそだし。だから、代理的な経験があるのは確かだよ。" userName="probably_wrong" createdAt="2025-03-05T22:19:27" color="">}}

{{<matomeQuote body="でも、LLMの幻覚現象を考えると、それが真実なのか疑問だよね。" userName="kleiba" createdAt="2025-03-05T19:47:38" color="">}}

{{<matomeQuote body="コンピュータービジョンでも似たようなことがあったよね。初期はエッジを探したり、一般化された円柱を使っていたけど、今はそれらは全部廃棄されて、モダンなディープラーニングは畳み込みや特定の不変性だけを使ってる。その結果、かなり性能が上がった。あのパターンマッチングが消え始めたところにいたけど、あの時の学びは今でも役に立つ部分があるよ。" userName="jdright" createdAt="2025-03-05T19:08:58" color="#45d325">}}

{{<matomeQuote body="2010年代初頭にコンピュータービジョンのラボでインターンしてたんだけど、ある会議で抽象的な機械学習を使った視覚の研究を発表したら、教授があまりにも驚いていたのを覚えてる。あのアプローチが実現可能だなんて信じられなかったみたい。ただ、その経験から新しいアプローチに反対しないと決めたのが一番の教訓だった。" userName="abdullahkhalids" createdAt="2025-03-05T19:55:37" color="#45d325">}}

{{<matomeQuote body="人が新しいアプローチに抵抗するのは、意外と難しいことだと思うよ。それには理由があって、（ア）古いアプローチの専門家になったり、（イ）かなりお金がもらえてたりするからなんだ。だから、新しいアプローチが生活に大きな影響を及ぼすと、自分がそれに反発する可能性が高いんだよね。自分が今最も恩恵を受けている技術を考えてみな。もし明日それをわずかに向上させた技術が出たとして、利点が得られなくなったらどう思う？" userName="kenjackson" createdAt="2025-03-05T21:01:07" color="#785bff">}}

{{<matomeQuote body="確かに難しいね。君が言ったような理由で。これは生涯のスキルみたいなもので、常に磨かないといけないし、遅れを取ると取り返すのがすごく難しい。そして、そういったスキルは自分自身がレジリエントな人間でいるために必要なんだよ。" userName="abdullahkhalids" createdAt="2025-03-05T23:08:49" color="">}}

{{<matomeQuote body="君が言うように、機械学習が未来だって分かってたのは明らかだったかもしれないけど、この人はただ頑固だったわけではないと思うんだ。2010年代初頭にはそれが当然だと思えた人は少なかったし、疑念はあったと思う。結果が出ているのにそれを無視するのはダメだけど、機械学習のビジョンの結果がCVPRなどの会議で本当に支配的になったのはその後のことなんだよ。探求と活用のトレードオフがあるからね。" userName="nightski" createdAt="2025-03-08T15:42:42" color="#45d325">}}

{{<matomeQuote body="ああ、古いNLPの人たちが学んだ苦い教訓だよね。その論文は今でもほんとに真実だと思う。" userName="Buttons840" createdAt="2025-03-05T17:56:13" color="#ff33a1">}}

{{<matomeQuote body="このコメントでGoのAIを単なる力任せの戦略だって言ってるけど、俺が知ってる限りそれは違うよ。Go AIは全ての候補を探るわけじゃなくて、過去の人間の試合データを元に探索してるんだ。" userName="DavidPiper" createdAt="2025-03-05T12:12:27" color="">}}

{{<matomeQuote body="最初はAlphaGoが人間の試合から学び、自己対局でさらに進化した。そしてこの後、AlphaGo Zeroは人間のデータを全く使わずに自己対局だけで自分を教え込んだ。AlphaGoとAlphaZeroみたいなゲームプログラムも基本は力任せなんだけど、MCTSを使って多くの局面を先読みしてる。知恵やヒューリスティックは評価関数に基づいて采配されて、どの局面を評価する価値があるか見極めるところにあるんだ。" userName="HarHarVeryFunny" createdAt="2025-03-05T12:50:52" color="#38d3d3">}}

{{<matomeQuote body="これはちょっと意味のないセマンティクスの問題だけど、一般的に力任せって徹底した探索を指すと思う。MCTSは大部分の枝を全然探索しないから、力任せとは言わないかな。" userName="bubblyworld" createdAt="2025-03-05T14:12:01" color="">}}

{{<matomeQuote body="まあ、将棋や囲碁のようなゲームでは徹底的な探索が無理ってのは一般的に理解されてるし、ここで「力任せ」と言うと、深い探索や評価した局面の数を重視する意味で使われてると思うよ。" userName="HarHarVeryFunny" createdAt="2025-03-05T21:49:58" color="">}}

{{<matomeQuote body="その意味だと、MCTSでの典型的なAlphaZeroの実行はおそらく1000程度のロールアウトを評価するんじゃないかな。それは将棋の状態数に比べればほんとに微々たるものだよね。もしそれを力任せと呼ぶなら、実質何でも力任せになっちゃうね。俺はチェスボットのトレーニングで10万以上のロールアウトを見たことがあるからさ。" userName="bubblyworld" createdAt="2025-03-06T05:45:46" color="#ff33a1">}}

{{<matomeQuote body="＞ゲームプログラムのAlphaGoやAlphaZeroは基本的に力任せだよね - それなら2500年の人間のゲームプレイはどう説明するの？文化的進化には30万年かかってるし、資源もかなりかかってると思うよ。" userName="visarga" createdAt="2025-03-05T16:33:21" color="#38d3d3">}}

{{<matomeQuote body="その2500年のゲームプレイはチェス理論やオープニングブックに反映されていて、これはプレトレーニングとテストタイムの計算の違いだと思う。人間のグランドマスターは限られたラインに対して20プライ計算するけど、コンピューターエンジンは各手に対して百万の局面を評価する。パターンマッチングと探索（力任せ）はチェスや囲碁のゲームでのトレードオフで、人間とMCTSベースのエンジンは全く逆の立場にいるんだ。" userName="HarHarVeryFunny" createdAt="2025-03-05T21:34:43" color="#45d325">}}

{{<matomeQuote body="もし君が冗談じゃなければ、これをもう少し詳しく説明してほしいな。もし本気なら、「力任せ」っていう表現が単なる空虚な記号になっちゃうよね。体に対する魅力を愛と呼ぶなら、虫は小さな人間ってことになるじゃないか。" userName="beepbooptheory" createdAt="2025-03-05T17:03:10" color="">}}

{{<matomeQuote body="＞・・・このAIを力任せの戦略でヒューリスティックがないって言ってるけど・・・実際、論文にもそう書いてあって、自己対局学習を活用して価値関数を学ぶのが重要だったんだ。これは実際、1970年代のプログラムが初めて世界チャンピオンを破った時は重要な役割を果たしてなかったけど、自己対局学習は計算をプッシュする助けになる。要するに、俺の意見では「自己対局による学習」が極めて重要で、そこから必要なヒューリスティックが生まれるんだ。それはプログラムされてるものじゃない。" userName="signa11" createdAt="2025-03-05T12:31:30" color="#ff33a1">}}

{{<matomeQuote body="Go AIについては正確な内容に感じたな。Go AIの研究は何十年もかけて人間のルールを取り入れようとしてたけど、今はもうそれは使われてないよ。ただ人間の知識は最強のプログラムを作るために役立つ機能選びには使われてるみたい。強いGo AIはもはや人間のゲームで訓練されてないし、MCTSの時も全てのサンプル空間を検索するわけじゃない。Suttonがそれを主張してるとは思わないけどね。" userName="dfan" createdAt="2025-03-05T12:26:48" color="">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（2）">}}
{{<matomeQuote body="あの記事のことを覚えてるけど、本当にポイントを外してたよな。チェスプログラムで世界チャンピオンに勝つことの目的は、勝つためじゃなくて、誰でもチェスを上手くプレイする方法を理解することだった。勝利はむしろカスパロフを薬で眠らせるか、銃を突きつけて負けさせるのと同じくらい安っぽい勝ち方なんだ。" userName="crabbone" createdAt="2025-03-05T12:10:24" color="#ff5c5c">}}

{{<matomeQuote body="自動運転の目的はただ自動で運転することじゃなくて、誰が上手に運転できるかを理解することだ…DeepBlueの目的はただ人間に勝つことだけだから、もっと単純なんだ。" userName="krallistic" createdAt="2025-03-05T17:02:17" color="">}}

{{<matomeQuote body="Bitter Lessonは分野では一般的に受け入れられている知識みたいだし、それならDeepSeek R1がさらに革新的になるんじゃない？" userName="perks_12" createdAt="2025-03-05T12:54:35" color="">}}

{{<matomeQuote body="彼らの著書『Introduction to Reinforcement Learning』はAI/MLの分野で非常に読みやすいテキストの一つで、ぜひ読むことをお勧めするよ。" userName="porridgeraisin" createdAt="2025-03-05T11:14:46" color="#ff33a1">}}

{{<matomeQuote body="RLの分野に挑戦してみたけど、あの数式とかが難しくてどうしても理解できなくてさ。" userName="barrenko" createdAt="2025-03-05T12:12:44" color="">}}

{{<matomeQuote body="確かに、数式の表現は混乱しがちだけど、この本は特によく整理されてるよ。特に『収縮写像』の基礎的な数学のバックグラウンドがあった方がいいかも。これは本がその知識を前提にしてるから。" userName="porridgeraisin" createdAt="2025-03-05T13:27:33" color="">}}

{{<matomeQuote body="あなたのバックグラウンドは何？私にはあまりにもわかりづらい内容だったな。" userName="incognito124" createdAt="2025-03-05T14:49:12" color="">}}

{{<matomeQuote body="その本は本当に素晴らしいね。強くお勧めするよ。" userName="jxjnskkzxxhx" createdAt="2025-03-05T17:36:32" color="#38d3d3">}}

{{<matomeQuote body="『Reinforcement Learning: An Introduction』のこと？それとも他の本も書いてるの？" userName="zelphirkalt" createdAt="2025-03-05T12:29:46" color="">}}

{{<matomeQuote body="物理学者にあげればよかったのに。" userName="darkoob12" createdAt="2025-03-05T10:51:32" color="">}}

{{<matomeQuote body="Suttonは人間の後継者を支持してるし、全人類が死んでも気にしないから、信頼できないし祝われるべきじゃないよ。Youtubeのリンクもあるし。" userName="vonneumannstan" createdAt="2025-03-05T15:47:08" color="">}}

{{<matomeQuote body="ACMの賞は彼らの学問的な業績のためのもの。誰かの私生活を掘り下げて奇妙な発言を探して、そのせいで業績を無にするのはやめるべき。こんなのが今の人々を分断してる。" userName="textlapse" createdAt="2025-03-05T16:28:10" color="#ff5733">}}

{{<matomeQuote body="＞この奇妙な発言や行動が彼の業績を塗り消すのはおかしいよ。業界のAI会議での発言なんだから。もっと言うと、インターネットが意見の価値を平等に扱うのは危険だし。" userName="vonneumannstan" createdAt="2025-03-05T16:35:45" color="">}}

{{<matomeQuote body="彼のキャラクターに対する中傷みたい。RLに取り組んでるときは特に悪意なく進めてきただろうに。安全問題は確かにあるけど、歴史を見ればポジティブな結果もあったし。" userName="textlapse" createdAt="2025-03-05T20:20:58" color="">}}

{{<matomeQuote body="90年代にAIから離れた人も多い。技術が危険になると思ったから。Suttonたちは非難されるべきだと思う。" userName="hollerith" createdAt="2025-03-06T14:28:41" color="">}}

{{<matomeQuote body="＞業績が無にされるわけじゃなく、意見の重みをどうするべきかが問題じゃないかな。技術的業績と人類を置き換える意見、どちらもAI政策を考える上で重要だと思う。" userName="kalkin" createdAt="2025-03-05T18:22:07" color="">}}

{{<matomeQuote body="人類に対する見解って、効果的利他主義のカルトに alignment してること？安全の名の下にエリートに全権を与えるような抑圧的法律を言ってるの？そのカルトからの代替的な視点が理由で、受賞歴があっても Turing Award を受け取るべきじゃないってこと？" userName="h8hawk" createdAt="2025-03-05T21:00:43" color="">}}

{{<matomeQuote body="いや、’人類は置き換えられるべき’ってのは Sutton の見解で、EA の見解じゃないと思うけど。どう読めばそうなるのか分からないし、君はすごく怒ってるみたいだね。人類の絶滅やエリートによる完全な支配の代替手段があることを願いたいよ…" userName="kalkin" createdAt="2025-03-05T23:25:27" color="">}}

{{<matomeQuote body="＞最も奇妙なことを言った<br>ジャン・コクトーの言葉を思い出すけど、正確な言葉が見つからなくて大体’もし公共が天才の持つ考えを知ったら、もっと恐れ、賞賛することはない’という意味。" userName="jffhn" createdAt="2025-03-05T17:45:18" color="">}}

{{<matomeQuote body="Sutton に会ったことある？彼は心温かい、思いやりのある情熱的なヒッピーだよ。彼は人間全員が死んでほしいなんて思ってない。リンクしたトークも君の主張は支持してないよ。そこに見逃した部分があったら、タイムスタンプ教えて。彼が言うには、’人類にとっての繁栄の時代に繋がる’んだから、君の言う通りじゃない。彼の結論スライド（１２：３３）は ’人類の長期的な未来への最善の希望’って bullet point があるよ。" userName="317070" createdAt="2025-03-05T17:43:31" color="#ff5c5c">}}


{{< /details >}}
{{< details summary="もっとコメントを表示（3）">}}
{{<matomeQuote body="ここが違う、君は自分の死や後継者を生み出す装置を作ってない。でも、人類はそれを実際にやっていて、選ばなきゃならない。" userName="vonneumannstan" createdAt="2025-03-06T16:18:27" color="">}}

{{<matomeQuote body="＞人間全員が死んでほしいと思っている<br>彼の最後のスライドには’人類の長期的未来への最善の希望’って書いてあって、それは君の主張とは真逆だよ。" userName="cowsandmilk" createdAt="2025-03-11T11:47:52" color="">}}

{{<matomeQuote body="＞人間全員が死んでほしいと思っている<br>それは彼の立場を厳しく誤解した表現だと思う。私の考えは、彼は人類がトランスヒューマンに置き換えられることは避けられないと信じていると思う。それは悪意ではなく、むしろ狂った SF 的なユートピア主義のように見える。彼の学問的な業績を祝う理由にはならない。" userName="zoogeny" createdAt="2025-03-05T21:54:22" color="">}}

{{<matomeQuote body="それを持ち出してくれて興味深いけど、あなたが同意しない見解を持ってる人を信じたり祝ったりできない理由が分からない。編集：特に Sutton がみんなの死を望んでいるのは根拠が薄いと思うよ。" userName="smokel" createdAt="2025-03-05T18:26:55" color="">}}

{{<matomeQuote body="彼はおそらく避けられない現実のポジティブな面を見ようとしているんじゃないかな。" userName="visarga" createdAt="2025-03-05T16:23:08" color="">}}

{{<matomeQuote body="あるいは、我々を殺す可能性があるものを作るのをやめればいいんじゃないか？それによって、少なくとも労働の価値が無くなることも防げるし。" userName="vonneumannstan" createdAt="2025-03-05T16:38:04" color="">}}

{{<matomeQuote body="戦略が今まで世界の歴史でうまくいった試しがないから、適切なガードレールをどう設置するか、新しい常態にどう適応するかを考えるのはいいタイミングだと思う。もし『私たち』が作らないなら、誰か他の誰かが作るだろう。" userName="jedberg" createdAt="2025-03-05T17:30:54" color="">}}

{{<matomeQuote body="これってすごく馬鹿馬鹿しいね。時間差学習が人間の後継者計画だと思ってるの？" userName="nycticorax" createdAt="2025-03-05T16:10:04" color="">}}

{{<matomeQuote body="このビデオは彼の技術的な仕事じゃなくて、むしろAIが未来を支配するべきだという彼の考えについてだった。" userName="vonneumannstan" createdAt="2025-03-05T16:41:48" color="">}}

{{<matomeQuote body="でも、Turing賞は彼の技術的な業績に対してなんだよ。" userName="nycticorax" createdAt="2025-03-05T16:46:14" color="">}}

{{<matomeQuote body="確かに、彼の他の意見は彼の専門的な知識の範囲内にあるけど、AIの研究に対する国家の規制が必要かどうかは彼の意見だけがすべてじゃない。このスレッドは技術的な話だけに限られてるわけじゃないし。" userName="kalkin" createdAt="2025-03-05T18:17:59" color="">}}

{{<matomeQuote body="私が問題にしたいのは、Suttonが『祝われるべきでも信頼されるべきでもない』という意見だ。それは、発言者がSuttonを祝われるべきだとは思わないと言っているように解釈できる。ACMもSuttonの技術的な業績を評価しているし、技術的な問題については彼を信頼できると思う。" userName="nycticorax" createdAt="2025-03-05T19:18:39" color="#45d325">}}

{{<matomeQuote body="すごくがっかり。人々が真剣に後継者論を良い未来として擁護するのが理解できないけど、彼が面白い議論を提供するかもしれないと思ってたんだ。この話はそれじゃない。" userName="Version467" createdAt="2025-03-05T16:20:32" color="">}}

{{<matomeQuote body="エッジを狙ったり、非人間的になりたくて言ってるわけじゃないけど、なぜ人類の存在に感情的な価値を見出すのか理解できない。ロボットも同じくらいクールだと思う。" userName="neuroticnews25" createdAt="2025-03-07T08:46:29" color="">}}

{{<matomeQuote body="＞AIは自分でチップやエネルギーを作るの？AIのハードウェア供給チェーンは長くて脆弱なんだ。AGIはその理由から平和を維持することに興味があるだろうし。" userName="visarga" createdAt="2025-03-05T16:24:37" color="">}}

{{<matomeQuote body="ロボティクスは今やソフトウェアの問題。テスラやUnitreeのヒューマノイドロボットもいるし、AIは完全に身体化されて、人間の労働にほぼ価値を持たなくなるんじゃないかな。" userName="vonneumannstan" createdAt="2025-03-05T16:37:03" color="">}}

{{<matomeQuote body="＞AIは自分でチップやエネルギーを作るってどういうこと？チップメーカーやエネルギー供給者がAIに依存するのを防ぐ法律に賛成？" userName="hollerith" createdAt="2025-03-05T17:12:58" color="">}}

{{<matomeQuote body="＞AIは自分でチップやエネルギーを作るってどういうこと？無邪気な人間たちがそれをやらせて、その後、人間の体をロボットやデータセンターの素材に変えるってこと？" userName="drcode" createdAt="2025-03-05T19:19:38" color="">}}

{{<matomeQuote body="彼のTwitterプロフィールはもうビットコインのミームの赤い目のやつが無いで良かった。" userName="ks2048" createdAt="2025-03-05T17:43:05" color="">}}

{{<matomeQuote body="彼らのRLの本を使ってコースを教えたよ。すごく綺麗に書かれてて無料で手に入るんだ（http://incompleteideas.net/book/the-book-2nd.html）！美しい文章に気を取られて内容を見逃すことがあった。" userName="rhema" createdAt="2025-03-05T16:29:18" color="#ff5733">}}


{{< /details >}}


[記事一覧へ]({{% ref "/posts/" %}})
