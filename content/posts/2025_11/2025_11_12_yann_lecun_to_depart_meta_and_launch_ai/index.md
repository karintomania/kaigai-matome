+++
date = '2025-11-12T00:00:00'
months = '2025/11'
draft = false
title = 'ヤン・ルカンがMetaを退社！ワールドモデル特化のAIスタートアップを設立へ'
tags = ["AI", "スタートアップ", "機械学習", "ワールドモデル", "Meta"]
featureimage = 'thumbnails/purple8.jpg'
+++

> ヤン・ルカンがMetaを退社！ワールドモデル特化のAIスタートアップを設立へ

引用元：[https://news.ycombinator.com/item?id=45897271](https://news.ycombinator.com/item?id=45897271)




{{<matomeQuote body="今のAI市場マジで変だよ。研究者がただの「科学実験」でお金もらいまくって、それが何十億ドルもの評価になるなんて、俺が見てきた中で一番イカれてる。昔はそんなのバッドワードだったのにね。" userName="mehulashah" createdAt="2025/11/12 13:21:19" color="#38d3d3">}}




{{<matomeQuote body="去年まではそうだったけど、今は転換期みたい。OpenAIはこの数ヶ月、Instant CheckoutとかAgentKitみたいに製品に集中してるし、AnthropicはClaude Codeに全振りだね。AGIとか超知能の話は減ってきて、既存モデルから製品を作るのと、消費を支えるためのデータセンター建設が今の主流さ。" userName="DebtDeflation" createdAt="2025/11/12 13:31:27" color="#ff5c5c">}}




{{<matomeQuote body="Metaがこの夏から研究者を1億ドル以上の高待遇で大量に雇ってるのって、結構新しい動きだよね。Llama 4で出遅れたZuckがよっぽど悔しいんだろうな。これが市場全体のトレンドかは分かんないけど。" userName="brandall10" createdAt="2025/11/12 13:43:21" color="">}}




{{<matomeQuote body="AnthropicがClaude Codeに力を入れてるなら、GitHubでめちゃくちゃコメントされてるIssueに対応しないのってどうなの？https://github.com/anthropics/claude-code/issues/3648なんか、みんなフィードバックを求めてOpenAIに行っちゃうって言ってるし、7月からずっと放置されてるよ。他も似たようなのいっぱいあるし。" userName="ximeng" createdAt="2025/11/12 14:57:01" color="#ff33a1">}}




{{<matomeQuote body="「今までで一番変な技術市場」だって？あんた、ドットコムバブル時代を知らないだけなんじゃない？あの頃は「e-」がつくものなら何でも売られてたんだぜ。ePets、ePlants、eStamps、eUnderwear、eStocks、eCards、eInvites…って、数えきれないくらいあったからね。" userName="zikduruqe" createdAt="2025/11/12 13:31:29" color="#38d3d3">}}




{{<matomeQuote body="Metaに雇われた奴ら、結構すぐに辞めたらしいじゃん。きっと、AI slopとかソーシャルメディアでの子供への精神的虐待みたいな仕事内容を見て、うんざりしたんだろうね。誰もそんなクソみたいな仕事したくないよ。" userName="renegade-otter" createdAt="2025/11/12 14:40:36" color="">}}




{{<matomeQuote body="もし「科学実験」がほとんどの仕事を代替できる可能性を秘めているなら、その実験で成功した奴が経済の覇者になるのは当たり前だよ。みんながそれに夢中になるのは当然だし、まさに囚人のジレンマってやつさ。" userName="gdulli" createdAt="2025/11/12 14:39:16" color="#45d325">}}




{{<matomeQuote body="「今までで一番変な技術市場」って話だけど、この現象は「The Perfect AI Startup」（https://www.bloomberg.com/opinion/newsletters/2025-09-29/the...）で詳しく解説されてるよ。Muratiが全然質問に答えられないのに20億ドルも調達したっていうエピソードはまさにそれ。" userName="xnx" createdAt="2025/11/12 17:05:42" color="#785bff">}}




{{<matomeQuote body="核融合だってほとんどの発電を置き換えてエネルギー経済を制する可能性を秘めてるのに、2024年の投資額はAIの2500億ドル以上に対してたったの100億ドルくらいだよね。なんでこんなに違うんだろう？" userName="0_____0" createdAt="2025/11/12 14:45:38" color="#785bff">}}




{{<matomeQuote body="2025年にFacebookからの仕事を受けた賢い人が、自分がどこの会社に入ったのか理解してないって、どういうことなんだろうね。理解できないよ。" userName="ikamm" createdAt="2025/11/12 14:44:56" color="">}}




{{<matomeQuote body="ブロードキャストTV（アメリカンフットボールとか）見てないのかな？Anthropicは、エンドユーザーにチャットボットを使ってもらうために、大規模な広告キャンペーンを展開しているよ。" userName="thefourthchime" createdAt="2025/11/12 16:39:32" color="">}}




{{<matomeQuote body="正直、Anthropicは他の大手とは違う方法で認知度を上げる必要があるよ。テック界隈ではClaudeは有名だけど、一般人にはほとんど知られてない。数ヶ月前は認知度が数％だったのに、OpenAI/ChatGPTは80％くらい。だからAnthropicは認知度アップキャンペーンから、もっと得るものが多いはずだね。" userName="commandar" createdAt="2025/11/12 17:58:06" color="#ff5c5c">}}




{{<matomeQuote body="「研究者が科学実験にVC資金を得るのは変だ」って意見への反論だね。僕は複数のスタートアップで働いたけど、研究バックグラウンドを持つ創業者がVCから資金を得て仮説を証明するのは普通のことだよ。研究が盛んな大学の近くならよく見る光景だし、FAANG出身者がVC資金を得るのも珍しくないよ。" userName="Aurornis" createdAt="2025/11/12 13:54:00" color="#ff5c5c">}}




{{<matomeQuote body="多くのユーザーはAnthropicの製品を求めてないから、一発屋みたいに感じるよ。でも、うちのベテランエンジニアたちはみんなClaude Sonnet 4.5をすごく気に入ってるんだ。この優位性がいつまで続くかはわからないけどね。" userName="potatoproduct" createdAt="2025/11/12 18:14:10" color="">}}




{{<matomeQuote body="LLMの出力が表面上説得力があるから、人々はもう知能があるとか、知能が近いとか、労働を代替するとか思ってるよね。もし「スロップ」消費が一時的な流行で終わって、真に有用な知能に到達しなければ、AIへの投資は冷え込むだろうね。" userName="gdulli" createdAt="2025/11/12 15:52:45" color="#ff5733">}}




{{<matomeQuote body="知能を問題解決能力と定義するなら、AIは僕をより賢くしてくれる。それにはお金を払う価値があると思ってるよ。" userName="SamPatt" createdAt="2025/11/12 16:36:07" color="#38d3d3">}}




{{<matomeQuote body="オランダってまだドットコムバブル時代みたいで面白いよね。ペット探しはverhuisdieren.nl、ウォールアートはwall-art.nlって感じで、何でも「.nl」の専門サイトがあるんだよ。Coolblueみたいな大手もこれ系のドメイン買って自社サイトに飛ばしてるくらいなんだ。<br>これって結構便利だよね！" userName="ricardobeat" createdAt="2025/11/12 13:46:27" color="#785bff">}}




{{<matomeQuote body="個人的には、これは良い傾向だと思うな。VCって元々はGenentechとかHerbert BoyerのリコンビナントDNA技術みたいな、高い技術リスクのある実験に投資してたんだ。それが最近は、もう動いてるけど規模拡大にお金が必要なものに投資する、PE（プライベートエクイティ）寄りになってきた感じだね。" userName="baxtr" createdAt="2025/11/12 14:20:21" color="#ff5c5c">}}




{{<matomeQuote body="何の証拠もなしに言いたい放題で、誰も反論しないんだね。Hacker Newsが嫌いな大手ハイテク企業に関するデタラメな主張にはよくあるパターンだよね、マジウケる。" userName="Anon1096" createdAt="2025/11/12 17:30:23" color="">}}




{{<matomeQuote body="投資家は、最初のプロダクトを見て今どう思ってるんだろうね？！もしかしたら、有望なAIスタートアップをピンポイントで選ぶよりも、コネクションの強いAIスタートアップ全部に投資する方が、結果的に安全なのかもね？" userName="HarHarVeryFunny" createdAt="2025/11/12 18:54:53" color="">}}




{{<matomeQuote body="これって別に外れ値じゃないよ。Theranos、Magic Leap、OpenAI、Anthropicとかを考えたら、みんな同じじゃん。一見するとplausibilityなアイデア（よく見ると怪しいけど）、slickなデモ、そして強力なコネクションを持った創業者たち。LeCunは嫌われてるけど（匿名掲示板の投稿見ればわかる）、彼はMetaでめちゃくちゃ成功したチームを率いて、立ち上げもしたんだよ。" userName="KaiserPro" createdAt="2025/11/12 16:11:16" color="#ff5c5c">}}




{{<matomeQuote body="ふと疑問なんだけどさ、もし今AIに投じられてるのと同じくらいのお金を、核融合エネルギーの研究開発に注いでいたら、たった3年間でどれだけ進歩してたんだろうって思っちゃうんだよね。" userName="mrbonner" createdAt="2025/11/12 14:46:29" color="">}}




{{<matomeQuote body="もし、ある科学実験が成功して世界を変えるなら、その価値は1兆ドルだとするじゃん？じゃあ、それが世界を変える可能性が5％だったら、一体どれくらいの価値があると思う？" userName="panarky" createdAt="2025/11/12 16:33:02" color="#ff33a1">}}




{{<matomeQuote body="みんなVS Codeで同じ現象が起きてるみたいだけど、俺はWindows TerminalからSSHでLinuxサーバーのClaude code使ってて、全く同じことになってるんだよ。ってことは、共通してるのは彼らのアプリってことだよね？" userName="andersa" createdAt="2025/11/12 15:18:32" color="">}}




{{<matomeQuote body="電卓ってさ、別に人を数学に強くしなかったよね。むしろ電卓がないと計算できない社会を作っちゃった。そのせいで、ちょっとした時に計算が必要なのに、電卓出すのが面倒だからって計算しない人が増えてるんだよ。結果として、スーパーとかで騙されやすくなっちゃったんだよね。" userName="gdulli" createdAt="2025/11/12 17:18:40" color="#785bff">}}




{{<matomeQuote body="もしN個のスタートアップがあって、そのうち最低1つが投資額のN倍以上の利益を生むって期待できるなら、全部に投資してもプラスのROIになるんだよ。どれも大当たりしなくても投資は失うけど、どれか一つでもめちゃくちゃ伸びれば利益が出る。事前に勝者と敗者を見極めるのは超難しいから、事業分野全体に投資するのって、VC版インデックスファンドみたいなもんだよね。" userName="SAI_Peregrinus" createdAt="2025/11/12 20:15:37" color="#ff33a1">}}




{{<matomeQuote body="Ridiculous. Theranos was a literal crime scene. Its products didn’t work at all, and physically couldn’t work due to the nature of blood itself.Magic Leap was an honest if overhyped effort that didn’t achieve product-market fit.Meanwhile, products from OpenAI and Anthropic have both done useful work for me this week." userName="CamperBob2" createdAt="2025/11/12 20:16:19" color="#785bff">}}




{{<matomeQuote body="＞ Meta hiring researchers en masse at $100m+ pay packages is fairly new, as of this summer.En masse? Wasn’t it just a couple of outliers?" userName="andsoitis" createdAt="2025/11/12 14:07:32" color="">}}




{{<matomeQuote body="Making LeCun report to Wang was the most boneheaded move imaginable. But… I suppose Zuckerberg knows what he wants, which is AI slopware and not truly groundbreaking foundation models." userName="sebmellen" createdAt="2025/11/12 07:57:49" color="">}}




{{<matomeQuote body="In industry research, someone in a chief position like LeCun should know how to balance long-term research with short-term projects. However, for whatever reason, he consistently shows hostility toward LLMs and engineering projects, even though Llama and PyTorch are two of the most influential projects from Meta AI. His attitude doesn’t really match what is expected from a Chief position at a product company like Facebook. When Llama 4 got criticized, he distanced himself from the project, stating that he only leads FAIR and that the project falls under a different organization. That kind of attitude doesn’t seem suitable for the face of AI at the company. It’s not a surprise that Zuck tried to demote him." userName="xuancanh" createdAt="2025/11/12 08:55:07" color="#ff33a1">}}




{{< details summary="もっとコメントを表示（1）">}}

{{<matomeQuote body="He is also not very interested in LLMs, and that seems to be Zuck’s top priority." userName="gnaman" createdAt="2025/11/12 08:02:22" color="">}}




{{<matomeQuote body="Yeah I think LeCun is underestimating the impact that LLM’s and Diffusion models are going to have, even considering the huge impact they’re already having. That’s no problem as I’m sure whatever LeCun is working on is going to be amazing as well, but an enterprise like Facebook can’t have their top researcher work on risky things when there’s surefire paths to success still available." userName="tinco" createdAt="2025/11/12 08:05:58" color="#45d325">}}




{{<matomeQuote body="These are the types that want academic freedom in a cut-throat industry setup and conversely never fit into academia because their profiles and growth ambitions far exceed what an academic research lab can afford (barring some marquee names). It’s an unfortunate paradox." userName="blutoot" createdAt="2025/11/12 10:55:59" color="">}}




{{<matomeQuote body="Maybe it’s time for Bell Labs 2?I guess everyone is racing towards AGI in a few years or whatever so it’s kind of impossible to cultivate that environment." userName="sigbottle" createdAt="2025/11/12 11:41:46" color="#38d3d3">}}




{{<matomeQuote body="That was obviously him getting sidelined. And it’s easy to see why.LLMs get results. None of the Yann LeCun’s pet projects do. He had ample time to prove that his approach is promising, and he didn’t." userName="ACCount37" createdAt="2025/11/12 09:06:46" color="">}}




{{<matomeQuote body="I would pose a question differently, under his leadership did Meta achieve good outcome?If the answer is yes, then better to keep him, because he has already proved himself and you can win in the long-term. With Meta’s pockets, you can always create a new department specifically for short-term projects.If the answer is no, then nothing to discuss here." userName="throwaw12" createdAt="2025/11/12 09:02:59" color="#ff5c5c">}}




{{<matomeQuote body="俺は遠慮なく反論するね。産業研究者は、企業が取れないようなリスクの高いことをするのが仕事なんだよ。アインシュタインも言ってたけど、『うまくいくと分かってるなら、それは研究じゃない』ってね。LeCunが言うように、今のLLMは行き詰まりだと思う。まだ限界まで活用してないのは確かだけどさ。WebエージェントとLLMを組み合わせるには、スケーラブルなマイクロペイメントインフラが必要になるだろうね。俺は空間/地理モデルの研究をしてるんだけど、知識モデルをテキスト生成から分離することが、幻覚を解決する唯一の方法だと感じるな。" userName="jll29" createdAt="2025/11/12 08:26:27" color="#45d325">}}




{{<matomeQuote body="LLMが結果を出してるなんて、かなり大胆な発言だよね。もし本当に結果が出てるなら、採用されて儲かってるはずだろ？なんで200億ドル以上の借金をSPVに隠してるんだよ。LLMって最高に謎な技術だよな。すごいんだけど、非決定論的な幻覚性があるせいでダメ。精度と正確さがいらないって皆を説得しない限り、普及は無理だよ。多くのCEOたちはこのアイデアに夢中になってるけど、まるでクラックコカインに依存してるようなもんだ。そろそろ現実が来るぞ。" userName="camillomiller" createdAt="2025/11/12 09:28:56" color="#38d3d3">}}




{{<matomeQuote body="人間が知性って何なのか、どう機能するのかさえ分かってないのに、AGIでそれを再現しようとするなんて、マジでクレイジーだよな？" userName="gtech1" createdAt="2025/11/12 13:06:41" color="">}}




{{<matomeQuote body="LLMは結果を出してるし、採用されてるし、ちゃんと儲かってるよ。フロンティアモデルは全部黒字だし、推論サービスも高マージンで売れてて、売上は伸び続けてる。みんな支出ばっかり見て、収益を全然見てないのがおかしいんだよ。数年で0から120億ドルに売上が伸びるってことは、誰も欲しがらない製品じゃないってことだろ？“非決定論的な幻覚性”についても、人間だってあるんだから大げさすぎるって思うね。AIは“十分良い”代替品を提供できればいいんだよ、そしてそれはよくできてる。" userName="ACCount37" createdAt="2025/11/12 09:43:49" color="#785bff">}}




{{<matomeQuote body="オントロジーみたいな知識モデルって、いつも怪しいって思うんだよな。世界は確率的で曖昧な情報だらけなのに、明確な二進法的事実のスキーマを約束するからさ。ソロテスパラドックスからリーキーアブストラクションまで、現実のものは細かく見ると精密な定義を拒むし、抽象化しようとすると細部がまた見えてくるんだ。数学モデルや情報システムでは純粋さを得られるけど、それらは世界を不完全にモデル化してるし、現実と乖離したら常に更新やリファクタリングが必要になる。これらはLLMみたいなモデルが使うツールとして使うのが一番で、必要に応じて作って捨てればいいんだ。決して真実の源泉にはならないよ。" userName="barrkel" createdAt="2025/11/12 08:42:30" color="#45d325">}}




{{<matomeQuote body="R＆D部門が軽視される製品会社は、真っ先に死ぬことになるんだよな。" userName="sharmajai" createdAt="2025/11/12 11:32:58" color="">}}




{{<matomeQuote body="Metaはまさにそうしたよな、LeCunを留めたけど彼の研究範囲は縮小したんだ。彼の研究は研究コミュニティには間違いなく貢献したけど、Metaに良い結果をもたらしたかは疑問だね。LeCunのSNSを見ると、FAIRの研究結果の評価方法がすごく視野が狭くて、まだ学術的な考え方に従ってるのが分かる。彼は『研究評価は難しい。なぜなら製品への影響は何年も（時には何十年も）後になるからだ。そのため、評価は出版物、引用、招待講演、賞などの代理指標を通じて、研究コミュニティの集合的な意見に頼ることが多い』って言ってる。でも、産業研究者なら、自分の研究が会社のビジョンにどう合致するかを簡単に評価できるはずだろ？もし会社のビジョンがAIリーダーになることなら、彼は10年以上Metaにいるのに、今のところその目標に失敗してるように見えるね。" userName="xuancanh" createdAt="2025/11/12 09:32:23" color="#45d325">}}




{{<matomeQuote body="数年後のAGIを目指してるってのは、史上最大の株式市場バブルを支える夢物語だね。賢い投資家はもう次のバブル、量子の方にジャンプしてるよ…。" userName="belter" createdAt="2025/11/12 12:02:28" color="">}}




{{<matomeQuote body="MetaはAIで一体何をしたいんだ？超知能で癌を治したり核融合炉を作ったりするってのは、100%彼らの専門外だろ。もし本物と同じかそれ以上の合成会話パートナーや合成コンテンツジェネレーターを作ったとしても、地球上の他の全ての人々が彼らのソーシャルネットワークに登録する価値はゼロになる。それはとにかく不可能だよ。俺がFacebookを使うのは、リアルな人間関係を維持するためで、無限のコンテンツを消費するためじゃないんだから。" userName="torginus" createdAt="2025/11/12 10:31:29" color="#ff5c5c">}}




{{<matomeQuote body="それに彼っていつも“これはうまくいかないだろう”って言ってるみたいだよね。おい、お前研究者か？実験して結果に従うのが研究者だろ。それが預言者とか哲学者の類と違うところなんだよ。" userName="nsonha" createdAt="2025/11/12 09:55:52" color="">}}




{{<matomeQuote body="LLM批判してる人たちに言いたいんだけど、LLMが未来じゃないって言うなら、もっと良いものを持ってこないとダメだよ。理論はすごいかもしれないけど、GPT2レベルまで実際に作ってから、LLMを否定すべきだね。<br>Linusも言ってるけど、「口で言うのは簡単、コードを見せてくれ」。" userName="raverbashing" createdAt="2025/11/12 08:09:53" color="#38d3d3">}}




{{<matomeQuote body="「史上最大の株式市場のバブルを支える夢物語」って？イノベーションってそういうもんでしょ。電気自動車、バッテリー、太陽光パネルとか見てみ？バブルとか生存競争とか、そんなこと言ってるからイノベーションを逃してるんだよ。<br>Metaの株はAI投資で既に下がってるんだし、どこがバブルなの？" userName="re-thc" createdAt="2025/11/12 12:08:46" color="#ff5733">}}




{{<matomeQuote body="「研究者の目的はリスクのあることをすること」って言うけどさ、それは大学での話だよ。兆ドル規模の会社では、株主を喜ばせるような「うまくいくリスクのあること」をリードするのが、チーフサイエンティストの仕事でしょ。" userName="siva7" createdAt="2025/11/12 08:34:35" color="">}}




{{<matomeQuote body="LeCunは本当にワールドモデルに未来があるって信じてるんだね。彼だけじゃないけどさ。ずっと望んでたポジションで、常に話してたことを証明できるといいね、彼にとって良いことだよ。" userName="hbarka" createdAt="2025/11/12 13:48:36" color="">}}




{{<matomeQuote body="「（LLMが）既に大きな影響を与えている」って言うけど、ソフトウェア開発の世界ではそうかもしれないけど、それ以外ではほぼゼロだよね。Officeでビデオ通話の文字起こしができるくらいじゃ画期的じゃないよ。<br>テック以外の分野で、ブルーカラーとホワイトカラーそれぞれ最低半々、企業階層も下のレベルから上のレベルまで、コスト削減か収益増加の具体的なインパクトを10個挙げられる？やってみてよ。" userName="netdevphoenix" createdAt="2025/11/12 10:47:07" color="#38d3d3">}}




{{<matomeQuote body="幻覚を起こすコードジェネレーターに2兆ドルも使って赤字なのに、「どこがバブルなの？」って聞いてるの？" userName="belter" createdAt="2025/11/12 12:10:49" color="#ff5733">}}




{{<matomeQuote body="中国のモデルがLlamaをぶちのめしてるって事実を考えると、Llamaは全然ダメなんじゃないかな。" userName="rw2" createdAt="2025/11/12 09:05:38" color="">}}




{{<matomeQuote body="OpenAIとAnthropicは年間40億ドル以上稼いでるし、ChatGPTは8億人ものユーザーがいるって計算もあるよ。今も未来も十分な収益かは別として、かなりの大金が動いてるんだ。もし問題を解決してないなら、これだけのユーザーが使うわけないでしょ。" userName="miohtama" createdAt="2025/11/12 10:12:09" color="#38d3d3">}}




{{<matomeQuote body="ねぇ、なんで誰も、青銅を発明した人たちに「金属の正しい定義が分かって働きを理解するまでやるな」って言わなかったんだろ？<br>多分、できないって言う人は、やってる人の邪魔をすべきじゃないってことだよね。" userName="afthonos" createdAt="2025/11/12 13:32:43" color="#ff5c5c">}}




{{<matomeQuote body="LLMとDiffusionモデルは、ワールドモデルとは全然違う問題を解決してるんだよ。LLMやDiffusionモデルには物体永続性が欠けてて、見えないものを予測できない。<br>ワールドモデルは、ロボットや自動運転車にとって「足りない要素」だと考えられてる。もしそれが少しでも正確なら、高価値な製品を可能にするから、ワールドモデルに大金を注ぎ込むのは理にかなってるんだ。" userName="fxtentacle" createdAt="2025/11/12 08:25:51" color="#ff33a1">}}




{{<matomeQuote body="何で？中国人はすごく有能じゃん。ほとんどのDeep Learningの論文には中国人の名前が一つは載ってるし。それが必ずしも中国人ってことじゃないけど、なんか意味深だよね。" userName="amelius" createdAt="2025/11/12 09:34:31" color="">}}




{{<matomeQuote body="Metaはクリックと注目時間が欲しいだけ。もしOpenAIが生成コンテンツだけのソーシャルネットワークを作ったらMetaを終わらせられるよ。今でもMetaのエンゲージメントは友達からじゃないし、AIプラットフォームも大差ないかもね。馬鹿げたMetaverseのビジョンも、リアルなWorld Modelがあれば実現しそう。" userName="breppp" createdAt="2025/11/12 11:03:35" color="#ff5733">}}




{{<matomeQuote body="MetaはLeCunやCarmack、Luckeyみたいな人を失ってるけど、成功者が環境変えると普通になるパターンってよくあるよね。Formula One、物理学者、企業でもそう。逆もあって、Palmer LuckeyやEd Wittenみたいに環境変えて大成功する人もいる。これは厳密な話じゃないけどね。" userName="assemblyman" createdAt="2025/11/12 18:36:20" color="#ff5733">}}




{{<matomeQuote body="SchumacherやEinsteinは神レベルだから、比べるのは不公平かも。Palmer Luckeyは頭いいけど、IP窃盗でFacebookに技術を売って数億ドルも稼いだんだ。5000万ドルの罰金で済んだのは、マジでラッキーだっただけだよ。" userName="caminante" createdAt="2025/11/15 20:50:46" color="#ff5c5c">}}

{{</details>}}




{{< details summary="もっとコメントを表示（2）">}}

{{<matomeQuote body="World Modelは絶対正しい戦略だと思う。LLMみたいなAIエージェントは事前情報をうまく使うし、包括的で効率的なWorld Modelがあれば新しい自律エージェントが生まれるはず。これがAGIへの道になるかもね。World Modelにはすごく情熱があるから、手伝いたいなぁ。" userName="numpy-thagoras" createdAt="2025/11/12 08:12:28" color="#785bff">}}




{{<matomeQuote body="この「World Model」って概念、説明してくれる？実際、こんなモデルとどうやって繋がるの？" userName="sebmellen" createdAt="2025/11/12 08:21:03" color="">}}




{{<matomeQuote body="LeCunは、人間はフィルターなしで現実を直接体験してるって考えてるんだ。だから、LLMはWorld Modelにはなれないって思ってる。でも、俺たちの現実体験はたくさんのフィルターや歪みを通してるし、視覚だって画像を逆さまにして神経に伝えてるじゃん。彼はそれを無視して、もっと人間に近いコンピューターを作れば、直接世界と繋がって、もっと世界を理解できるモデルを作れるって信じてるんだね。" userName="natch" createdAt="2025/11/12 09:32:00" color="#ff5c5c">}}




{{<matomeQuote body="いろんな感覚障害があるから、この考え（現実を直接体験してるってやつ）は間違ってるんじゃない？俺は感覚ノイズをフィルタリングできない障害があって、視覚がアナログTVみたいに歪むんだ。ひどい時は、脳が画像をリアルタイムで構築してるのが見える。鹿が木の束になったり、泥の岩になったりするんだよ。これは、俺たちが現実を直接体験してなくて、予測的に知覚を構築してるって証拠だと思うね。" userName="BoxOfRain" createdAt="2025/11/12 10:23:04" color="#ff5733">}}




{{<matomeQuote body="人間はPredictive Codingアプローチで動くって理論があるよ。脳はKalman filterみたいに、内部のWorld Modelで世界を予測して、現実とのズレをチェックしてるんだ。学習はその誤差を最小化すること。研究者が言うWorld Modelは、視覚入力から次に何が起こるか予測できるモデルのこと。これは、次に起こることを予測したり、もしも（Counterfactuals）を考えたり、推論したりするのにすごく役立つんだ。" userName="curiouscube" createdAt="2025/11/12 11:54:52" color="#ff5c5c">}}




{{<matomeQuote body="視覚ノイズ（visual snow）で苦しんでる人がいて嬉しいよ。僕の場合、耳鳴り（tinnitus）みたいに、思い出したりひどくなったりしない限りは特に意識しないんだ。僕たちの「現実」が部分的に構築されてるって言うのは全くその通りだね。周辺視野の顔が歪んで見える「Flashed Face Distortion Effect」とか、脳が欠けてる情報を以前の情報で補完してる例だよ。<br>[0] https://en.wikipedia.org/wiki/Flashed_face_distortion_effect<br>[1] https://www.nature.com/articles/s41598-018-37991-9" userName="scoot" createdAt="2025/11/12 10:58:47" color="">}}




{{<matomeQuote body="へぇ、それは興味深いね。僕のは常に存在してて、ひどい時は自分のコードも読めなくて仕事休まなきゃいけないんだ。常にベースラインがあって、たまにランダムに悪化する感じ。君は生まれつきvisual snowを持ってるの？それとも後から？僕は10代で発症して、大学生の時に熱を出したらすごく悪化したんだ。あと、頭痛も併発したりする？" userName="BoxOfRain" createdAt="2025/11/12 11:16:34" color="">}}




{{<matomeQuote body="ワールドモデルっていうのは、AIがアクセスしたり計算したりできる、世界の一貫した（圧縮された）表現のことだよ。例えば、気象ワールドモデルなら、風速、地表温度、様々な大気層、総降水量なんかが含まれるだろうね。LLMにリアルタイムのライブフィードを提供して、常に最新の気象知識をコンテキストに読み込ませることができれば、そのLLMは予測能力で有利になるはずだよ。AIエージェント自身がモデルを更新できるワールドモデルもあるんだ。「Mr. Bot、アイスクリームを車から冷凍庫に移したよ」みたいにね。" userName="numpy-thagoras" createdAt="2025/11/12 16:44:23" color="#ff33a1">}}




{{<matomeQuote body="それって、AGIへの道筋になりそうじゃない？" userName="sgt" createdAt="2025/11/12 12:46:38" color="">}}




{{<matomeQuote body="僕は大人になってから発症したんだ。耳鳴り（tinnitus）の方が早かったけど（過度の騒音暴露が原因じゃないと思う）、僕の（非科学的な）意見としては、どちらも脳への感覚入力のノイズフィルターの欠陥か不具合っていう、同じ根本的な問題の異なる症状だと思うよ。幸い頭痛は併発しないし、めったに頭痛も起きないんだ。起こっても軽くて短時間（数分）で終わる。ひどい頭痛や長引く頭痛は経験したことがないね。君のは僕のよりずっと極端そうだ。僕のは全然日常生活に支障がないからね。ただ、こんな現象が存在すること、そして広く認識されて研究されていないことがもどかしいだけさ。視力検査士で、これが本当に存在する現象だと完全に信じてくれる人にはまだ会ったことがないよ。" userName="scoot" createdAt="2025/11/12 12:19:21" color="">}}




{{<matomeQuote body="現実を直接体験していないことが「十分な結果」（例えば人間知能）を生み出すからといって、より直接的な現実体験がより良い結果を生み出さないわけじゃないし、AIでより良い結果を生み出せないわけでもないよ。君の議論は的外れで、ストローマン論法だ。ヤン・ルカンは人間が現実を大きく修正・歪曲して体験してることを知ってるはずさ。でも彼は、僕たちが「トークンや言葉の狭いストローで現実をすすってる」わけじゃないし、「書かれたメモからだけ学んでる」わけじゃないって知ってるんだ（そして彼はそれが正しいと確信してる）。LLMも間接的なレベルでワールドモデルだけど、より直接的なワールドモデルに近いものは、大きな恩恵をもたらす可能性が非常に高いんだ。" userName="dragochat" createdAt="2025/11/12 13:07:14" color="#ff5c5c">}}




{{<matomeQuote body="アラン・ケイが言うには「人間は3ポンドのオートミールによって仲介されない現実の直接的な経験を持っている」ってことだけど、彼は心の哲学的な観念論を主張してるの？それとも代替の物理主義的な理論があるの？" userName="Gooblebrai" createdAt="2025/11/12 11:06:21" color="">}}




{{<matomeQuote body="ワールドモデルには、世界と豊かに相互作用する方法（つまり具現化）も提供されないと意味ないんじゃない？そうでなければ、どうやって訓練するの？新しい状況でワールドモデルの正確さをどう検証するんだい？" userName="Vegenoid" createdAt="2025/11/12 17:24:53" color="#ff5c5c">}}




{{<matomeQuote body="もし君の「ワールドモデル」が世界のほんの一部しかモデル化しないなら、より適切な名称は「時系列モデル」だと思うよ。相関するデータを切り捨ててしまったら、残されたモデルは全然「世界的」とは言えないからね。" userName="bigyabai" createdAt="2025/11/12 17:20:49" color="">}}




{{<matomeQuote body="今のワールドモデル研究で一番すごいのはDreamer 4だよ。ここが著者との興味深いインタビューね：https://www.talkrl.com/episodes/danijar-hafner-on-dreamer-v4<br>彼らはMinecraftをプレイする人々の録画ビデオ2,500時間分で訓練して、Minecraftのニューラルネットワールドモデルを作り出したんだ。それは基本的に学習されたMinecraftシミュレーターだよ。実際にリアルタイムでその中でMinecraftをプレイできるんだ。彼らはそのワールドモデルの中で、ダイヤモンドの入手までMinecraftをプレイして特定の目標を達成するニューラルネットエージェントを訓練したよ。このエージェントは訓練中、決して実際のMinecraftゲームをプレイしないんだ。ワールドモデルの中でだけプレイする。エージェントは自分の想像の中で訓練されるから「Dreamer」って呼ばれてるんだね。この利点は、一度ワールドモデルができれば、エージェントの訓練に追加の実際のデータは必要ないってこと。システムへの入力は、Minecraftをプレイする人々の録画ビデオという比較的小さなデータセットだけで、出力は、世界で特定の目標を達成できるエージェントになるんだ。従来はこれを達成するのに何桁も多くの実データが必要で、しかもその実データはエージェントに達成させたい特定の目標に焦点を当てる必要があったんだ。ワールドモデルは、少量の区別のない実データを、大量の目標指向の合成データに安価に増幅する素晴らしい方法だよ。<br>Minecraft自体はすでに安価に実行できるワールドモデルだから、学習されたMinecraftのワールドモデルはそれほど有用に見えないかもしれないね。Minecraftはただのテストベッドなんだ。ワールドモデルは、ロボット工学のように実データの収集が高価な領域で非常に魅力的だよ。もっと知りたいなら、上記のインタビューを聞くことをお勧めするよ。ワールドモデルは、ゲームとしてプレイしたり、ビデオを生成したりと、それ自体でも有用だよ。でも、その最も重要な応用はエージェントの訓練だと僕は思うね。" userName="modeless" createdAt="2025/11/12 15:52:17" color="#45d325">}}




{{<matomeQuote body="ヤン・ルカンはJEPAの良さをLLMを貶すことでしか伝えられてないみたいだね。彼のLLMへの不満は、次のトークン予測だけじゃ物理みたいな複雑なモデルを理解できないってところみたい。" userName="krackers" createdAt="2025/11/12 22:22:03" color="#45d325">}}




{{<matomeQuote body="人間の生物学や心理学の基本的な考え方は、表象的実在論ってやつだよ。現実ってのは感覚入力によって認識される過程で変化しちゃうってこと。直接的実在論は、現実がそのまま認識されるって考えだけど、これはもう否定されてるんだ。熱い水と冷たい水のバケツとか、水中のストローとか、例はたくさんあるよ。" userName="numpy-thagoras" createdAt="2025/11/12 16:39:00" color="">}}




{{<matomeQuote body="リアルワールドから学ぶのが、真の知性や創造性を得る唯一の方法だよ。LLMの能力ってのは、学習データに縛られちゃうんだ。いくらRLとか合成データとかエージェントループとかツールを使っても、結局は模倣であって、本当の創造性や知性には限界があるんだよね。" userName="HarHarVeryFunny" createdAt="2025/11/12 12:55:00" color="#45d325">}}




{{<matomeQuote body="でもさ、ヤンは、トークンの束を何千、何億ものトークンに再構成できるって可能性を無視してるみたいだね。LLMはまだ始まったばかりなんだ。他に良い方法がないってわけじゃないけど、もっとやれることがあるってことを彼は認めようとしないんだよ。" userName="natch" createdAt="2025/11/13 01:21:12" color="#ff5c5c">}}




{{<matomeQuote body="言語モデルのワールドモデルって、結局は言語モデルそのものだよ。目が見えず手足もない人が、一生檻に閉じ込められて、WikiPediaや4chanの言葉のフィードだけを聞いてるようなものだ。LLMが持ってるのは、この言葉の世界のモデルだけ。リアルワールドの経験がないから、リアルワールドのモデルなんて持てないんだよ。" userName="HarHarVeryFunny" createdAt="2025/11/12 13:07:36" color="#ff33a1">}}




{{<matomeQuote body="その方法だと、すごく賢いトカゲは作れるかもしれないけど、アインシュタインみたいな存在にはなれないよ。ワールドモデルは、LLMみたいに高次の脳機能と統合されるべきだと思うんだ。" userName="trhway" createdAt="2025/11/12 10:07:36" color="#45d325">}}




{{<matomeQuote body="LLMは人間がテキストで世界を説明しようとしたものから訓練されてるけど、そもそも人間の文章って現実をうまく説明できてないんだよ。だから、LLMが現実理解への足がかりになるなんてことはないんだ。" userName="tarsinge" createdAt="2025/11/12 19:01:10" color="#38d3d3">}}

{{</details>}}



[記事一覧へ]({{% ref "/posts/" %}})
